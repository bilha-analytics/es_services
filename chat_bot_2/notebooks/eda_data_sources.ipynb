{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#gsheet read db\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow, Flow \n",
    "from google.auth.transport.requests import Request \n",
    "\n",
    "import os, sys, pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gsheet read to pdf\n",
    "def gsheetRead_GoogleWay(dpath):\n",
    "    results = None\n",
    "    \n",
    "    scope =  ['https://www.googleapis.com/auth/spreadsheets'] \n",
    "\n",
    "    creds = None\n",
    "    if os.path.exists( 'token.pickle'):\n",
    "        with open( 'token.pickle', 'rb') as fd:\n",
    "            creds = pickle.load( fd ) \n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh( Request() ) \n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file( 'gsheet_get.json', scope) \n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.pickle', 'wb') as fd:\n",
    "            pickle.dump( creds, fd) \n",
    "    \n",
    "    service = build('sheets', 'v4', credentials=creds, cache_discovery=False) \n",
    "\n",
    "    sheet = service.spreadsheets()\n",
    "    reader = sheet.values().get(spreadsheetId=dpath[0], range=dpath[1]).execute() \n",
    "\n",
    "    results = reader.get('values', None)  \n",
    "\n",
    "    return results  \n",
    "''\n",
    "\n",
    "'''\n",
    "Returns two dicts : responses_db(class_category : response_paragraph) and input_phrases(input_que : class_category )\n",
    "'''\n",
    "def unpack_FaqGsheet(db_path, training_set, removeHeader=True):     \n",
    "    start_idx = 1 if removeHeader else 0\n",
    "    ## 1. unpack responses set @ retrieval class_cat : response \n",
    "    gsheet_faq_db = {} \n",
    "    tmp = gsheetRead_GoogleWay( db_path )[start_idx: ] ## ignore header row TODO: refactor at caller to decide\n",
    "    for row in tmp:\n",
    "        if len(row) > 2:\n",
    "            gsheet_faq_db[ row[1] ] = row[2] \n",
    "\n",
    "    ## 2. unpack training set  que : class_cat       \n",
    "    gsheet_faq_training_set_db = {}\n",
    "    tmp = gsheetRead_GoogleWay( training_set )[start_idx: ]\n",
    "    for row in tmp:\n",
    "        if len(row) > 1:\n",
    "            gsheet_faq_training_set_db[ row[0] ] = row[1] \n",
    "\n",
    "    return gsheet_faq_db, gsheet_faq_training_set_db \n",
    "\n",
    "\n",
    "db_pathz = [ ('1EuvcPe9WXSQTsmSqhq0LWJG4xz2ZRQ1FEdnQ_LQ-_Ks', 'FAQ responses!A1:G1000'), ('1EuvcPe9WXSQTsmSqhq0LWJG4xz2ZRQ1FEdnQ_LQ-_Ks', 'Classify_Phrases!A1:G1000')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 91 responses and 141 training input text\n"
     ]
    }
   ],
   "source": [
    "res_path, que_path = db_pathz\n",
    "\n",
    "dict_responses_db, dict_inputs_db = unpack_FaqGsheet( res_path, que_path)\n",
    "\n",
    "print( \"Loaded {} responses and {} training input text\".format(len(dict_responses_db), len(dict_inputs_db)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_category</th>\n",
       "      <th>response_paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pandemic_define</td>\n",
       "      <td>A pandemic is an epidemic (infectious disease ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pandemic_causes</td>\n",
       "      <td>A pandemic can occur when a new virus emerges ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pandemic_WHO</td>\n",
       "      <td>On 11 March WHO declared COVID-19 a pandemic. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pandemic_impact</td>\n",
       "      <td>The health impact of a pandemic on the communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>corana_viruses</td>\n",
       "      <td>Coronaviruses are a large family of viruses. S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class_category                                 response_paragraph\n",
       "0  pandemic_define  A pandemic is an epidemic (infectious disease ...\n",
       "1  pandemic_causes  A pandemic can occur when a new virus emerges ...\n",
       "2     pandemic_WHO  On 11 March WHO declared COVID-19 a pandemic. ...\n",
       "3  pandemic_impact  The health impact of a pandemic on the communi...\n",
       "4   corana_viruses  Coronaviruses are a large family of viruses. S..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make pandas data frame\n",
    "db_faq = pd.DataFrame( dict_responses_db.items() )\n",
    "db_faq.columns = ['class_category', 'response_paragraph']\n",
    "db_faq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>class_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>what is a pandemic?</td>\n",
       "      <td>pandemic_define</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>what causes pandemics?</td>\n",
       "      <td>pandemic_causes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>what does it mean that WHO has declared a pand...</td>\n",
       "      <td>pandemic_WHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Why do pandemics occur?</td>\n",
       "      <td>pandemic_why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>How serious will the impact be?</td>\n",
       "      <td>pandemic_impact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text   class_category\n",
       "0                                what is a pandemic?  pandemic_define\n",
       "1                             what causes pandemics?  pandemic_causes\n",
       "2  what does it mean that WHO has declared a pand...     pandemic_WHO\n",
       "3                            Why do pandemics occur?     pandemic_why\n",
       "4                    How serious will the impact be?  pandemic_impact"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make pandas data frame\n",
    "db_training = pd.DataFrame( dict_inputs_db.items() )\n",
    "db_training.columns = [ 'input_text', 'class_category']\n",
    "db_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean and Tokenize/Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string , re \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brown dog fox jumped lazy over quick the the 23 bone dog had the a surprise this to u wa'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Use nltk english puctuations dict. \n",
    "Replace all punctions with None\n",
    "\n",
    "Input: dataset to be operated on. Must be a list (or array or vector)\n",
    "Output: lower case word tokens after operation \n",
    "'''\n",
    "def wordTokenizeWithoutPunctuations(dataset):\n",
    "    punctuations = dict( (ord(p), None) for p in string.punctuation )\n",
    "    text = dataset if isinstance(dataset, str) else \" \".join(dataset)\n",
    "    return nltk.word_tokenize( text.lower().translate( punctuations) ) \n",
    "\n",
    "'''\n",
    "Use WordNetLemmatizer english dict\n",
    "\n",
    "Input: dataset to be operated on\n",
    "Output: dataset after operation \n",
    "'''\n",
    "def lemmatizeTokens(tokenz ):\n",
    "    lemertizer = nltk.stem.WordNetLemmatizer() \n",
    "    tokenz =  wordTokenizeWithoutPunctuations( tokenz )  \n",
    "    return sorted( [ lemertizer.lemmatize( token )  for token in tokenz ] ) \n",
    "\n",
    "'''\n",
    "Work on paragraphs and \n",
    "Return sentence as opposed to a list of tokens \n",
    "'''\n",
    "def lemmatizeSentences( sentz_list):\n",
    "    result = []\n",
    "    sentz_list = sentz_list if isinstance(sentz_list, list) else nltk.sent_tokenize( sentz_list ) \n",
    "    for sent in sentz_list:\n",
    "        result.extend( lemmatizeTokens(sent) )\n",
    "    return \" \".join(result )\n",
    "\n",
    "lemmatizeSentences( \"The quick brown fox jumped over the lazy dogs. The dog had 23 bones. This was a surprise to us.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>class_category</th>\n",
       "      <th>lemma_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>what is a pandemic?</td>\n",
       "      <td>pandemic_define</td>\n",
       "      <td>a is pandemic what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>what causes pandemics?</td>\n",
       "      <td>pandemic_causes</td>\n",
       "      <td>cause pandemic what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>what does it mean that WHO has declared a pand...</td>\n",
       "      <td>pandemic_WHO</td>\n",
       "      <td>a declared doe ha it mean pandemic that what who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Why do pandemics occur?</td>\n",
       "      <td>pandemic_why</td>\n",
       "      <td>do occur pandemic why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>How serious will the impact be?</td>\n",
       "      <td>pandemic_impact</td>\n",
       "      <td>be how impact serious the will</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text   class_category  \\\n",
       "0                                what is a pandemic?  pandemic_define   \n",
       "1                             what causes pandemics?  pandemic_causes   \n",
       "2  what does it mean that WHO has declared a pand...     pandemic_WHO   \n",
       "3                            Why do pandemics occur?     pandemic_why   \n",
       "4                    How serious will the impact be?  pandemic_impact   \n",
       "\n",
       "                                    lemma_sentences  \n",
       "0                                a is pandemic what  \n",
       "1                               cause pandemic what  \n",
       "2  a declared doe ha it mean pandemic that what who  \n",
       "3                             do occur pandemic why  \n",
       "4                    be how impact serious the will  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1. Tokenize input strings\n",
    "db_training['lemma_sentences'] = db_training.input_text.apply( lambda x: lemmatizeSentences(x) )\n",
    "db_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>class_category</th>\n",
       "      <th>lemma_sentences</th>\n",
       "      <th>14</th>\n",
       "      <th>14 day</th>\n",
       "      <th>14 day doctor</th>\n",
       "      <th>14 day finishing</th>\n",
       "      <th>19</th>\n",
       "      <th>19 corana</th>\n",
       "      <th>19 corana virus</th>\n",
       "      <th>...</th>\n",
       "      <th>visit</th>\n",
       "      <th>warm</th>\n",
       "      <th>warm weather</th>\n",
       "      <th>wash</th>\n",
       "      <th>water</th>\n",
       "      <th>weather</th>\n",
       "      <th>woman</th>\n",
       "      <th>work</th>\n",
       "      <th>worried</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>what is a pandemic?</td>\n",
       "      <td>pandemic_define</td>\n",
       "      <td>a is pandemic what</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>what causes pandemics?</td>\n",
       "      <td>pandemic_causes</td>\n",
       "      <td>cause pandemic what</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 846 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               input_text   class_category      lemma_sentences  14  14 day  \\\n",
       "0     what is a pandemic?  pandemic_define   a is pandemic what   0       0   \n",
       "1  what causes pandemics?  pandemic_causes  cause pandemic what   0       0   \n",
       "\n",
       "   14 day doctor  14 day finishing  19  19 corana  19 corana virus  ...  \\\n",
       "0              0                 0   0          0                0  ...   \n",
       "1              0                 0   0          0                0  ...   \n",
       "\n",
       "   visit  warm  warm weather  wash  water  weather  woman  work  worried  \\\n",
       "0      0     0             0     0      0        0      0     0        0   \n",
       "1      0     0             0     0      0        0      0     0        0   \n",
       "\n",
       "   young  \n",
       "0      0  \n",
       "1      0  \n",
       "\n",
       "[2 rows x 846 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Vectorize tokenized input strings\n",
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "cv_out = count_vectorizer.fit_transform( db_training.lemma_sentences ) \n",
    "# print( count_vectorizer.get_feature_names() )\n",
    "cv_out\n",
    "\n",
    "db_training = db_training.join( pd.DataFrame( \n",
    "        cv_out.toarray(), \n",
    "        columns=count_vectorizer.get_feature_names(), index=db_training.index\n",
    "        ) )\n",
    "\n",
    "db_training.to_csv('training_matrix.csv')\n",
    "\n",
    "db_training.head(2)\n",
    "\n",
    "## TODO: min_df and max_df=1 to remove terms that appear too (in)frequently << corpus specific stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(count_vectorizer, open('count_vectorizer.pkl', 'wb') )\n",
    "db_faq.to_pickle( 'faq_responses.pkl' )\n",
    "db_training.to_pickle( 'training_set.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploration (EDA)\n",
    "Seek apparent patterns and areas for further cleaning/preprocessing\n",
    "\n",
    "- Most commond words; threshold to add them to the stopwords and update the CV_matrix\n",
    "- Vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "covid19         36\n",
       "virus           27\n",
       "risk            10\n",
       "doe              9\n",
       "child            9\n",
       "spread           8\n",
       "sanitizer        8\n",
       "hand             7\n",
       "safe             6\n",
       "pet              6\n",
       "tested           6\n",
       "im               6\n",
       "people           6\n",
       "infected         6\n",
       "corana           6\n",
       "school           6\n",
       "protect          6\n",
       "use              6\n",
       "infection        5\n",
       "covid19 doe      5\n",
       "home             5\n",
       "long             5\n",
       "spread virus     4\n",
       "family           4\n",
       "isolate          4\n",
       "test             4\n",
       "make             4\n",
       "self             4\n",
       "isolation        4\n",
       "person           4\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter # has common_words \n",
    "\n",
    "dftmp = pd.DataFrame( db_training.iloc[:, 3:].sum() ) \n",
    "# print( list(dftmp.index )  )\n",
    "dftmp.head()\n",
    "dftmp[0].sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('virus', 3), ('corana', 2), ('ncov19 virus', 1), ('ncov19', 1), ('covid19 virus', 1), ('19', 1), ('19 corana', 1), ('19 corana virus', 1), ('rona', 1), ('corana virus', 1), ('covid19', 1), ('diy okay', 0), ('diy', 0), ('young', 0), ('distancing social', 0), ('doctor', 0), ('doctor finishing', 0), ('doctor finishing isolation', 0), ('doctor im', 0), ('diy okay sanitizer', 0), ('distancing practice', 0), ('distancing practice social', 0), ('doe', 0), ('distancing', 0), ('disability higher people', 0), ('disability higher', 0), ('disability', 0), ('different symptom', 0), ('different', 0), ('difference flu virus', 0)]\n"
     ]
    }
   ],
   "source": [
    "## get top 30 words for each category\n",
    "top_dict = {}\n",
    "words = []\n",
    "class_cats = db_training.class_category.unique()\n",
    "\n",
    "for class_cat in class_cats:\n",
    "    dftmp =  pd.DataFrame( db_training[ db_training.class_category == class_cat ].iloc[:, 3:].sum())\n",
    "    top = dftmp[0].sort_values(ascending=False).head(30)     \n",
    "    top_dict[ \"{}\".format(class_cat) ] = list(zip(top.index, top.values) ) #[  ]\n",
    "        \n",
    "print( top_dict['covid19_define'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandemic_define \tpandemic, young, distancing practice social, doe ha, doe, doctor im speak, doctor im, doctor finishing isolation, doctor finishing, doctor\n",
      "pandemic_causes \tpandemic, cause pandemic, cause, young, diy, doe ha mean, doe ha, doe, doctor im speak, doctor im\n",
      "pandemic_WHO \tdeclared doe, ha mean, mean pandemic, doe, doe ha, doe ha mean, ha mean pandemic, ha, declared doe ha, declared\n",
      "pandemic_why \toccur, pandemic, occur pandemic, young, distancing social, doe, doctor im speak, doctor im, doctor finishing isolation, doctor finishing\n",
      "pandemic_impact \timpact, young, distancing social, doe ha, doe, doctor im speak, doctor im, doctor finishing isolation, doctor finishing, doctor\n",
      "corana_viruses \tcorona virus, corona, virus, young, distancing social, doe, doctor im speak, doctor im, doctor finishing isolation, doctor finishing\n",
      "covid19_define \tvirus, corana, ncov19 virus, ncov19, covid19 virus, 19, 19 corana, 19 corana virus, rona, corana virus\n",
      "covid19_spread \tspread, spread virus, covid19, doe spread, doe spread virus, covid19 doe, virus, doe, covid19 doe spread, disability\n",
      "covid19_surfaces_last \tvirus, doe, long, doe long, survive, doe long surface, long surface virus, long surfeaces, object, object virus\n",
      "covid19_symptoms \tcovid19, infected, virus, infected tell, covid19 im infected, im infected tell, covid19 symptom, tell virus, covid19 know virus, covid19 know\n",
      "covid19_Vs_flu \tflu, difference, virus, difference flu, flu virus, corana, covid19 difference flu, corana flu, corana difference flu, corana difference\n",
      "covid19_traveller_axn \tcountry travelled, country, travelled, diy, doe ha, doe, doctor im speak, doctor im, doctor finishing isolation, doctor finishing\n",
      "covid19_gatherings \tevent gathering, gathering public, gathering, avoid event gathering, avoid event, public, avoid, event, event gathering public, attending avoid event\n",
      "covid19_sickness_duration \tlong, doe, doe infection, doe infection long, infection long, infection, covid19 doe infection, long sick, covid19, corana doe infection\n",
      "covid19_diagnosis \tdiagnosed, temperature, cough, high temperature, high, covid19, covid19 diagnosed, doctor im speak, doctor im, doctor finishing isolation\n",
      "covid19_negative_test_implication \tmean negative result, covid19 doe, negative result, negative result test, doe, result, result test, test, covid19, doe mean\n",
      "covid19_contact_infected \tcome, come contact, contact, covid19, contanct corana infected, come contact covid19, shoudl, shoudl virus, come contanct, come contanct corana\n",
      "covid19_contact_potential \tperson, come contact, come, contact, ha, ha identified person, identified person, come contact ha, infected, ha incontact infected\n",
      "covid19_at_risk \trisk, people risk, people, old, le people risk, le people, le, people risk young, child, young\n",
      "covid19_pregnant \tpregnant, pregnant worried, woman, im pregnant worried, im, pregnant risk, worried, risk woman, risk, pregnant risk woman\n",
      "covid19_prevention \tcovid19, infection, prevented, infection prevent, covid19 infection prevent, covid19 infection, prevent, covid19 prevented, disability higher people, different\n",
      "covid19_cure \tcure, cure vaccine, vaccine, distancing social, doe ha, doe, doctor im speak, doctor im, doctor finishing isolation, doctor finishing\n",
      "covid19_see_doc_proc \tdoctor, doctor im speak, hospital, doctor im, im, im speak, speak unable, speak, im speak unable, unable\n",
      "covid19_testing \tcovid19, kit, kit self, self test, covid19 tested, self, covid19 kit, used, kit self test, self test used\n",
      "covid19_airport_screening \tpeople place, airport arrangement, checking, people place screening, people, checking people, checking people place, screening, arrangement checking people, airport\n",
      "covid19_seaport_screening \tpeople place, arrangement checking people, people place screening, people, checking, checking people, seaport, screening seaport, screening, checking people place\n",
      "covid19_public_health \tpublic response, covid19 healht, covid19, healht, healht public, healht public response, covid19 healht public, public, response, doctor\n",
      "covid19_self_protect \tsafe stay, safe, protect, stay, practice, observe practice, observe, family, practice safe, adhere observe practice\n",
      "covid19_handwashing \thand, wash, dont, dont hand, sanitizer, sanitizer wash, hand handwash, hand handwash sanitizer, soap, hand ordinary\n",
      "covid19_facemasks \tface, mask, face mask, use, mask use, face mask use, mask recommended, face infection mask, asymptomatic, covid19\n",
      "covid19_heat \tcovid19, prevent, heat prevent, hand prevent, covid19 doe, covid19 doe heat, doe heat prevent, heat, doe, dryer hand prevent\n",
      "covid19_public_water \tdrinking, use water, safe, drinking public, drinking public safe, public safe use, public safe, public, safe use water, use\n",
      "covid19_cleaning_surfaces \tfurniture hospital protect, virus, furniture hospital, cleaned equipment furniture, cleaned equipment, cleaned, hospital protect virus, hospital, equipment furniture hospital, equipment furniture\n",
      "covid19_hospital_visits_if_cases \tcase covid19, covid19 hostpital, case covid19 hostpital, covid19, hostpital safe, hostpital, covid19 hostpital safe, case, safe, disability higher people\n",
      "covid19_healed \tinfectious know, virus, people virus, infectious, know nolonger people, people, know nolonger, know, nolonger people virus, nolonger people\n",
      "covid19_chemist \tmedicine, medicine purchasing, purchasing, limit medicine purchasing, limit medicine, limit, young, distancing social, doctor im, doctor finishing isolation\n",
      "covid19_swimming \tpool, swim, thats, pool swim thats, ocean pool, ocean pool swim, swimming, swim thats, ocean, pool swim\n",
      "covid19_travel \tholiday, cancel holiday travel, travel trip work, travel trip, travel, cancel, trip work, cancel holiday, holiday travel trip, holiday travel\n",
      "covid19_school \tschool, child, child school, young, diy okay, doe heat, doe ha mean, doe ha, doe, doctor im speak\n",
      "covid19_snr_home \telderly facility, child, care child, care, facility senior visit, senior visit, senior, facility senior, facility, care child elderly\n",
      "self_isolation_traveller \tive need returned, home, returned trip, isolate ive need, isolate ive, returned, home isolate ive, home isolate, isolate, need\n",
      "covid19_testing_when \thaving im, im, having, having im tested, im tested virus, virus, virus worried, worried, tested, tested virus\n",
      "self_isolation_at_home \tisolate, self, home, home isolate, isolating need, home isolate self, need pople self, need pople, need, isolate isolating\n",
      "self_isolation_of_family \thouse isolate overseas, self selfisolating travel, self selfisolating, self, isolate, selfisolating, house, isolate overseas, isolate overseas recently, house isolate\n",
      "self_isolation_access_groceries \tgrocery home, home isolation, medicine, isolation, isolation medicine, grocery home isolation, home, access, access grocery, access grocery home\n",
      "self_isolation_after_14_days \t14, isolation, 14 day, day, finishing isolation, finishing, day finishing isolation, day finishing, day doctor finishing, day doctor\n",
      "isolation_trauma \tisolation traumatized, going im, im, corona going im, corona going, corona, im stressed, im stressed stuff, going im stressed, going\n",
      "social_distancing_define \tdistancing social, social, distancing, diy, doe ha, doe, doctor im speak, doctor im, doctor finishing isolation, doctor finishing\n",
      "social_distancing_for_who \tdistancing practice social, social, practice, distancing, distancing practice, practice social, diy, doctor im speak, doctor im, doctor finishing isolation\n",
      "social_distancing_gym \tsafe, gym, gym safe, young, distancing practice, doctor im speak, doctor im, doctor finishing isolation, doctor finishing, doctor\n",
      "prepare_bulk_buy \tprepare, item prepare, item, bulkbuy item prepare, bulkbuy item, bulkbuy, diy okay, doe ha, doe, doctor im speak\n",
      "pets_infection \tpet virus, infected, infected pet, infected pet virus, virus, pet, young, distancing social, doctor im speak, doctor im\n",
      "more_infor \tinformation, doe heat, doe ha mean, doe ha, doe, doctor im speak, doctor im, doctor finishing isolation, doctor finishing, doctor\n",
      "covid19_source \tcovid19 source, covid19 source virus, covid19, virus, source, source virus, young, diy okay, doe, doctor im speak\n",
      "covid19_spread_cdc \tspread, doe, spread virus, covid19 spread, virus, covid19, doe spread, doe spread virus, diy, doctor im speak\n",
      "covid19_spread_cases_rise \trise seeing, case, case rise, seeing, case rise seeing, rise, young, doe heat, doe ha mean, doe ha\n",
      "covid19_spread_priors \tillness spread, covid19 ha illness, covid19, ha illness, ha illness spread, spread, ha, covid19 ha, illness, doctor im\n",
      "covid19_quarantine \tquanrantine spread, quanrantine spread virus, person, person quanrantine, person quanrantine spread, spread, quanrantine, spread virus, virus, distancing practice social\n",
      "covid19_spread_foods \tfood, including refrigerated spread, virus, refrigerated, refrigerated spread, refrigerated spread virus, food food, food food frozen, food frozen, spread\n",
      "covid19_spread_warm_weather \toutbreak stop, outbreak stop warm, warm, warm weather, stop warm, stop, weather, outbreak, stop warm weather, distancing\n",
      "covid19_community_spread \tcommunity, community spread, spread, young, diy, doe, doctor im speak, doctor im, doctor finishing isolation, doctor finishing\n",
      "covid19_temp_kill \ttemperature virus, virus, covid19, kill, kill temperature, kill temperature virus, covid19 kill, covid19 kill temperature, temperature, diy\n",
      "covid19_spread_insects \tcockroach covid19 infect, mosquito, insect mite, insect, cockroach, cockroach covid19, tick virus, tick, bedbug, mosquito spread tick\n",
      "covid19_spread_shipment \tarea, china, package, live product shipped, import stuff, shipping, live, continue, continue import, continue import stuff\n",
      "blood_donate \tdonate, blood donate, blood, young, diy, doe ha, doe, doctor im speak, doctor im, doctor finishing isolation\n",
      "covid19_at_risk_kids \tchild covid19, child, covid19 risk, covid19 risk sick, covid19, risk sick, risk, sick, child covid19 risk, doctor finishing\n",
      "child_protect \tprotect, child, child protect, young, distancing social, doe ha, doe, doctor im speak, doctor im, doctor finishing isolation\n",
      "symptoms_diff_child \tchild covid19 different, child, covid19, covid19 different, covid19 different symptom, adult child covid19, adult child, symptom, adult, different\n",
      "testing_who \ttested, need tested, need, young, distancing practice social, doctor im speak, doctor im, doctor finishing isolation, doctor finishing, doctor\n",
      "testing_negative \ttest, negative positive test, later, negative, positive, positive test, positive test test, test test, later negative positive, later negative\n",
      "dead_infectious \ttheyve touch virus, covid19 died passed, away covid19, away, died, died passed, died passed risk, theyve, theyve touch, touch\n",
      "pets_infection_cdc \tpet, cat dog, dog, cat, animal, covid19 pet, covid19, pet sick, animal covid19, cat dog make\n",
      "pets_testing \tcovid19 dog, dog, tested, pet shoul tested, pet shoul, pet, cat, covid19, cat covid19, shoul tested\n",
      "pets_carrier_skin \tcovid19 fur, virus, carry covid19 fur, animal carry, animal carry covid19, carry covid19, carry, covid19, skin, skin virus\n",
      "pets_isolation \tanimal avoid, avoid, animal, pet virus, im, im infected, pet, im infected pet, contact, contact im\n",
      "school_out_hanging \tchild friend, hang shool, behave, behave closed, behave closed school, friend hang shool, friend hang, friend, shool, closed school\n",
      "school_out_learning \tcontinue, help, learning, learning shool, shool, child, child continue, continue help learning, help learning, help learning shool\n",
      "school_out_meals \tschool, meal school, meal, kid, kid meal, school school, kid meal school, access, access kid, access kid meal\n",
      "school_out_healthy \tschool, healthy school, family healthy, family, healthy, family healthy school, different symptom, disability, difference, doe ha mean\n",
      "school_out_relatives \tadult chronically ill, chronically ill including, relative school, relative school time, limit older relative, limit, adult chronically, limit older, school time, adult\n",
      "covid19_at_risk_disability \thigher people, disability, risk, disability higher people, people, disability higher, people risk, higher people risk, higher, difference flu virus\n",
      "covid19_at_risk_cdc \thigher illness risk, risk, illness risk, illness, higher, higher illness, distancing practice social, doe, doctor im speak, doctor im\n",
      "outbreak_axn \tcommunity outbreak, outbreak, community, distancing social, doe ha, doe, doctor im speak, doctor im, doctor finishing isolation, doctor finishing\n",
      "outbreak_kids \toutbreak prepare, child community covid19, community, covid19 outbreak, prepare, covid19, covid19 outbreak prepare, child, community covid19, child community\n",
      "prepare_home \tcovid19 family, family prepare, family, covid19, prepare, covid19 family prepare, difference flu virus, different, doe ha, doe\n",
      "covid19_spread_family_axn \tfamily, getting, covid19, family getting, reduce, risk, reduce risk, getting reduce risk, risk step, getting reduce\n",
      "covid19_home_infection \tsick, house sick, covid19, covid19 house, covid19 house sick, house, diy okay, doe ha mean, doe ha, doe\n",
      "soap_vs_sanitizer \tsanitizer soap use, use water, hand sanitizer, hand sanitizer soap, soap, soap use, soap use water, use, hand, water\n",
      "sanitizer_diy \tsanitizer, make sanitizer, make, hand make sanitizer, hand, hand make, sanitizer work, home sanitizer, diy okay sanitizer, diy okay\n",
      "cleaning_products \tproduct, use, product protect use, product protect, covid19 product protect, covid19 product, protect, agains cleaning covid19, agains cleaning, agains\n"
     ]
    }
   ],
   "source": [
    " ## Visualize top 10 words per category\n",
    "for class_cat, top_words in top_dict.items():\n",
    "    print( \"{} \\t{}\".format(class_cat, \", \".join([ w for w, c in top_words[0:10]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pandemic', 'young', 'distancing practice social']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add most common words to stop_words\n",
    "words = []\n",
    "for class_cat in top_dict.keys():\n",
    "    top = [ w for (w, c) in top_dict[class_cat] ]\n",
    "    for t in top:\n",
    "        words.append( t )\n",
    "\n",
    "words[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('diy', 81),\n",
       " ('doctor', 80),\n",
       " ('diy okay', 80),\n",
       " ('distancing practice', 79),\n",
       " ('doctor finishing', 77),\n",
       " ('diy okay sanitizer', 77),\n",
       " ('distancing', 76),\n",
       " ('distancing practice social', 74),\n",
       " ('distancing social', 74),\n",
       " ('doctor finishing isolation', 72),\n",
       " ('disability higher people', 72),\n",
       " ('disability higher', 72),\n",
       " ('disability', 70),\n",
       " ('different symptom', 67),\n",
       " ('doctor im', 64),\n",
       " ('different', 61),\n",
       " ('doe', 57),\n",
       " ('doctor im speak', 56),\n",
       " ('difference flu virus', 50),\n",
       " ('difference flu', 46),\n",
       " ('doe ha', 45),\n",
       " ('young', 44),\n",
       " ('doe ha mean', 36),\n",
       " ('difference', 31),\n",
       " ('covid19', 31),\n",
       " ('doe heat', 28),\n",
       " ('doe heat prevent', 24),\n",
       " ('died passed risk', 22),\n",
       " ('virus', 20),\n",
       " ('doe infection', 12),\n",
       " ('died passed', 10),\n",
       " ('child', 9),\n",
       " ('risk', 8),\n",
       " ('spread', 7),\n",
       " ('died', 6),\n",
       " ('dog make', 6),\n",
       " ('im', 6),\n",
       " ('covid19 doe', 5),\n",
       " ('infected', 5),\n",
       " ('people', 5),\n",
       " ('protect', 5),\n",
       " ('use', 5),\n",
       " ('school', 5),\n",
       " ('pandemic', 4),\n",
       " ('drinking public safe', 4),\n",
       " ('corana', 4),\n",
       " ('spread virus', 4),\n",
       " ('sick', 4),\n",
       " ('dog', 4),\n",
       " ('tested', 4),\n",
       " ('safe', 4),\n",
       " ('family', 4),\n",
       " ('hand', 4),\n",
       " ('dont hand', 4),\n",
       " ('dryer hand', 4),\n",
       " ('drinking', 4),\n",
       " ('drinking public', 4),\n",
       " ('home', 4),\n",
       " ('pet', 4),\n",
       " ('doe infection long', 3),\n",
       " ('ha', 3),\n",
       " ('public', 3),\n",
       " ('infection', 3),\n",
       " ('test', 3),\n",
       " ('doe mean', 3),\n",
       " ('contact', 3),\n",
       " ('person', 3),\n",
       " ('dog infect', 3),\n",
       " ('worried', 3),\n",
       " ('self', 3),\n",
       " ('dont', 3),\n",
       " ('sanitizer', 3),\n",
       " ('dont hand sanitizer', 3),\n",
       " ('dont hand handwash', 3),\n",
       " ('case', 3),\n",
       " ('isolate', 3),\n",
       " ('need', 3),\n",
       " ('isolation', 3),\n",
       " ('dog make pet', 3),\n",
       " ('prepare', 3),\n",
       " ('outbreak', 3),\n",
       " ('community', 3),\n",
       " ('animal', 3),\n",
       " ('mean', 2),\n",
       " ('corona', 2),\n",
       " ('doe spread', 2),\n",
       " ('doe spread virus', 2),\n",
       " ('long', 2),\n",
       " ('doe long', 2),\n",
       " ('live', 2),\n",
       " ('symptom', 2),\n",
       " ('im infected', 2),\n",
       " ('know', 2),\n",
       " ('country', 2),\n",
       " ('avoid', 2),\n",
       " ('diagnosed', 2),\n",
       " ('temperature', 2),\n",
       " ('doe mean negative', 2),\n",
       " ('negative', 2),\n",
       " ('come', 2),\n",
       " ('come contact', 2),\n",
       " ('contanct', 2),\n",
       " ('dog infect pet', 2),\n",
       " ('people risk', 2),\n",
       " ('prevent', 2),\n",
       " ('hospital', 2),\n",
       " ('covid19 kit', 2),\n",
       " ('people place', 2),\n",
       " ('checking', 2),\n",
       " ('people place screening', 2),\n",
       " ('checking people', 2),\n",
       " ('checking people place', 2),\n",
       " ('screening', 2),\n",
       " ('arrangement checking people', 2),\n",
       " ('arrangement checking', 2),\n",
       " ('arrangement', 2),\n",
       " ('place', 2),\n",
       " ('place screening', 2),\n",
       " ('covid19 healht', 2),\n",
       " ('covid19 healht public', 2),\n",
       " ('practice', 2),\n",
       " ('soap', 2),\n",
       " ('soap use', 2),\n",
       " ('hand sanitizer', 2),\n",
       " ('dryer', 2),\n",
       " ('use water', 2),\n",
       " ('water', 2),\n",
       " ('medicine', 2),\n",
       " ('limit', 2),\n",
       " ('travel', 2),\n",
       " ('work', 2),\n",
       " ('trip', 2),\n",
       " ('returned', 2),\n",
       " ('home isolate', 2),\n",
       " ('house', 2),\n",
       " ('access', 2),\n",
       " ('stuff', 2),\n",
       " ('social', 2),\n",
       " ('pet virus', 2),\n",
       " ('infected pet', 2),\n",
       " ('infected pet virus', 2),\n",
       " ('illness', 2),\n",
       " ('including', 2),\n",
       " ('infect', 2),\n",
       " ('continue', 2),\n",
       " ('product', 2),\n",
       " ('child covid19', 2),\n",
       " ('adult', 2),\n",
       " ('cat', 2),\n",
       " ('make', 2),\n",
       " ('shool', 2),\n",
       " ('higher', 2),\n",
       " ('covid19 family', 2),\n",
       " ('cause pandemic', 1),\n",
       " ('cause', 1),\n",
       " ('declared doe', 1),\n",
       " ('ha mean', 1),\n",
       " ('mean pandemic', 1),\n",
       " ('ha mean pandemic', 1),\n",
       " ('declared doe ha', 1),\n",
       " ('declared', 1),\n",
       " ('occur', 1),\n",
       " ('occur pandemic', 1),\n",
       " ('impact', 1),\n",
       " ('corona virus', 1),\n",
       " ('ncov19 virus', 1),\n",
       " ('ncov19', 1),\n",
       " ('covid19 virus', 1),\n",
       " ('19', 1),\n",
       " ('19 corana', 1),\n",
       " ('19 corana virus', 1),\n",
       " ('rona', 1),\n",
       " ('corana virus', 1),\n",
       " ('covid19 doe spread', 1),\n",
       " ('survive', 1),\n",
       " ('doe long surface', 1),\n",
       " ('long surface virus', 1),\n",
       " ('long surfeaces', 1),\n",
       " ('object', 1),\n",
       " ('object virus', 1),\n",
       " ('long surfeaces survive', 1),\n",
       " ('survive virus', 1),\n",
       " ('surfeaces survive virus', 1),\n",
       " ('doe long surfeaces', 1),\n",
       " ('surfeaces survive', 1),\n",
       " ('surfeaces', 1),\n",
       " ('covid19 doe long', 1),\n",
       " ('surface virus', 1),\n",
       " ('surface', 1),\n",
       " ('live object virus', 1),\n",
       " ('live object', 1),\n",
       " ('long surface', 1),\n",
       " ('infected tell', 1),\n",
       " ('covid19 im infected', 1),\n",
       " ('im infected tell', 1),\n",
       " ('covid19 symptom', 1),\n",
       " ('tell virus', 1),\n",
       " ('covid19 know virus', 1),\n",
       " ('covid19 know', 1),\n",
       " ('tell', 1),\n",
       " ('infected tell virus', 1),\n",
       " ('know virus', 1),\n",
       " ('covid19 im', 1),\n",
       " ('flu', 1),\n",
       " ('flu virus', 1),\n",
       " ('covid19 difference flu', 1),\n",
       " ('corana flu', 1),\n",
       " ('corana difference flu', 1),\n",
       " ('corana difference', 1),\n",
       " ('corana flu virus', 1),\n",
       " ('covid19 difference', 1),\n",
       " ('country travelled', 1),\n",
       " ('travelled', 1),\n",
       " ('event gathering', 1),\n",
       " ('gathering public', 1),\n",
       " ('gathering', 1),\n",
       " ('avoid event gathering', 1),\n",
       " ('avoid event', 1),\n",
       " ('event', 1),\n",
       " ('event gathering public', 1),\n",
       " ('attending avoid event', 1),\n",
       " ('attending avoid', 1),\n",
       " ('attending', 1),\n",
       " ('infection long', 1),\n",
       " ('covid19 doe infection', 1),\n",
       " ('long sick', 1),\n",
       " ('corana doe infection', 1),\n",
       " ('corana doe', 1),\n",
       " ('cough', 1),\n",
       " ('high temperature', 1),\n",
       " ('high', 1),\n",
       " ('covid19 diagnosed', 1),\n",
       " ('mean negative result', 1),\n",
       " ('negative result', 1),\n",
       " ('negative result test', 1),\n",
       " ('result', 1),\n",
       " ('result test', 1),\n",
       " ('covid19 doe mean', 1),\n",
       " ('mean negative', 1),\n",
       " ('contanct corana infected', 1),\n",
       " ('come contact covid19', 1),\n",
       " ('shoudl', 1),\n",
       " ('shoudl virus', 1),\n",
       " ('come contanct', 1),\n",
       " ('come contanct corana', 1),\n",
       " ('corana infected shoudl', 1),\n",
       " ('covid19 person', 1),\n",
       " ('corana infected', 1),\n",
       " ('contact covid19', 1),\n",
       " ('contact covid19 person', 1),\n",
       " ('infected shoudl virus', 1),\n",
       " ('infected shoudl', 1),\n",
       " ('contanct corana', 1),\n",
       " ('ha identified person', 1),\n",
       " ('identified person', 1),\n",
       " ('come contact ha', 1),\n",
       " ('ha incontact infected', 1),\n",
       " ('ha incontact', 1),\n",
       " ('contact contanct', 1),\n",
       " ('incontact infected', 1),\n",
       " ('identified', 1),\n",
       " ('contact contanct ha', 1),\n",
       " ('contact ha', 1),\n",
       " ('contact ha incontact', 1),\n",
       " ('contanct ha', 1),\n",
       " ('contanct ha identified', 1),\n",
       " ('incontact', 1),\n",
       " ('incontact infected person', 1),\n",
       " ('ha identified', 1),\n",
       " ('infected person', 1),\n",
       " ('come contact contanct', 1),\n",
       " ('old', 1),\n",
       " ('le people risk', 1),\n",
       " ('le people', 1),\n",
       " ('le', 1),\n",
       " ('people risk young', 1),\n",
       " ('old people', 1),\n",
       " ('risk young', 1),\n",
       " ('child le', 1),\n",
       " ('child le people', 1),\n",
       " ('old people risk', 1),\n",
       " ('pregnant', 1),\n",
       " ('pregnant worried', 1),\n",
       " ('woman', 1),\n",
       " ('im pregnant worried', 1),\n",
       " ('pregnant risk', 1),\n",
       " ('risk woman', 1),\n",
       " ('pregnant risk woman', 1),\n",
       " ('im pregnant', 1),\n",
       " ('prevented', 1),\n",
       " ('infection prevent', 1),\n",
       " ('covid19 infection prevent', 1),\n",
       " ('covid19 infection', 1),\n",
       " ('covid19 prevented', 1),\n",
       " ('cure', 1),\n",
       " ('cure vaccine', 1),\n",
       " ('vaccine', 1),\n",
       " ('im speak', 1),\n",
       " ('speak unable', 1),\n",
       " ('speak', 1),\n",
       " ('im speak unable', 1),\n",
       " ('unable', 1),\n",
       " ('kit', 1),\n",
       " ('kit self', 1),\n",
       " ('self test', 1),\n",
       " ('covid19 tested', 1),\n",
       " ('used', 1),\n",
       " ('kit self test', 1),\n",
       " ('self test used', 1),\n",
       " ('covid19 kit self', 1),\n",
       " ('test used', 1),\n",
       " ('airport arrangement', 1),\n",
       " ('airport', 1),\n",
       " ('airport arrangement checking', 1),\n",
       " ('border', 1),\n",
       " ('seaport', 1),\n",
       " ('screening seaport', 1),\n",
       " ('place screening seaport', 1),\n",
       " ('public response', 1),\n",
       " ('healht', 1),\n",
       " ('healht public', 1),\n",
       " ('healht public response', 1),\n",
       " ('response', 1),\n",
       " ('safe stay', 1),\n",
       " ('stay', 1),\n",
       " ('observe practice', 1),\n",
       " ('observe', 1),\n",
       " ('practice safe', 1),\n",
       " ('adhere observe practice', 1),\n",
       " ('adhere observe', 1),\n",
       " ('adhere', 1),\n",
       " ('practice safe stay', 1),\n",
       " ('observe practice safe', 1),\n",
       " ('family protect', 1),\n",
       " ('wash', 1),\n",
       " ('sanitizer wash', 1),\n",
       " ('hand handwash', 1),\n",
       " ('hand handwash sanitizer', 1),\n",
       " ('hand ordinary', 1),\n",
       " ('hand ordinary soap', 1),\n",
       " ('soap use wash', 1),\n",
       " ('handwash sanitizer', 1),\n",
       " ('handwash sanitizer wash', 1),\n",
       " ('handwash', 1),\n",
       " ('use wash', 1),\n",
       " ('ordinary', 1),\n",
       " ('ordinary soap', 1),\n",
       " ('ordinary soap use', 1),\n",
       " ('face', 1),\n",
       " ('mask', 1),\n",
       " ('face mask', 1),\n",
       " ('mask use', 1),\n",
       " ('face mask use', 1),\n",
       " ('mask recommended', 1),\n",
       " ('face infection mask', 1),\n",
       " ('asymptomatic', 1),\n",
       " ('face infection', 1),\n",
       " ('face mask recommended', 1),\n",
       " ('recommended type', 1),\n",
       " ('mask protect', 1),\n",
       " ('recommended', 1),\n",
       " ('infection mask', 1),\n",
       " ('asymptomatic face', 1),\n",
       " ('asymptomatic face mask', 1),\n",
       " ('type', 1),\n",
       " ('mask recommended type', 1),\n",
       " ('covid19 face infection', 1),\n",
       " ('covid19 face', 1),\n",
       " ('infection mask protect', 1),\n",
       " ('heat prevent', 1),\n",
       " ('hand prevent', 1),\n",
       " ('covid19 doe heat', 1),\n",
       " ('heat', 1),\n",
       " ('dryer hand prevent', 1),\n",
       " ('covid19 dryer', 1),\n",
       " ('covid19 dryer hand', 1),\n",
       " ('public safe use', 1),\n",
       " ('public safe', 1),\n",
       " ('safe use water', 1),\n",
       " ('safe use', 1),\n",
       " ('furniture hospital protect', 1),\n",
       " ('furniture hospital', 1),\n",
       " ('cleaned equipment furniture', 1),\n",
       " ('cleaned equipment', 1),\n",
       " ('cleaned', 1),\n",
       " ('hospital protect virus', 1),\n",
       " ('equipment furniture hospital', 1),\n",
       " ('equipment furniture', 1),\n",
       " ('equipment', 1),\n",
       " ('hospital protect', 1),\n",
       " ('protect virus', 1),\n",
       " ('furniture', 1),\n",
       " ('case covid19', 1),\n",
       " ('covid19 hostpital', 1),\n",
       " ('case covid19 hostpital', 1),\n",
       " ('hostpital safe', 1),\n",
       " ('hostpital', 1),\n",
       " ('covid19 hostpital safe', 1),\n",
       " ('infectious know', 1),\n",
       " ('people virus', 1),\n",
       " ('infectious', 1),\n",
       " ('know nolonger people', 1),\n",
       " ('know nolonger', 1),\n",
       " ('nolonger people virus', 1),\n",
       " ('nolonger people', 1),\n",
       " ('nolonger', 1),\n",
       " ('infectious know nolonger', 1),\n",
       " ('medicine purchasing', 1),\n",
       " ('purchasing', 1),\n",
       " ('limit medicine purchasing', 1),\n",
       " ('limit medicine', 1),\n",
       " ('pool', 1),\n",
       " ('swim', 1),\n",
       " ('thats', 1),\n",
       " ('pool swim thats', 1),\n",
       " ('ocean pool', 1),\n",
       " ('ocean pool swim', 1),\n",
       " ('swimming', 1),\n",
       " ('swim thats', 1),\n",
       " ('ocean', 1),\n",
       " ('pool swim', 1),\n",
       " ('holiday', 1),\n",
       " ('cancel holiday travel', 1),\n",
       " ('travel trip work', 1),\n",
       " ('travel trip', 1),\n",
       " ('cancel', 1),\n",
       " ('trip work', 1),\n",
       " ('cancel holiday', 1),\n",
       " ('holiday travel trip', 1),\n",
       " ('holiday travel', 1),\n",
       " ('child school', 1),\n",
       " ('elderly facility', 1),\n",
       " ('care child', 1),\n",
       " ('care', 1),\n",
       " ('facility senior visit', 1),\n",
       " ('senior visit', 1),\n",
       " ('senior', 1),\n",
       " ('facility senior', 1),\n",
       " ('facility', 1),\n",
       " ('care child elderly', 1),\n",
       " ('elderly facility senior', 1),\n",
       " ('visit', 1),\n",
       " ('child elderly facility', 1),\n",
       " ('child elderly', 1),\n",
       " ('elderly', 1),\n",
       " ('ive need returned', 1),\n",
       " ('returned trip', 1),\n",
       " ('isolate ive need', 1),\n",
       " ('isolate ive', 1),\n",
       " ('home isolate ive', 1),\n",
       " ('need returned', 1),\n",
       " ('need returned trip', 1),\n",
       " ('ive', 1),\n",
       " ('ive need', 1),\n",
       " ('having im', 1),\n",
       " ('having', 1),\n",
       " ('having im tested', 1),\n",
       " ('im tested virus', 1),\n",
       " ('virus worried', 1),\n",
       " ('tested virus', 1),\n",
       " ('tested virus worried', 1),\n",
       " ('im tested', 1),\n",
       " ('isolating need', 1),\n",
       " ('home isolate self', 1),\n",
       " ('need pople self', 1),\n",
       " ('need pople', 1),\n",
       " ('isolate isolating', 1),\n",
       " ('isolate isolating need', 1),\n",
       " ('isolate self', 1),\n",
       " ('isolating', 1),\n",
       " ('pople', 1),\n",
       " ('isolating need pople', 1),\n",
       " ('pople self', 1),\n",
       " ('home isolate isolating', 1),\n",
       " ('house isolate overseas', 1),\n",
       " ('self selfisolating travel', 1),\n",
       " ('self selfisolating', 1),\n",
       " ('selfisolating', 1),\n",
       " ('isolate overseas', 1),\n",
       " ('isolate overseas recently', 1),\n",
       " ('house isolate', 1),\n",
       " ('returned self', 1),\n",
       " ('returned self selfisolating', 1),\n",
       " ('overseas recently returned', 1),\n",
       " ('overseas recently', 1),\n",
       " ('overseas', 1),\n",
       " ('selfisolating travel', 1),\n",
       " ('recently', 1),\n",
       " ('recently returned', 1),\n",
       " ('recently returned self', 1),\n",
       " ('grocery home', 1),\n",
       " ('home isolation', 1),\n",
       " ('isolation medicine', 1),\n",
       " ('grocery home isolation', 1),\n",
       " ('access grocery', 1),\n",
       " ('access grocery home', 1),\n",
       " ('grocery', 1),\n",
       " ('home isolation medicine', 1),\n",
       " ('14', 1),\n",
       " ('14 day', 1),\n",
       " ('day', 1),\n",
       " ('finishing isolation', 1),\n",
       " ('finishing', 1),\n",
       " ('day finishing isolation', 1),\n",
       " ('day finishing', 1),\n",
       " ('day doctor finishing', 1),\n",
       " ('day doctor', 1),\n",
       " ('finishing isolation shoud', 1),\n",
       " ('shoud', 1),\n",
       " ('14 day doctor', 1),\n",
       " ('isolation shoud', 1),\n",
       " ('14 day finishing', 1),\n",
       " ('isolation traumatized', 1),\n",
       " ('going im', 1),\n",
       " ('corona going im', 1),\n",
       " ('corona going', 1),\n",
       " ('im stressed', 1),\n",
       " ('im stressed stuff', 1),\n",
       " ('going im stressed', 1),\n",
       " ('going', 1),\n",
       " ('traumatized worried', 1),\n",
       " ('stressed stuff', 1),\n",
       " ('axious', 1),\n",
       " ('axious isolation', 1),\n",
       " ('axious isolation traumatized', 1),\n",
       " ('isolation traumatized worried', 1),\n",
       " ('traumatized', 1),\n",
       " ('stressed', 1),\n",
       " ('practice social', 1),\n",
       " ('gym', 1),\n",
       " ('gym safe', 1),\n",
       " ('item prepare', 1),\n",
       " ('item', 1),\n",
       " ('bulkbuy item prepare', 1),\n",
       " ('bulkbuy item', 1),\n",
       " ('bulkbuy', 1),\n",
       " ('information', 1),\n",
       " ('covid19 source', 1),\n",
       " ('covid19 source virus', 1),\n",
       " ('source', 1),\n",
       " ('source virus', 1),\n",
       " ('covid19 spread', 1),\n",
       " ('rise seeing', 1),\n",
       " ('case rise', 1),\n",
       " ('seeing', 1),\n",
       " ('case rise seeing', 1),\n",
       " ('rise', 1),\n",
       " ('illness spread', 1),\n",
       " ('covid19 ha illness', 1),\n",
       " ('ha illness', 1),\n",
       " ('ha illness spread', 1),\n",
       " ('covid19 ha', 1),\n",
       " ('quanrantine spread', 1),\n",
       " ('quanrantine spread virus', 1),\n",
       " ('person quanrantine', 1),\n",
       " ('person quanrantine spread', 1),\n",
       " ('quanrantine', 1),\n",
       " ('food', 1),\n",
       " ('including refrigerated spread', 1),\n",
       " ('refrigerated', 1),\n",
       " ('refrigerated spread', 1),\n",
       " ('refrigerated spread virus', 1),\n",
       " ('food food', 1),\n",
       " ('food food frozen', 1),\n",
       " ('food frozen', 1),\n",
       " ('food frozen including', 1),\n",
       " ('frozen including', 1),\n",
       " ('frozen including refrigerated', 1),\n",
       " ('frozen', 1),\n",
       " ('including refrigerated', 1),\n",
       " ('outbreak stop', 1),\n",
       " ('outbreak stop warm', 1),\n",
       " ('warm', 1),\n",
       " ('warm weather', 1),\n",
       " ('stop warm', 1),\n",
       " ('stop', 1),\n",
       " ('weather', 1),\n",
       " ('stop warm weather', 1),\n",
       " ('community spread', 1),\n",
       " ('temperature virus', 1),\n",
       " ('kill', 1),\n",
       " ('kill temperature', 1),\n",
       " ('kill temperature virus', 1),\n",
       " ('covid19 kill', 1),\n",
       " ('covid19 kill temperature', 1),\n",
       " ('cockroach covid19 infect', 1),\n",
       " ('mosquito', 1),\n",
       " ('insect mite', 1),\n",
       " ('insect', 1),\n",
       " ('cockroach', 1),\n",
       " ('cockroach covid19', 1),\n",
       " ('tick virus', 1),\n",
       " ('tick', 1),\n",
       " ('bedbug', 1),\n",
       " ('mosquito spread tick', 1),\n",
       " ('mosquito spread', 1),\n",
       " ('mite mosquito spread', 1),\n",
       " ('insect mite mosquito', 1),\n",
       " ('mite mosquito', 1),\n",
       " ('mite', 1),\n",
       " ('infect insect mite', 1),\n",
       " ('infect insect', 1),\n",
       " ('bedbug cockroach covid19', 1),\n",
       " ('bedbug cockroach', 1),\n",
       " ('spread tick', 1),\n",
       " ('spread tick virus', 1),\n",
       " ('covid19 infect', 1),\n",
       " ('covid19 infect insect', 1),\n",
       " ('area', 1),\n",
       " ('china', 1),\n",
       " ('package', 1),\n",
       " ('live product shipped', 1),\n",
       " ('import stuff', 1),\n",
       " ('shipping', 1),\n",
       " ('continue import', 1),\n",
       " ('continue import stuff', 1),\n",
       " ('imported item live', 1),\n",
       " ('imported item', 1),\n",
       " ('imported', 1),\n",
       " ('import', 1),\n",
       " ('shipped', 1),\n",
       " ('live product', 1),\n",
       " ('country imported', 1),\n",
       " ('country imported item', 1),\n",
       " ('county', 1),\n",
       " ('county infection', 1),\n",
       " ('shipped virus', 1),\n",
       " ('covi19', 1),\n",
       " ('reported', 1),\n",
       " ('reported safe', 1),\n",
       " ('item live', 1),\n",
       " ('item live product', 1),\n",
       " ('donate', 1),\n",
       " ('blood donate', 1),\n",
       " ('blood', 1),\n",
       " ('covid19 risk', 1),\n",
       " ('covid19 risk sick', 1),\n",
       " ('risk sick', 1),\n",
       " ('child covid19 risk', 1),\n",
       " ('child protect', 1),\n",
       " ('child covid19 different', 1),\n",
       " ('covid19 different', 1),\n",
       " ('covid19 different symptom', 1),\n",
       " ('adult child covid19', 1),\n",
       " ('adult child', 1),\n",
       " ('need tested', 1),\n",
       " ('negative positive test', 1),\n",
       " ('later', 1),\n",
       " ('positive', 1),\n",
       " ('positive test', 1),\n",
       " ('positive test test', 1),\n",
       " ('test test', 1),\n",
       " ('later negative positive', 1),\n",
       " ('later negative', 1),\n",
       " ('negative positive', 1),\n",
       " ('theyve touch virus', 1),\n",
       " ('covid19 died passed', 1),\n",
       " ('away covid19', 1),\n",
       " ('away', 1),\n",
       " ('theyve', 1),\n",
       " ('theyve touch', 1),\n",
       " ('touch', 1),\n",
       " ('touch virus', 1),\n",
       " ('covid19 died', 1),\n",
       " ('passed risk theyve', 1),\n",
       " ('passed risk', 1),\n",
       " ('passed', 1),\n",
       " ('away covid19 died', 1),\n",
       " ('risk theyve touch', 1),\n",
       " ('risk theyve', 1),\n",
       " ('cat dog', 1),\n",
       " ('covid19 pet', 1),\n",
       " ('pet sick', 1),\n",
       " ('animal covid19', 1),\n",
       " ('cat dog make', 1),\n",
       " ('animal covid19 pet', 1),\n",
       " ('make pet', 1),\n",
       " ('make pet sick', 1),\n",
       " ('infect pet', 1),\n",
       " ('cat dog infect', 1),\n",
       " ('covid19 dog', 1),\n",
       " ('pet shoul tested', 1),\n",
       " ('pet shoul', 1),\n",
       " ('cat covid19', 1),\n",
       " ('shoul tested', 1),\n",
       " ('cat covid19 dog', 1),\n",
       " ('shoul', 1),\n",
       " ('covid19 dog pet', 1),\n",
       " ('dog pet', 1),\n",
       " ('dog pet shoul', 1),\n",
       " ('covid19 fur', 1),\n",
       " ('carry covid19 fur', 1),\n",
       " ('animal carry', 1),\n",
       " ('animal carry covid19', 1),\n",
       " ('carry covid19', 1),\n",
       " ('carry', 1),\n",
       " ('skin', 1),\n",
       " ('skin virus', 1),\n",
       " ('covid19 fur skin', 1),\n",
       " ('fur skin virus', 1),\n",
       " ('fur skin', 1),\n",
       " ('fur', 1),\n",
       " ('animal avoid', 1),\n",
       " ('im infected pet', 1),\n",
       " ('contact im', 1),\n",
       " ('contact im infected', 1),\n",
       " ('animal avoid contact', 1),\n",
       " ('avoid contact', 1),\n",
       " ('avoid contact im', 1),\n",
       " ('child friend', 1),\n",
       " ('hang shool', 1),\n",
       " ('behave', 1),\n",
       " ('behave closed', 1),\n",
       " ('behave closed school', 1),\n",
       " ('friend hang shool', 1),\n",
       " ('friend hang', 1),\n",
       " ('friend', 1),\n",
       " ('closed school', 1),\n",
       " ('closed', 1),\n",
       " ('hang', 1),\n",
       " ('child friend hang', 1),\n",
       " ('help', 1),\n",
       " ('learning', 1),\n",
       " ('learning shool', 1),\n",
       " ('child continue', 1),\n",
       " ('continue help learning', 1),\n",
       " ('help learning', 1),\n",
       " ('help learning shool', 1),\n",
       " ('child continue help', 1),\n",
       " ('continue help', 1),\n",
       " ('meal school', 1),\n",
       " ('meal', 1),\n",
       " ('kid', 1),\n",
       " ('kid meal', 1),\n",
       " ('school school', 1),\n",
       " ('kid meal school', 1),\n",
       " ('access kid', 1),\n",
       " ('access kid meal', 1),\n",
       " ('meal school school', 1),\n",
       " ('healthy school', 1),\n",
       " ('family healthy', 1),\n",
       " ('healthy', 1),\n",
       " ('family healthy school', 1),\n",
       " ('adult chronically ill', 1),\n",
       " ('chronically ill including', 1),\n",
       " ('relative school', 1),\n",
       " ('relative school time', 1),\n",
       " ('limit older relative', 1),\n",
       " ('adult chronically', 1),\n",
       " ('limit older', 1),\n",
       " ('school time', 1),\n",
       " ('ill', 1),\n",
       " ('time', 1),\n",
       " ('chronically ill', 1),\n",
       " ('chronically', 1),\n",
       " ('ill including', 1),\n",
       " ('ill including limit', 1),\n",
       " ('including limit', 1),\n",
       " ('including limit older', 1),\n",
       " ('older', 1),\n",
       " ('older relative', 1),\n",
       " ('older relative school', 1),\n",
       " ('relative', 1),\n",
       " ('higher people', 1),\n",
       " ('higher people risk', 1),\n",
       " ('higher illness risk', 1),\n",
       " ('illness risk', 1),\n",
       " ('higher illness', 1),\n",
       " ('community outbreak', 1),\n",
       " ('outbreak prepare', 1),\n",
       " ('child community covid19', 1),\n",
       " ('covid19 outbreak', 1),\n",
       " ('covid19 outbreak prepare', 1),\n",
       " ('community covid19', 1),\n",
       " ('child community', 1),\n",
       " ('case child community', 1),\n",
       " ('case child', 1),\n",
       " ('community covid19 outbreak', 1),\n",
       " ('family prepare', 1),\n",
       " ('covid19 family prepare', 1),\n",
       " ('getting', 1),\n",
       " ('family getting', 1),\n",
       " ('reduce', 1),\n",
       " ('reduce risk', 1),\n",
       " ('getting reduce risk', 1),\n",
       " ('risk step', 1),\n",
       " ('getting reduce', 1),\n",
       " ('reduce risk step', 1),\n",
       " ('step', 1),\n",
       " ('family getting reduce', 1),\n",
       " ('covid19 family getting', 1),\n",
       " ('house sick', 1),\n",
       " ('covid19 house', 1),\n",
       " ('covid19 house sick', 1),\n",
       " ('sanitizer soap use', 1),\n",
       " ('hand sanitizer soap', 1),\n",
       " ('soap use water', 1),\n",
       " ('sanitizer soap', 1),\n",
       " ('make sanitizer', 1),\n",
       " ('hand make sanitizer', 1),\n",
       " ('hand make', 1),\n",
       " ('sanitizer work', 1),\n",
       " ('home sanitizer', 1),\n",
       " ('okay', 1),\n",
       " ('okay sanitizer', 1),\n",
       " ('home sanitizer work', 1),\n",
       " ('product protect use', 1),\n",
       " ('product protect', 1),\n",
       " ('covid19 product protect', 1),\n",
       " ('covid19 product', 1),\n",
       " ('agains cleaning covid19', 1),\n",
       " ('agains cleaning', 1),\n",
       " ('agains', 1),\n",
       " ('cleaning covid19 product', 1),\n",
       " ('cleaning covid19', 1),\n",
       " ('cleaning', 1),\n",
       " ('protect use', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter( words ).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diy', 'doctor', 'diy okay', 'distancing practice', 'doctor finishing']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_stop_words = [ w for (w, c) in Counter(words).most_common() if c > 20]\n",
    "add_stop_words[ : 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bilha\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['died', 'finishing', 'flu', 'ha', 'heat', 'higher', 'im', 'isolation', 'mean', 'okay', 'passed', 'people', 'practice', 'prevent', 'risk', 'sanitizer', 'social', 'speak', 'symptom', 'virus'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>class_category</th>\n",
       "      <th>lemma_sentences</th>\n",
       "      <th>14</th>\n",
       "      <th>14 day</th>\n",
       "      <th>14 day finishing</th>\n",
       "      <th>19</th>\n",
       "      <th>19 corana</th>\n",
       "      <th>19 corana virus</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>virus worried</th>\n",
       "      <th>visit</th>\n",
       "      <th>warm</th>\n",
       "      <th>warm weather</th>\n",
       "      <th>wash</th>\n",
       "      <th>water</th>\n",
       "      <th>weather</th>\n",
       "      <th>woman</th>\n",
       "      <th>work</th>\n",
       "      <th>worried</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>what is a pandemic?</td>\n",
       "      <td>pandemic_define</td>\n",
       "      <td>a is pandemic what</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>what causes pandemics?</td>\n",
       "      <td>pandemic_causes</td>\n",
       "      <td>cause pandemic what</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 740 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               input_text   class_category      lemma_sentences  14  14 day  \\\n",
       "0     what is a pandemic?  pandemic_define   a is pandemic what   0       0   \n",
       "1  what causes pandemics?  pandemic_causes  cause pandemic what   0       0   \n",
       "\n",
       "   14 day finishing  19  19 corana  19 corana virus  access  ...  \\\n",
       "0                 0   0          0                0       0  ...   \n",
       "1                 0   0          0                0       0  ...   \n",
       "\n",
       "   virus worried  visit  warm  warm weather  wash  water  weather  woman  \\\n",
       "0              0      0     0             0     0      0        0      0   \n",
       "1              0      0     0             0     0      0        0      0   \n",
       "\n",
       "   work  worried  \n",
       "0     0        0  \n",
       "1     0        0  \n",
       "\n",
       "[2 rows x 740 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "add_stop_words = text.ENGLISH_STOP_WORDS.union( add_stop_words)\n",
    "new_cv = CountVectorizer( stop_words = add_stop_words, ngram_range=(1,3) )\n",
    "data_cv = new_cv.fit_transform( db_training.lemma_sentences )\n",
    "\n",
    "db_training.drop( db_training.iloc[:, 3:], axis=1, inplace=True)\n",
    "\n",
    "db_training = db_training.join( pd.DataFrame( \n",
    "        data_cv.toarray(), \n",
    "        columns=new_cv.get_feature_names(), index=db_training.index\n",
    "        ) )\n",
    "\n",
    "db_training.to_csv('training_matrix.csv')\n",
    "\n",
    "db_training.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "virus           27\n",
       "risk            10\n",
       "child            9\n",
       "sanitizer        8\n",
       "spread           8\n",
       "hand             7\n",
       "safe             6\n",
       "tested           6\n",
       "use              6\n",
       "im               6\n",
       "infected         6\n",
       "people           6\n",
       "pet              6\n",
       "school           6\n",
       "protect          6\n",
       "corana           6\n",
       "infection        5\n",
       "long             5\n",
       "home             5\n",
       "isolate          4\n",
       "pandemic         4\n",
       "person           4\n",
       "test             4\n",
       "family           4\n",
       "self             4\n",
       "isolation        4\n",
       "ha               4\n",
       "face             4\n",
       "spread virus     4\n",
       "contact          4\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dftmp = pd.DataFrame( db_training.iloc[:, 3:].sum() ) \n",
    "dftmp[0].sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeStopWords = True \n",
    "'''\n",
    "TODO: alternative similarity measures Vs acurracy\n",
    "\n",
    "Input: a doc/sentence observation to find matching docs for\n",
    "Return: Doc with highest matching score or None if nothing found\n",
    "TODO: set a threshold for matching scores; don't just use max\n",
    "'''\n",
    "def predict(observation, model):                 \n",
    "    sent_tokenz = list( db_training.lemma_sentences )\n",
    "    sent_class_cat = list( db_training.class_category )\n",
    "    sent_tokenz.append( observation )       \n",
    "    tfidf = model.fit_transform( sent_tokenz ) \n",
    "\n",
    "    valz = cosine_similarity( tfidf[-1], tfidf) \n",
    "    idx = valz.argsort()[0][-2] \n",
    "    flatz = valz.flatten()\n",
    "    flatz.sort()\n",
    "\n",
    "    resp = flatz[-2]\n",
    "\n",
    "    if resp == 0:\n",
    "        return (None, None)\n",
    "    else:\n",
    "        # return \"{}\\n\\t{}\".format(sent_tokenz[ idx ] , sent_tokenz[ idx+1])\n",
    "        return  sent_class_cat[idx], \"{} <<< {}\".format( sent_class_cat[idx], sent_tokenz[ idx ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "quez = ['What is corana?', 'what is covid virus', 'what is covid-19 virus',  'What is COVID-19', \n",
    "        'What is pandemic?', 'Can my cat infect me', 'can an insect infect me', 'should i get my pet tested', \n",
    "       'how do i protect myself', 'is my child at risk', 'is my old man at risk', \n",
    "        'can i go swimming', 'is bottled water a risk', 'is bottled drinking water a risk', \n",
    "        'is it safe to drink bottled water', 'is public water bad', 'are frozen foods safe', \n",
    "       'can i get infect from handling dead bodies of previously infected persons', \n",
    "       'do i have corona']\n",
    "\n",
    "labelz = [\n",
    "    'covid19_define', 'covid19_define', 'covid19_define', 'covid19_define', \n",
    "    'pandemic_define', 'pets_infection_cdc', 'covid19_spread_insects', 'pets_infection_cdc',\n",
    "    'covid19_self_protect', 'covid19_at_risk_kids', 'covid19_at_risk',\n",
    "    'covid19_swimming', 'covid19_public_water', 'covid19_public_water', \n",
    "    'covid19_public_water', 'Ã§ovid19_public_water', 'covid19_spread_foods',\n",
    "    'covid19_dead',\n",
    "    'covid19_symptoms'\n",
    "]\n",
    "\n",
    "def doTfIdf_Predict(quez=quez, labelz=labelz, tokenizerz=None, stop_wordz=None, ngramz=(1,1)):\n",
    "    md =  TfidfVectorizer(\n",
    "            tokenizer = tokenizerz, \n",
    "            stop_words = stop_wordz, \n",
    "            ngram_range = ngramz,             \n",
    "        )\n",
    "    \n",
    "    predicted = []\n",
    "\n",
    "    for i, que in enumerate(quez):\n",
    "        cat, pred = predict( que, md )\n",
    "        predicted.append( cat )\n",
    "        print( \"{}. [{}] {} ====> {}\".format( i, (cat == labelz[i]), que, pred))\n",
    "\n",
    "    predicted = np.array(predicted) \n",
    "    labelz = np.array(labelz ) \n",
    "    y_true = len( predicted[ predicted == labelz]) \n",
    "    n = len(labelz) \n",
    "\n",
    "    print( 'y_true = {} \\tn={} \\taccuracy = {}%'.format( y_true, n, (y_true*100/n) ) )\n",
    "    \n",
    "    return md\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bilha\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['died', 'finishing', 'flu', 'ha', 'heat', 'higher', 'im', 'isolation', 'le', 'mean', 'okay', 'passed', 'people', 'practice', 'prevent', 'risk', 'sanitizer', 'social', 'speak', 'symptom', 'u', 'virus', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [True] What is corana? ====> covid19_define <<< corana is what\n",
      "1. [True] what is covid virus ====> covid19_define <<< covid19 is virus what\n",
      "2. [True] what is covid-19 virus ====> covid19_define <<< covid19 is virus what\n",
      "3. [False] What is COVID-19 ====> None\n",
      "4. [True] What is pandemic? ====> pandemic_define <<< a is pandemic what\n",
      "5. [True] Can my cat infect me ====> pets_infection_cdc <<< cat dog infect me my or or other pet will\n",
      "6. [True] can an insect infect me ====> covid19_spread_insects <<< a bedbug can cockroach covid19 infect insect mite mosquito or or spread such the tick u virus with\n",
      "7. [False] should i get my pet tested ====> testing_who <<< be i should tested\n",
      "8. [True] how do i protect myself ====> covid19_self_protect <<< can how i myself protect\n",
      "9. [True] is my child at risk ====> covid19_at_risk_kids <<< becoming child covid19 is my of risk sick the what with\n",
      "10. [True] is my old man at risk ====> covid19_at_risk <<< at is most risk who\n",
      "11. [True] can i go swimming ====> covid19_swimming <<< can go i swimming\n",
      "12. [False] is bottled water a risk ====> covid19_at_risk <<< at is most risk who\n",
      "13. [False] is bottled drinking water a risk ====> covid19_at_risk <<< at is most risk who\n",
      "14. [True] is it safe to drink bottled water ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "15. [False] is public water bad ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "16. [True] are frozen foods safe ====> covid19_spread_foods <<< be can food food frozen including or refrigerated spread the through virus\n",
      "17. [False] can i get infect from handling dead bodies of previously infected persons ====> covid19_symptoms <<< am i infected\n",
      "18. [False] do i have corona ====> corana_viruses <<< are corona virus what\n",
      "y_true = 12 \tn=19 \taccuracy = 63.1578947368421%\n"
     ]
    }
   ],
   "source": [
    "## With corpus specific stop words\n",
    "\n",
    "doTfIdf_Predict(\n",
    "            tokenizerz = lemmatizeTokens,\n",
    "            stop_wordz = add_stop_words if removeStopWords else None,\n",
    "            ngramz = (1,3),             \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bilha\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [True] What is corana? ====> covid19_define <<< corana is what\n",
      "1. [True] what is covid virus ====> covid19_define <<< covid19 is virus what\n",
      "2. [True] what is covid-19 virus ====> covid19_define <<< covid19 is virus what\n",
      "3. [True] What is COVID-19 ====> covid19_define <<< covid19 is virus what\n",
      "4. [True] What is pandemic? ====> pandemic_define <<< a is pandemic what\n",
      "5. [True] Can my cat infect me ====> pets_infection_cdc <<< cat dog infect me my or or other pet will\n",
      "6. [True] can an insect infect me ====> covid19_spread_insects <<< a bedbug can cockroach covid19 infect insect mite mosquito or or spread such the tick u virus with\n",
      "7. [False] should i get my pet tested ====> testing_who <<< be i should tested\n",
      "8. [True] how do i protect myself ====> covid19_self_protect <<< can how i myself protect\n",
      "9. [False] is my child at risk ====> covid19_at_risk <<< at is most risk who\n",
      "10. [True] is my old man at risk ====> covid19_at_risk <<< at is most risk who\n",
      "11. [True] can i go swimming ====> covid19_swimming <<< can go i swimming\n",
      "12. [False] is bottled water a risk ====> covid19_at_risk <<< at is most risk who\n",
      "13. [False] is bottled drinking water a risk ====> covid19_at_risk <<< at is most risk who\n",
      "14. [True] is it safe to drink bottled water ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "15. [False] is public water bad ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "16. [True] are frozen foods safe ====> covid19_spread_foods <<< be can food food frozen including or refrigerated spread the through virus\n",
      "17. [False] can i get infect from handling dead bodies of previously infected persons ====> covid19_symptoms <<< am i infected\n",
      "18. [False] do i have corona ====> corana_viruses <<< are corona virus what\n",
      "y_true = 12 \tn=19 \taccuracy = 63.1578947368421%\n"
     ]
    }
   ],
   "source": [
    "## same thing with default stop words\n",
    "\n",
    "doTfIdf_Predict(\n",
    "            tokenizerz = lemmatizeTokens,\n",
    "            stop_wordz = 'english' if removeStopWords else None,\n",
    "            ngramz = (1,3),             \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bilha\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [False] What is corana? ====> None\n",
      "1. [False] what is covid virus ====> None\n",
      "2. [True] what is covid-19 virus ====> covid19_define <<< covid19 is virus what\n",
      "3. [False] What is COVID-19 ====> None\n",
      "4. [False] What is pandemic? ====> None\n",
      "5. [False] Can my cat infect me ====> None\n",
      "6. [True] can an insect infect me ====> covid19_spread_insects <<< a bedbug can cockroach covid19 infect insect mite mosquito or or spread such the tick u virus with\n",
      "7. [False] should i get my pet tested ====> None\n",
      "8. [False] how do i protect myself ====> None\n",
      "9. [False] is my child at risk ====> None\n",
      "10. [False] is my old man at risk ====> None\n",
      "11. [False] can i go swimming ====> None\n",
      "12. [False] is bottled water a risk ====> None\n",
      "13. [False] is bottled drinking water a risk ====> None\n",
      "14. [False] is it safe to drink bottled water ====> None\n",
      "15. [False] is public water bad ====> None\n",
      "16. [True] are frozen foods safe ====> covid19_spread_foods <<< be can food food frozen including or refrigerated spread the through virus\n",
      "17. [False] can i get infect from handling dead bodies of previously infected persons ====> covid19_contact_potential <<< an been come contact do ha i i if incontact infected into person should someone that what with with\n",
      "18. [False] do i have corona ====> None\n",
      "y_true = 3 \tn=19 \taccuracy = 15.789473684210526%\n"
     ]
    }
   ],
   "source": [
    "doTfIdf_Predict(\n",
    "            tokenizerz = lemmatizeTokens,\n",
    "            stop_wordz = 'english' if removeStopWords else None,\n",
    "            ngramz = (2,2),             \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bilha\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [True] What is corana? ====> covid19_define <<< corana is what\n",
      "1. [True] what is covid virus ====> covid19_define <<< covid19 is virus what\n",
      "2. [True] what is covid-19 virus ====> covid19_define <<< covid19 is virus what\n",
      "3. [True] What is COVID-19 ====> covid19_define <<< covid19 is virus what\n",
      "4. [True] What is pandemic? ====> pandemic_define <<< a is pandemic what\n",
      "5. [True] Can my cat infect me ====> pets_infection_cdc <<< cat dog infect me my or or other pet will\n",
      "6. [True] can an insect infect me ====> covid19_spread_insects <<< a bedbug can cockroach covid19 infect insect mite mosquito or or spread such the tick u virus with\n",
      "7. [False] should i get my pet tested ====> testing_who <<< be i should tested\n",
      "8. [True] how do i protect myself ====> covid19_self_protect <<< can how i myself protect\n",
      "9. [False] is my child at risk ====> covid19_at_risk <<< at is most risk who\n",
      "10. [True] is my old man at risk ====> covid19_at_risk <<< are at more old people risk\n",
      "11. [True] can i go swimming ====> covid19_swimming <<< can go i swimming\n",
      "12. [False] is bottled water a risk ====> covid19_at_risk <<< at is most risk who\n",
      "13. [False] is bottled drinking water a risk ====> covid19_at_risk <<< at is most risk who\n",
      "14. [True] is it safe to drink bottled water ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "15. [False] is public water bad ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "16. [True] are frozen foods safe ====> covid19_spread_foods <<< be can food food frozen including or refrigerated spread the through virus\n",
      "17. [False] can i get infect from handling dead bodies of previously infected persons ====> covid19_symptoms <<< am i infected\n",
      "18. [False] do i have corona ====> corana_viruses <<< are corona virus what\n",
      "y_true = 12 \tn=19 \taccuracy = 63.1578947368421%\n"
     ]
    }
   ],
   "source": [
    "doTfIdf_Predict(\n",
    "            tokenizerz = lemmatizeTokens,\n",
    "            stop_wordz = 'english' if removeStopWords else None,\n",
    "            ngramz = (1,2),             \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bilha\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [False] What is corana? ====> None\n",
      "1. [False] what is covid virus ====> None\n",
      "2. [True] what is covid-19 virus ====> covid19_define <<< covid19 is virus what\n",
      "3. [False] What is COVID-19 ====> None\n",
      "4. [False] What is pandemic? ====> None\n",
      "5. [False] Can my cat infect me ====> None\n",
      "6. [True] can an insect infect me ====> covid19_spread_insects <<< a bedbug can cockroach covid19 infect insect mite mosquito or or spread such the tick u virus with\n",
      "7. [False] should i get my pet tested ====> None\n",
      "8. [False] how do i protect myself ====> None\n",
      "9. [False] is my child at risk ====> None\n",
      "10. [False] is my old man at risk ====> None\n",
      "11. [False] can i go swimming ====> None\n",
      "12. [False] is bottled water a risk ====> None\n",
      "13. [False] is bottled drinking water a risk ====> None\n",
      "14. [False] is it safe to drink bottled water ====> None\n",
      "15. [False] is public water bad ====> None\n",
      "16. [True] are frozen foods safe ====> covid19_spread_foods <<< be can food food frozen including or refrigerated spread the through virus\n",
      "17. [False] can i get infect from handling dead bodies of previously infected persons ====> covid19_contact_potential <<< an been come contact do ha i i if incontact infected into person should someone that what with with\n",
      "18. [False] do i have corona ====> None\n",
      "y_true = 3 \tn=19 \taccuracy = 15.789473684210526%\n"
     ]
    }
   ],
   "source": [
    "doTfIdf_Predict(\n",
    "            tokenizerz = lemmatizeTokens,\n",
    "            stop_wordz = 'english' if removeStopWords else None,\n",
    "            ngramz = (2,3),             \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [True] What is corana? ====> covid19_define <<< corana is what"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bilha\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. [True] what is covid virus ====> covid19_define <<< covid19 is virus what\n",
      "2. [True] what is covid-19 virus ====> covid19_define <<< covid19 is virus what\n",
      "3. [True] What is COVID-19 ====> covid19_define <<< covid19 is virus what\n",
      "4. [True] What is pandemic? ====> pandemic_define <<< a is pandemic what\n",
      "5. [True] Can my cat infect me ====> pets_infection_cdc <<< cat dog infect me my or or other pet will\n",
      "6. [True] can an insect infect me ====> covid19_spread_insects <<< a bedbug can cockroach covid19 infect insect mite mosquito or or spread such the tick u virus with\n",
      "7. [False] should i get my pet tested ====> testing_who <<< be i should tested\n",
      "8. [True] how do i protect myself ====> covid19_self_protect <<< can how i myself protect\n",
      "9. [True] is my child at risk ====> covid19_at_risk_kids <<< becoming child covid19 is my of risk sick the what with\n",
      "10. [True] is my old man at risk ====> covid19_at_risk <<< are at more old people risk\n",
      "11. [True] can i go swimming ====> covid19_swimming <<< can go i swimming\n",
      "12. [False] is bottled water a risk ====> covid19_at_risk <<< at is most risk who\n",
      "13. [True] is bottled drinking water a risk ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "14. [True] is it safe to drink bottled water ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "15. [False] is public water bad ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "16. [True] are frozen foods safe ====> covid19_spread_foods <<< be can food food frozen including or refrigerated spread the through virus\n",
      "17. [False] can i get infect from handling dead bodies of previously infected persons ====> covid19_symptoms <<< am i infected\n",
      "18. [False] do i have corona ====> corana_viruses <<< are corona virus what\n",
      "y_true = 14 \tn=19 \taccuracy = 73.6842105263158%\n"
     ]
    }
   ],
   "source": [
    "# no n-grams\n",
    "doTfIdf_Predict(\n",
    "            tokenizerz = lemmatizeTokens,\n",
    "            stop_wordz = 'english' if removeStopWords else None,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [True] What is corana? ====> covid19_define <<< corana is what\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bilha\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['died', 'finishing', 'flu', 'ha', 'heat', 'higher', 'im', 'isolation', 'le', 'mean', 'okay', 'passed', 'people', 'practice', 'prevent', 'risk', 'sanitizer', 'social', 'speak', 'symptom', 'u', 'virus', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [True] what is covid virus ====> covid19_define <<< covid19 is virus what\n",
      "2. [True] what is covid-19 virus ====> covid19_define <<< covid19 is virus what\n",
      "3. [False] What is COVID-19 ====> None\n",
      "4. [True] What is pandemic? ====> pandemic_define <<< a is pandemic what\n",
      "5. [True] Can my cat infect me ====> pets_infection_cdc <<< cat dog infect me my or or other pet will\n",
      "6. [True] can an insect infect me ====> covid19_spread_insects <<< a bedbug can cockroach covid19 infect insect mite mosquito or or spread such the tick u virus with\n",
      "7. [False] should i get my pet tested ====> testing_who <<< be i should tested\n",
      "8. [True] how do i protect myself ====> covid19_self_protect <<< can how i myself protect\n",
      "9. [True] is my child at risk ====> covid19_at_risk_kids <<< becoming child covid19 is my of risk sick the what with\n",
      "10. [True] is my old man at risk ====> covid19_at_risk <<< are at more old people risk\n",
      "11. [True] can i go swimming ====> covid19_swimming <<< can go i swimming\n",
      "12. [False] is bottled water a risk ====> covid19_at_risk <<< at is most risk who\n",
      "13. [True] is bottled drinking water a risk ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "14. [True] is it safe to drink bottled water ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "15. [False] is public water bad ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "16. [True] are frozen foods safe ====> covid19_spread_foods <<< be can food food frozen including or refrigerated spread the through virus\n",
      "17. [False] can i get infect from handling dead bodies of previously infected persons ====> covid19_symptoms <<< am i infected\n",
      "18. [False] do i have corona ====> corana_viruses <<< are corona virus what\n",
      "y_true = 13 \tn=19 \taccuracy = 68.42105263157895%\n"
     ]
    }
   ],
   "source": [
    "# no n-grams & corpus specific stop_words\n",
    "doTfIdf_Predict(\n",
    "            tokenizerz = lemmatizeTokens,\n",
    "            stop_wordz = add_stop_words if removeStopWords else None,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [True] What is corana? ====> covid19_define <<< corana is what\n",
      "1. [True] what is covid virus ====> covid19_define <<< covid19 is virus what\n",
      "2. [True] what is covid-19 virus ====> covid19_define <<< 19 corana is virus what\n",
      "3. [True] What is COVID-19 ====> covid19_define <<< 19 corana is virus what\n",
      "4. [True] What is pandemic? ====> pandemic_define <<< a is pandemic what\n",
      "5. [True] Can my cat infect me ====> pets_infection_cdc <<< cat dog infect me my or or other pet will\n",
      "6. [True] can an insect infect me ====> covid19_spread_insects <<< a bedbug can cockroach covid19 infect insect mite mosquito or or spread such the tick u virus with\n",
      "7. [False] should i get my pet tested ====> testing_who <<< be i should tested\n",
      "8. [True] how do i protect myself ====> covid19_self_protect <<< can how i myself protect\n",
      "9. [True] is my child at risk ====> covid19_at_risk_kids <<< becoming child covid19 is my of risk sick the what with\n",
      "10. [True] is my old man at risk ====> covid19_at_risk <<< are at more old people risk\n",
      "11. [True] can i go swimming ====> covid19_swimming <<< can go i swimming\n",
      "12. [False] is bottled water a risk ====> covid19_at_risk <<< at is most risk who\n",
      "13. [True] is bottled drinking water a risk ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "14. [True] is it safe to drink bottled water ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "15. [False] is public water bad ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "16. [False] are frozen foods safe ====> covid19_self_protect <<< do how i safe stay\n",
      "17. [False] can i get infect from handling dead bodies of previously infected persons ====> covid19_symptoms <<< am i infected\n",
      "18. [False] do i have corona ====> corana_viruses <<< are corona virus what\n",
      "y_true = 13 \tn=19 \taccuracy = 68.42105263157895%\n"
     ]
    }
   ],
   "source": [
    "# no n-grams, english stopwords only and default tokenizer \n",
    "doTfIdf_Predict(\n",
    "            stop_wordz = 'english' if removeStopWords else None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [True] What is corana? ====> covid19_define <<< corana is what\n",
      "1. [True] what is covid virus ====> covid19_define <<< covid19 is virus what\n",
      "2. [True] what is covid-19 virus ====> covid19_define <<< 19 corana is virus what\n",
      "3. [True] What is COVID-19 ====> covid19_define <<< 19 corana is virus what\n",
      "4. [True] What is pandemic? ====> pandemic_define <<< a is pandemic what\n",
      "5. [True] Can my cat infect me ====> pets_infection_cdc <<< cat dog infect me my or or other pet will\n",
      "6. [False] can an insect infect me ====> pets_infection_cdc <<< cat dog infect me my or or other pet will\n",
      "7. [False] should i get my pet tested ====> testing_who <<< can get i tested\n",
      "8. [True] how do i protect myself ====> covid19_self_protect <<< can how i myself protect\n",
      "9. [False] is my child at risk ====> covid19_at_risk <<< at is most risk who\n",
      "10. [True] is my old man at risk ====> covid19_at_risk <<< are at more old people risk\n",
      "11. [True] can i go swimming ====> covid19_swimming <<< can go i swimming\n",
      "12. [True] is bottled water a risk ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "13. [True] is bottled drinking water a risk ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "14. [True] is it safe to drink bottled water ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "15. [False] is public water bad ====> covid19_public_water <<< drinking is it public safe to use water\n",
      "16. [False] are frozen foods safe ====> covid19_self_protect <<< do how i safe stay\n",
      "17. [False] can i get infect from handling dead bodies of previously infected persons ====> testing_who <<< can get i tested\n",
      "18. [False] do i have corona ====> corana_viruses <<< are corona virus what\n",
      "y_true = 12 \tn=19 \taccuracy = 63.1578947368421%\n"
     ]
    }
   ],
   "source": [
    "## zero effort\n",
    "doTfIdf_Predict(       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. [False] The quick brown fox jumped ====> None\n",
      "1. [False] Over the lazy dogs ====> None\n",
      "y_true = 0 \tn=2 \taccuracy = 0.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tmd = doTfIdf_Predict(\n",
    "    quez=['The quick brown fox jumped', 'Over the lazy dogs'],\n",
    "    labelz=['a', 'b'],\n",
    "    stop_wordz = 'english' if removeStopWords else None,\n",
    ")\n",
    "\n",
    "print( tmd )\n",
    "\n",
    "print( tmd )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF.KERAS Multi-Class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 5), dtype=float32, numpy=\n",
       "array([[[ 0.00889337, -0.03368528,  0.03606992,  0.04826439,\n",
       "         -0.02976949],\n",
       "        [-0.00044631, -0.01895789, -0.00770618,  0.02872257,\n",
       "          0.02595706],\n",
       "        [ 0.02267219,  0.04893998,  0.02294003,  0.0479191 ,\n",
       "          0.00070655]],\n",
       "\n",
       "       [[-0.0437455 , -0.02143556, -0.04711114,  0.01028641,\n",
       "         -0.02745432],\n",
       "        [ 0.04068342,  0.04728297, -0.02447218,  0.03460673,\n",
       "          0.01889784],\n",
       "        [ 0.00969733, -0.04518531,  0.01890311, -0.03280558,\n",
       "          0.01764473]]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## WORD EMBEDDINGS - KERAS.LAYERS.EMBEDDING \n",
    "# works like a dnn - random init weights, re-learn via backpropagation, vocab is input, output is len(vocab) x dim_latents lookup table and learnt weights\n",
    "# each word is identified by an int@row_index, \n",
    "embedding = keras.layers.Embedding(1000, 5) # num_words, hyperparam_dimensionality \n",
    "d = embedding( tf.constant([[1, 11, 10], [2, 22, 20]] ) )\n",
    "print( d.shape )\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size =  8185 ['the_', ', ', '. ', 'a_', 'and_', 'of_', 'to_', 's_', 'is_', 'br', 'in_', 'I_', 'that_', 'this_', 'it_']\n"
     ]
    }
   ],
   "source": [
    "## learn embeddings from scratch @ IMDB movie reviews\n",
    "\n",
    "(train_data, test_data), info = tfds.load('imdb_reviews/subwords8k', \n",
    "                                 split= (tfds.Split.TRAIN, tfds.Split.TEST),\n",
    "                                 with_info=True, as_supervised=True)\n",
    "\n",
    "# encoder vocab - tfds.features.text.SubwordTextEncoder\n",
    "encoder = info.features['text'].encoder \n",
    "print( \"vocab size = \", encoder.vocab_size, encoder.subwords[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(10, 941), dtype=int64, numpy=\n",
       "  array([[  12, 1063, 8002, ...,    0,    0,    0],\n",
       "         [  62,   27,   18, ...,    0,    0,    0],\n",
       "         [  19, 1059,  903, ...,    6, 7895, 7975],\n",
       "         ...,\n",
       "         [ 133,  378,    6, ...,    0,    0,    0],\n",
       "         [1156,    4, 1171, ...,    0,    0,    0],\n",
       "         [1917,  102, 2216, ...,    0,    0,    0]], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 1, 0, 0, 0, 0, 1, 1, 1], dtype=int64)>)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the text reviews are already integer encoded. Padding to make of same length\n",
    "train_batch = train_data.shuffle(1000).padded_batch(10, padded_shapes=([None], [])) \n",
    "test_batch = test_data.shuffle(1000).padded_batch(10, padded_shapes=([None], [])) \n",
    "list(train_batch)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          130960    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 131,249\n",
      "Trainable params: 131,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## A continuous bag of words style model and sentiment analysise p(x) is positive output layer \n",
    "embedding_dim = 16\n",
    "model2 = keras.Sequential([\n",
    "    keras.layers.Embedding( encoder.vocab_size, embedding_dim), ## encode the words \n",
    "    keras.layers.GlobalAveragePooling1D(), #pool down\n",
    "    keras.layers.Dense(16, activation='relu'), # learn \n",
    "    keras.layers.Dense(1) #sigmoid p(positive)\n",
    "])\n",
    "\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    174/Unknown - 1s 700ms/step - loss: 0.6939 - accuracy: 0.300 - 1s 352ms/step - loss: 0.6936 - accuracy: 0.500 - 1s 236ms/step - loss: 0.6935 - accuracy: 0.533 - 1s 178ms/step - loss: 0.6933 - accuracy: 0.550 - 1s 143ms/step - loss: 0.6934 - accuracy: 0.520 - 1s 120ms/step - loss: 0.6930 - accuracy: 0.550 - 1s 104ms/step - loss: 0.6930 - accuracy: 0.542 - 1s 91ms/step - loss: 0.6934 - accuracy: 0.512 - 1s 82ms/step - loss: 0.6931 - accuracy: 0.52 - 1s 74ms/step - loss: 0.6931 - accuracy: 0.52 - 1s 67ms/step - loss: 0.6929 - accuracy: 0.53 - 1s 62ms/step - loss: 0.6930 - accuracy: 0.52 - 1s 58ms/step - loss: 0.6930 - accuracy: 0.51 - 1s 54ms/step - loss: 0.6931 - accuracy: 0.50 - 1s 50ms/step - loss: 0.6930 - accuracy: 0.50 - 1s 48ms/step - loss: 0.6931 - accuracy: 0.50 - 1s 45ms/step - loss: 0.6930 - accuracy: 0.51 - 1s 43ms/step - loss: 0.6931 - accuracy: 0.51 - 1s 41ms/step - loss: 0.6931 - accuracy: 0.51 - 1s 39ms/step - loss: 0.6930 - accuracy: 0.51 - 1s 37ms/step - loss: 0.6929 - accuracy: 0.51 - 1s 36ms/step - loss: 0.6931 - accuracy: 0.50 - 1s 34ms/step - loss: 0.6930 - accuracy: 0.51 - 1s 33ms/step - loss: 0.6931 - accuracy: 0.50 - 1s 32ms/step - loss: 0.6930 - accuracy: 0.50 - 1s 31ms/step - loss: 0.6932 - accuracy: 0.50 - 1s 30ms/step - loss: 0.6931 - accuracy: 0.50 - 1s 29ms/step - loss: 0.6929 - accuracy: 0.51 - 1s 28ms/step - loss: 0.6929 - accuracy: 0.51 - 1s 27ms/step - loss: 0.6931 - accuracy: 0.51 - 1s 27ms/step - loss: 0.6932 - accuracy: 0.50 - 1s 26ms/step - loss: 0.6932 - accuracy: 0.50 - 1s 25ms/step - loss: 0.6932 - accuracy: 0.50 - 1s 25ms/step - loss: 0.6930 - accuracy: 0.51 - 1s 24ms/step - loss: 0.6930 - accuracy: 0.51 - 1s 23ms/step - loss: 0.6931 - accuracy: 0.50 - 1s 23ms/step - loss: 0.6931 - accuracy: 0.50 - 1s 22ms/step - loss: 0.6931 - accuracy: 0.50 - 1s 22ms/step - loss: 0.6929 - accuracy: 0.51 - 1s 21ms/step - loss: 0.6929 - accuracy: 0.51 - 1s 21ms/step - loss: 0.6929 - accuracy: 0.51 - 1s 21ms/step - loss: 0.6930 - accuracy: 0.51 - 1s 20ms/step - loss: 0.6930 - accuracy: 0.51 - 1s 20ms/step - loss: 0.6931 - accuracy: 0.50 - 1s 19ms/step - loss: 0.6931 - accuracy: 0.50 - 1s 19ms/step - loss: 0.6931 - accuracy: 0.50 - 1s 19ms/step - loss: 0.6930 - accuracy: 0.50 - 1s 18ms/step - loss: 0.6931 - accuracy: 0.50 - 1s 18ms/step - loss: 0.6930 - accuracy: 0.51 - 1s 18ms/step - loss: 0.6929 - accuracy: 0.51 - 1s 18ms/step - loss: 0.6929 - accuracy: 0.51 - 1s 17ms/step - loss: 0.6929 - accuracy: 0.51 - 1s 17ms/step - loss: 0.6929 - accuracy: 0.51 - 1s 17ms/step - loss: 0.6929 - accuracy: 0.51 - 1s 17ms/step - loss: 0.6928 - accuracy: 0.52 - 1s 16ms/step - loss: 0.6928 - accuracy: 0.51 - 1s 16ms/step - loss: 0.6928 - accuracy: 0.51 - 1s 16ms/step - loss: 0.6928 - accuracy: 0.51 - 1s 16ms/step - loss: 0.6928 - accuracy: 0.51 - 1s 16ms/step - loss: 0.6927 - accuracy: 0.51 - 1s 15ms/step - loss: 0.6925 - accuracy: 0.52 - 1s 15ms/step - loss: 0.6926 - accuracy: 0.52 - 1s 15ms/step - loss: 0.6926 - accuracy: 0.52 - 1s 15ms/step - loss: 0.6926 - accuracy: 0.52 - 1s 15ms/step - loss: 0.6925 - accuracy: 0.52 - 1s 14ms/step - loss: 0.6925 - accuracy: 0.52 - 1s 14ms/step - loss: 0.6925 - accuracy: 0.52 - 1s 14ms/step - loss: 0.6925 - accuracy: 0.51 - 1s 14ms/step - loss: 0.6925 - accuracy: 0.52 - 1s 14ms/step - loss: 0.6923 - accuracy: 0.52 - 1s 14ms/step - loss: 0.6923 - accuracy: 0.52 - 1s 14ms/step - loss: 0.6923 - accuracy: 0.52 - 1s 13ms/step - loss: 0.6924 - accuracy: 0.52 - 1s 13ms/step - loss: 0.6921 - accuracy: 0.52 - 1s 13ms/step - loss: 0.6920 - accuracy: 0.52 - 1s 13ms/step - loss: 0.6918 - accuracy: 0.53 - 1s 13ms/step - loss: 0.6918 - accuracy: 0.53 - 1s 13ms/step - loss: 0.6921 - accuracy: 0.52 - 1s 13ms/step - loss: 0.6919 - accuracy: 0.52 - 1s 13ms/step - loss: 0.6920 - accuracy: 0.52 - 1s 13ms/step - loss: 0.6924 - accuracy: 0.52 - 1s 12ms/step - loss: 0.6924 - accuracy: 0.52 - 1s 12ms/step - loss: 0.6922 - accuracy: 0.52 - 1s 12ms/step - loss: 0.6924 - accuracy: 0.52 - 1s 12ms/step - loss: 0.6925 - accuracy: 0.51 - 1s 12ms/step - loss: 0.6924 - accuracy: 0.51 - 1s 12ms/step - loss: 0.6924 - accuracy: 0.51 - 1s 12ms/step - loss: 0.6924 - accuracy: 0.52 - 1s 12ms/step - loss: 0.6925 - accuracy: 0.51 - 1s 12ms/step - loss: 0.6924 - accuracy: 0.52 - 1s 12ms/step - loss: 0.6923 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6923 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6922 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6922 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6921 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6920 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6923 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6922 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6922 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6923 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6923 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6922 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6922 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6922 - accuracy: 0.52 - 1s 11ms/step - loss: 0.6921 - accuracy: 0.52 - 1s 10ms/step - loss: 0.6923 - accuracy: 0.51 - 1s 10ms/step - loss: 0.6922 - accuracy: 0.52 - 1s 10ms/step - loss: 0.6922 - accuracy: 0.52 - 1s 10ms/step - loss: 0.6919 - accuracy: 0.52 - 1s 10ms/step - loss: 0.6920 - accuracy: 0.52 - 1s 10ms/step - loss: 0.6919 - accuracy: 0.52 - 1s 10ms/step - loss: 0.6920 - accuracy: 0.52 - 1s 10ms/step - loss: 0.6921 - accuracy: 0.52 - 1s 10ms/step - loss: 0.6920 - accuracy: 0.52 - 1s 10ms/step - loss: 0.6921 - accuracy: 0.52 - 1s 10ms/step - loss: 0.6921 - accuracy: 0.51 - 1s 10ms/step - loss: 0.6920 - accuracy: 0.52 - 1s 10ms/step - loss: 0.6921 - accuracy: 0.51 - 1s 10ms/step - loss: 0.6921 - accuracy: 0.51 - 1s 10ms/step - loss: 0.6923 - accuracy: 0.51 - 1s 10ms/step - loss: 0.6923 - accuracy: 0.51 - 1s 10ms/step - loss: 0.6923 - accuracy: 0.51 - 1s 10ms/step - loss: 0.6924 - accuracy: 0.51 - 1s 9ms/step - loss: 0.6925 - accuracy: 0.5137 - 1s 9ms/step - loss: 0.6925 - accuracy: 0.512 - 1s 9ms/step - loss: 0.6925 - accuracy: 0.513 - 1s 9ms/step - loss: 0.6925 - accuracy: 0.512 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.512 - 1s 9ms/step - loss: 0.6925 - accuracy: 0.513 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.512 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 9ms/step - loss: 0.6927 - accuracy: 0.510 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 9ms/step - loss: 0.6925 - accuracy: 0.512 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 9ms/step - loss: 0.6925 - accuracy: 0.512 - 1s 9ms/step - loss: 0.6925 - accuracy: 0.512 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.510 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.510 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.510 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.510 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.510 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.509 - 1s 9ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6926 - accuracy: 0.512 - 1s 8ms/step - loss: 0.6926 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6926 - accuracy: 0.510 - 1s 8ms/step - loss: 0.6926 - accuracy: 0.509 - 1s 8ms/step - loss: 0.6926 - accuracy: 0.508 - 1s 8ms/step - loss: 0.6926 - accuracy: 0.510 - 1s 8ms/step - loss: 0.6925 - accuracy: 0.512 - 1s 8ms/step - loss: 0.6925 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6925 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6925 - accuracy: 0.510 - 1s 8ms/step - loss: 0.6925 - accuracy: 0.510 - 1s 8ms/step - loss: 0.6925 - accuracy: 0.509 - 1s 8ms/step - loss: 0.6925 - accuracy: 0.510 - 1s 8ms/step - loss: 0.6925 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6924 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6924 - accuracy: 0.512 - 1s 8ms/step - loss: 0.6924 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6924 - accuracy: 0.512 - 1s 8ms/step - loss: 0.6924 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6923 - accuracy: 0.5126\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    348/Unknown - 1s 8ms/step - loss: 0.6924 - accuracy: 0.512 - 1s 8ms/step - loss: 0.6923 - accuracy: 0.513 - 1s 8ms/step - loss: 0.6923 - accuracy: 0.513 - 1s 8ms/step - loss: 0.6924 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6924 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6924 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6924 - accuracy: 0.512 - 1s 8ms/step - loss: 0.6924 - accuracy: 0.512 - 1s 8ms/step - loss: 0.6924 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6923 - accuracy: 0.512 - 1s 8ms/step - loss: 0.6923 - accuracy: 0.511 - 1s 8ms/step - loss: 0.6922 - accuracy: 0.512 - 1s 8ms/step - loss: 0.6922 - accuracy: 0.512 - 1s 8ms/step - loss: 0.6921 - accuracy: 0.513 - 1s 7ms/step - loss: 0.6921 - accuracy: 0.512 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.512 - 1s 7ms/step - loss: 0.6921 - accuracy: 0.513 - 1s 7ms/step - loss: 0.6921 - accuracy: 0.512 - 1s 7ms/step - loss: 0.6921 - accuracy: 0.512 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.511 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.510 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.509 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.509 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.509 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.509 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.510 - 1s 7ms/step - loss: 0.6923 - accuracy: 0.509 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.510 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.511 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.510 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.510 - 1s 7ms/step - loss: 0.6922 - accuracy: 0.510 - 1s 7ms/step - loss: 0.6921 - accuracy: 0.510 - 1s 7ms/step - loss: 0.6921 - accuracy: 0.509 - 1s 7ms/step - loss: 0.6921 - accuracy: 0.510 - 1s 7ms/step - loss: 0.6921 - accuracy: 0.510 - 1s 7ms/step - loss: 0.6921 - accuracy: 0.510 - 2s 7ms/step - loss: 0.6921 - accuracy: 0.509 - 2s 7ms/step - loss: 0.6920 - accuracy: 0.511 - 2s 7ms/step - loss: 0.6920 - accuracy: 0.511 - 2s 7ms/step - loss: 0.6920 - accuracy: 0.510 - 2s 7ms/step - loss: 0.6920 - accuracy: 0.511 - 2s 7ms/step - loss: 0.6920 - accuracy: 0.510 - 2s 7ms/step - loss: 0.6920 - accuracy: 0.510 - 2s 7ms/step - loss: 0.6920 - accuracy: 0.510 - 2s 7ms/step - loss: 0.6920 - accuracy: 0.508 - 2s 7ms/step - loss: 0.6919 - accuracy: 0.508 - 2s 7ms/step - loss: 0.6919 - accuracy: 0.508 - 2s 7ms/step - loss: 0.6919 - accuracy: 0.508 - 2s 7ms/step - loss: 0.6919 - accuracy: 0.508 - 2s 7ms/step - loss: 0.6919 - accuracy: 0.508 - 2s 7ms/step - loss: 0.6919 - accuracy: 0.509 - 2s 7ms/step - loss: 0.6918 - accuracy: 0.509 - 2s 7ms/step - loss: 0.6918 - accuracy: 0.509 - 2s 7ms/step - loss: 0.6919 - accuracy: 0.508 - 2s 7ms/step - loss: 0.6918 - accuracy: 0.507 - 2s 7ms/step - loss: 0.6918 - accuracy: 0.507 - 2s 7ms/step - loss: 0.6918 - accuracy: 0.506 - 2s 7ms/step - loss: 0.6918 - accuracy: 0.507 - 2s 7ms/step - loss: 0.6918 - accuracy: 0.506 - 2s 7ms/step - loss: 0.6918 - accuracy: 0.507 - 2s 7ms/step - loss: 0.6917 - accuracy: 0.506 - 2s 7ms/step - loss: 0.6917 - accuracy: 0.507 - 2s 7ms/step - loss: 0.6917 - accuracy: 0.508 - 2s 7ms/step - loss: 0.6917 - accuracy: 0.507 - 2s 7ms/step - loss: 0.6917 - accuracy: 0.507 - 2s 7ms/step - loss: 0.6917 - accuracy: 0.507 - 2s 7ms/step - loss: 0.6917 - accuracy: 0.507 - 2s 7ms/step - loss: 0.6916 - accuracy: 0.507 - 2s 7ms/step - loss: 0.6916 - accuracy: 0.506 - 2s 7ms/step - loss: 0.6916 - accuracy: 0.506 - 2s 7ms/step - loss: 0.6916 - accuracy: 0.506 - 2s 7ms/step - loss: 0.6916 - accuracy: 0.506 - 2s 7ms/step - loss: 0.6916 - accuracy: 0.506 - 2s 7ms/step - loss: 0.6916 - accuracy: 0.506 - 2s 7ms/step - loss: 0.6915 - accuracy: 0.505 - 2s 7ms/step - loss: 0.6915 - accuracy: 0.504 - 2s 7ms/step - loss: 0.6915 - accuracy: 0.506 - 2s 7ms/step - loss: 0.6915 - accuracy: 0.505 - 2s 7ms/step - loss: 0.6915 - accuracy: 0.504 - 2s 7ms/step - loss: 0.6915 - accuracy: 0.505 - 2s 7ms/step - loss: 0.6914 - accuracy: 0.504 - 2s 7ms/step - loss: 0.6915 - accuracy: 0.505 - 2s 6ms/step - loss: 0.6914 - accuracy: 0.505 - 2s 6ms/step - loss: 0.6914 - accuracy: 0.505 - 2s 6ms/step - loss: 0.6914 - accuracy: 0.505 - 2s 6ms/step - loss: 0.6913 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6913 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6913 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6913 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6913 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6913 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6913 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6913 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6911 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6911 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6911 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6911 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6913 - accuracy: 0.504 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.504 - 2s 6ms/step - loss: 0.6912 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6911 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6911 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6911 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6911 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6911 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6911 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6911 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6911 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6910 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6910 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6910 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6910 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6910 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6910 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6910 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6909 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6909 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6909 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6909 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6909 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6909 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6909 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6909 - accuracy: 0.504 - 2s 6ms/step - loss: 0.6909 - accuracy: 0.505 - 2s 6ms/step - loss: 0.6909 - accuracy: 0.505 - 2s 6ms/step - loss: 0.6908 - accuracy: 0.505 - 2s 6ms/step - loss: 0.6908 - accuracy: 0.504 - 2s 6ms/step - loss: 0.6908 - accuracy: 0.505 - 2s 6ms/step - loss: 0.6908 - accuracy: 0.505 - 2s 6ms/step - loss: 0.6908 - accuracy: 0.505 - 2s 6ms/step - loss: 0.6907 - accuracy: 0.504 - 2s 6ms/step - loss: 0.6907 - accuracy: 0.504 - 2s 6ms/step - loss: 0.6907 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6907 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6907 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6906 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6906 - accuracy: 0.504 - 2s 6ms/step - loss: 0.6906 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6906 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6906 - accuracy: 0.503 - 2s 6ms/step - loss: 0.6906 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6906 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6906 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6906 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6905 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6905 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6905 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6905 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6905 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6905 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6905 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6905 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6904 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6904 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6904 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6903 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6903 - accuracy: 0.502 - 2s 6ms/step - loss: 0.6903 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6903 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6902 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6902 - accuracy: 0.5011"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    522/Unknown - 2s 6ms/step - loss: 0.6902 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6901 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6901 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6901 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6900 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6900 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6900 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6899 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6899 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6899 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6899 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6898 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6898 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6898 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6898 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6898 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6898 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6897 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6896 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6896 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6896 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6895 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6895 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6895 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6895 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6894 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6894 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6893 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6894 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6894 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6894 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6893 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6893 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6893 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6892 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6892 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6891 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6891 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6891 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6891 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6890 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6890 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6890 - accuracy: 0.499 - 2s 6ms/step - loss: 0.6890 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6890 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6890 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6890 - accuracy: 0.501 - 2s 6ms/step - loss: 0.6890 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6890 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6889 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6889 - accuracy: 0.500 - 2s 6ms/step - loss: 0.6888 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6888 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6887 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6887 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6887 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6886 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6886 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6885 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6885 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6884 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6884 - accuracy: 0.498 - 2s 5ms/step - loss: 0.6884 - accuracy: 0.498 - 2s 5ms/step - loss: 0.6884 - accuracy: 0.498 - 2s 5ms/step - loss: 0.6884 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6884 - accuracy: 0.498 - 2s 5ms/step - loss: 0.6884 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6884 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6884 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6884 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6883 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6882 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6882 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6882 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6881 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6882 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6881 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6881 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6880 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6880 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6880 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6880 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6880 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6879 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6879 - accuracy: 0.501 - 2s 5ms/step - loss: 0.6879 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6879 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6878 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6878 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6878 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6878 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6878 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6878 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6877 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6877 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6877 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6876 - accuracy: 0.501 - 2s 5ms/step - loss: 0.6875 - accuracy: 0.501 - 2s 5ms/step - loss: 0.6875 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6875 - accuracy: 0.501 - 2s 5ms/step - loss: 0.6874 - accuracy: 0.501 - 2s 5ms/step - loss: 0.6874 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6874 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6874 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6873 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6873 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6873 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6873 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6873 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6873 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6873 - accuracy: 0.499 - 2s 5ms/step - loss: 0.6873 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6872 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6871 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6871 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6871 - accuracy: 0.501 - 2s 5ms/step - loss: 0.6871 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6870 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6870 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6870 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6869 - accuracy: 0.500 - 2s 5ms/step - loss: 0.6869 - accuracy: 0.501 - 2s 5ms/step - loss: 0.6868 - accuracy: 0.501 - 2s 5ms/step - loss: 0.6868 - accuracy: 0.501 - 2s 5ms/step - loss: 0.6868 - accuracy: 0.501 - 2s 5ms/step - loss: 0.6867 - accuracy: 0.501 - 2s 5ms/step - loss: 0.6867 - accuracy: 0.501 - 2s 5ms/step - loss: 0.6866 - accuracy: 0.502 - 2s 5ms/step - loss: 0.6865 - accuracy: 0.502 - 2s 5ms/step - loss: 0.6865 - accuracy: 0.502 - 2s 5ms/step - loss: 0.6865 - accuracy: 0.502 - 2s 5ms/step - loss: 0.6864 - accuracy: 0.502 - 2s 5ms/step - loss: 0.6864 - accuracy: 0.502 - 2s 5ms/step - loss: 0.6865 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6865 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6864 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6863 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6862 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6861 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6860 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6860 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6859 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6859 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6860 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6859 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6859 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6859 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6858 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6858 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6858 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6857 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6856 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6857 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6856 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6855 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6855 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6855 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6854 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6855 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6854 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6854 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6853 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6852 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6851 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6851 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6852 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6851 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6851 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6850 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6850 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6849 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6849 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6849 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6848 - accuracy: 0.5010"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    696/Unknown - 3s 5ms/step - loss: 0.6847 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6846 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6846 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6845 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6845 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6845 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6845 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6845 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6844 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6843 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6842 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6843 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6842 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6842 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6841 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6840 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6840 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6838 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6839 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6839 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6839 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6839 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6837 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6836 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6835 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6834 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6834 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6833 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6833 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6832 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6832 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6830 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6830 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6830 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6828 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6828 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6827 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6826 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6826 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6826 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6825 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6824 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6824 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6823 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6823 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6822 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6822 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6822 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6821 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6821 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6820 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6820 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6819 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6819 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6818 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6817 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6817 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6816 - accuracy: 0.499 - 3s 5ms/step - loss: 0.6816 - accuracy: 0.499 - 3s 5ms/step - loss: 0.6815 - accuracy: 0.499 - 3s 5ms/step - loss: 0.6814 - accuracy: 0.499 - 3s 5ms/step - loss: 0.6814 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6813 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6813 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6813 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6812 - accuracy: 0.499 - 3s 5ms/step - loss: 0.6812 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6811 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6811 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6811 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6810 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6809 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6808 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6808 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6806 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6806 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6806 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6806 - accuracy: 0.500 - 3s 5ms/step - loss: 0.6805 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6803 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6803 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6804 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6803 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6801 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6801 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6800 - accuracy: 0.501 - 3s 5ms/step - loss: 0.6799 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6798 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6798 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6798 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6797 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6795 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6796 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6794 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6793 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6793 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6793 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6791 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6791 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6790 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6790 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6789 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6787 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6787 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6787 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6786 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6785 - accuracy: 0.502 - 3s 5ms/step - loss: 0.6784 - accuracy: 0.503 - 3s 5ms/step - loss: 0.6784 - accuracy: 0.503 - 3s 5ms/step - loss: 0.6782 - accuracy: 0.503 - 3s 5ms/step - loss: 0.6781 - accuracy: 0.503 - 3s 5ms/step - loss: 0.6781 - accuracy: 0.503 - 3s 5ms/step - loss: 0.6780 - accuracy: 0.503 - 3s 5ms/step - loss: 0.6780 - accuracy: 0.503 - 3s 5ms/step - loss: 0.6779 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6777 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6777 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6776 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6775 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6775 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6775 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6774 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6772 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6773 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6772 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6769 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6768 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6767 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6767 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6766 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6765 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6765 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6763 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6762 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6762 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6761 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6761 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6760 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6758 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6756 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6756 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6756 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6756 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6754 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6753 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6753 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6752 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6752 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6751 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6750 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6750 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6749 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6748 - accuracy: 0.504 - 3s 5ms/step - loss: 0.6748 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6747 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6747 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6746 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6745 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6744 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6743 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6742 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6741 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6740 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6740 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6739 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6738 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6738 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6736 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6736 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6735 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6734 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6734 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6733 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6732 - accuracy: 0.5059"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    750/Unknown - 3s 5ms/step - loss: 0.6731 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6729 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6729 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6729 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6727 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6726 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6725 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6723 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6722 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6721 - accuracy: 0.505 - 3s 5ms/step - loss: 0.6720 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6720 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6719 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6718 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6718 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6717 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6715 - accuracy: 0.506 - 3s 5ms/step - loss: 0.6714 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6714 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6713 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6711 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6711 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6710 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6708 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6708 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6705 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6704 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6703 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6703 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6701 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6701 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6699 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6699 - accuracy: 0.507 - 3s 5ms/step - loss: 0.6697 - accuracy: 0.508 - 3s 5ms/step - loss: 0.6695 - accuracy: 0.508 - 3s 5ms/step - loss: 0.6695 - accuracy: 0.508 - 3s 5ms/step - loss: 0.6695 - accuracy: 0.509 - 3s 5ms/step - loss: 0.6694 - accuracy: 0.509 - 3s 5ms/step - loss: 0.6693 - accuracy: 0.509 - 3s 5ms/step - loss: 0.6692 - accuracy: 0.509 - 3s 5ms/step - loss: 0.6691 - accuracy: 0.509 - 3s 5ms/step - loss: 0.6690 - accuracy: 0.509 - 3s 5ms/step - loss: 0.6689 - accuracy: 0.509 - 3s 5ms/step - loss: 0.6688 - accuracy: 0.509 - 3s 5ms/step - loss: 0.6687 - accuracy: 0.510 - 3s 5ms/step - loss: 0.6687 - accuracy: 0.510 - 3s 5ms/step - loss: 0.6685 - accuracy: 0.510 - 3s 5ms/step - loss: 0.6684 - accuracy: 0.510 - 3s 5ms/step - loss: 0.6683 - accuracy: 0.510 - 3s 5ms/step - loss: 0.6683 - accuracy: 0.510 - 3s 5ms/step - loss: 0.6682 - accuracy: 0.510 - 3s 5ms/step - loss: 0.6682 - accuracy: 0.510 - 3s 5ms/step - loss: 0.6682 - accuracy: 0.510 - 3s 5ms/step - loss: 0.6680 - accuracy: 0.510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1185/Unknown - 4s 4ms/step - loss: 0.6365 - accuracy: 0.548 - 4s 4ms/step - loss: 0.6364 - accuracy: 0.548 - 4s 4ms/step - loss: 0.6363 - accuracy: 0.548 - 4s 4ms/step - loss: 0.6362 - accuracy: 0.548 - 4s 4ms/step - loss: 0.6360 - accuracy: 0.548 - 4s 4ms/step - loss: 0.6359 - accuracy: 0.549 - 4s 4ms/step - loss: 0.6356 - accuracy: 0.549 - 4s 4ms/step - loss: 0.6356 - accuracy: 0.549 - 4s 4ms/step - loss: 0.6355 - accuracy: 0.550 - 4s 4ms/step - loss: 0.6355 - accuracy: 0.550 - 4s 4ms/step - loss: 0.6354 - accuracy: 0.550 - 4s 4ms/step - loss: 0.6353 - accuracy: 0.550 - 4s 4ms/step - loss: 0.6351 - accuracy: 0.551 - 4s 4ms/step - loss: 0.6351 - accuracy: 0.551 - 4s 4ms/step - loss: 0.6350 - accuracy: 0.551 - 4s 4ms/step - loss: 0.6348 - accuracy: 0.551 - 4s 4ms/step - loss: 0.6346 - accuracy: 0.551 - 4s 4ms/step - loss: 0.6344 - accuracy: 0.552 - 4s 4ms/step - loss: 0.6342 - accuracy: 0.552 - 4s 4ms/step - loss: 0.6342 - accuracy: 0.552 - 4s 4ms/step - loss: 0.6340 - accuracy: 0.552 - 4s 4ms/step - loss: 0.6337 - accuracy: 0.552 - 4s 4ms/step - loss: 0.6336 - accuracy: 0.552 - 4s 4ms/step - loss: 0.6334 - accuracy: 0.553 - 4s 4ms/step - loss: 0.6333 - accuracy: 0.553 - 4s 4ms/step - loss: 0.6329 - accuracy: 0.553 - 4s 4ms/step - loss: 0.6328 - accuracy: 0.553 - 4s 4ms/step - loss: 0.6327 - accuracy: 0.553 - 4s 4ms/step - loss: 0.6327 - accuracy: 0.554 - 4s 4ms/step - loss: 0.6327 - accuracy: 0.553 - 4s 4ms/step - loss: 0.6327 - accuracy: 0.554 - 4s 4ms/step - loss: 0.6325 - accuracy: 0.554 - 4s 4ms/step - loss: 0.6323 - accuracy: 0.554 - 4s 4ms/step - loss: 0.6322 - accuracy: 0.554 - 4s 4ms/step - loss: 0.6320 - accuracy: 0.554 - 4s 4ms/step - loss: 0.6319 - accuracy: 0.554 - 4s 4ms/step - loss: 0.6317 - accuracy: 0.554 - 4s 4ms/step - loss: 0.6316 - accuracy: 0.554 - 4s 4ms/step - loss: 0.6318 - accuracy: 0.554 - 4s 4ms/step - loss: 0.6316 - accuracy: 0.554 - 4s 4ms/step - loss: 0.6315 - accuracy: 0.554 - 4s 4ms/step - loss: 0.6313 - accuracy: 0.555 - 4s 4ms/step - loss: 0.6311 - accuracy: 0.555 - 4s 4ms/step - loss: 0.6309 - accuracy: 0.555 - 4s 4ms/step - loss: 0.6308 - accuracy: 0.555 - 4s 4ms/step - loss: 0.6306 - accuracy: 0.555 - 4s 4ms/step - loss: 0.6305 - accuracy: 0.556 - 4s 4ms/step - loss: 0.6303 - accuracy: 0.556 - 4s 4ms/step - loss: 0.6303 - accuracy: 0.556 - 4s 4ms/step - loss: 0.6302 - accuracy: 0.556 - 4s 4ms/step - loss: 0.6302 - accuracy: 0.557 - 4s 4ms/step - loss: 0.6301 - accuracy: 0.557 - 4s 4ms/step - loss: 0.6300 - accuracy: 0.557 - 4s 4ms/step - loss: 0.6298 - accuracy: 0.557 - 4s 4ms/step - loss: 0.6298 - accuracy: 0.558 - 4s 4ms/step - loss: 0.6297 - accuracy: 0.558 - 4s 4ms/step - loss: 0.6296 - accuracy: 0.558 - 4s 4ms/step - loss: 0.6294 - accuracy: 0.558 - 4s 4ms/step - loss: 0.6293 - accuracy: 0.559 - 4s 4ms/step - loss: 0.6292 - accuracy: 0.559 - 4s 4ms/step - loss: 0.6291 - accuracy: 0.559 - 4s 4ms/step - loss: 0.6288 - accuracy: 0.559 - 4s 4ms/step - loss: 0.6287 - accuracy: 0.559 - 4s 4ms/step - loss: 0.6287 - accuracy: 0.559 - 4s 4ms/step - loss: 0.6284 - accuracy: 0.560 - 5s 4ms/step - loss: 0.6285 - accuracy: 0.560 - 5s 4ms/step - loss: 0.6284 - accuracy: 0.560 - 5s 4ms/step - loss: 0.6283 - accuracy: 0.560 - 5s 4ms/step - loss: 0.6281 - accuracy: 0.560 - 5s 4ms/step - loss: 0.6278 - accuracy: 0.561 - 5s 4ms/step - loss: 0.6275 - accuracy: 0.561 - 5s 4ms/step - loss: 0.6275 - accuracy: 0.561 - 5s 4ms/step - loss: 0.6274 - accuracy: 0.561 - 5s 4ms/step - loss: 0.6273 - accuracy: 0.561 - 5s 4ms/step - loss: 0.6271 - accuracy: 0.562 - 5s 4ms/step - loss: 0.6269 - accuracy: 0.562 - 5s 4ms/step - loss: 0.6268 - accuracy: 0.563 - 5s 4ms/step - loss: 0.6266 - accuracy: 0.563 - 5s 4ms/step - loss: 0.6265 - accuracy: 0.563 - 5s 4ms/step - loss: 0.6265 - accuracy: 0.563 - 5s 4ms/step - loss: 0.6264 - accuracy: 0.563 - 5s 4ms/step - loss: 0.6264 - accuracy: 0.563 - 5s 4ms/step - loss: 0.6263 - accuracy: 0.563 - 5s 4ms/step - loss: 0.6261 - accuracy: 0.563 - 5s 4ms/step - loss: 0.6261 - accuracy: 0.564 - 5s 4ms/step - loss: 0.6260 - accuracy: 0.564 - 5s 4ms/step - loss: 0.6257 - accuracy: 0.564 - 5s 4ms/step - loss: 0.6256 - accuracy: 0.564 - 5s 4ms/step - loss: 0.6253 - accuracy: 0.564 - 5s 4ms/step - loss: 0.6251 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6250 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6248 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6247 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6247 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6244 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6244 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6242 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6242 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6241 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6239 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6238 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6236 - accuracy: 0.565 - 5s 4ms/step - loss: 0.6235 - accuracy: 0.566 - 5s 4ms/step - loss: 0.6234 - accuracy: 0.566 - 5s 4ms/step - loss: 0.6234 - accuracy: 0.566 - 5s 4ms/step - loss: 0.6233 - accuracy: 0.566 - 5s 4ms/step - loss: 0.6231 - accuracy: 0.566 - 5s 4ms/step - loss: 0.6231 - accuracy: 0.566 - 5s 4ms/step - loss: 0.6229 - accuracy: 0.567 - 5s 4ms/step - loss: 0.6227 - accuracy: 0.567 - 5s 4ms/step - loss: 0.6225 - accuracy: 0.567 - 5s 4ms/step - loss: 0.6224 - accuracy: 0.567 - 5s 4ms/step - loss: 0.6223 - accuracy: 0.568 - 5s 4ms/step - loss: 0.6220 - accuracy: 0.568 - 5s 4ms/step - loss: 0.6218 - accuracy: 0.568 - 5s 4ms/step - loss: 0.6215 - accuracy: 0.569 - 5s 4ms/step - loss: 0.6213 - accuracy: 0.569 - 5s 4ms/step - loss: 0.6212 - accuracy: 0.569 - 5s 4ms/step - loss: 0.6209 - accuracy: 0.570 - 5s 4ms/step - loss: 0.6209 - accuracy: 0.570 - 5s 4ms/step - loss: 0.6207 - accuracy: 0.570 - 5s 4ms/step - loss: 0.6205 - accuracy: 0.570 - 5s 4ms/step - loss: 0.6204 - accuracy: 0.570 - 5s 4ms/step - loss: 0.6202 - accuracy: 0.570 - 5s 4ms/step - loss: 0.6199 - accuracy: 0.571 - 5s 4ms/step - loss: 0.6198 - accuracy: 0.571 - 5s 4ms/step - loss: 0.6198 - accuracy: 0.571 - 5s 4ms/step - loss: 0.6196 - accuracy: 0.571 - 5s 4ms/step - loss: 0.6195 - accuracy: 0.572 - 5s 4ms/step - loss: 0.6194 - accuracy: 0.572 - 5s 4ms/step - loss: 0.6194 - accuracy: 0.572 - 5s 4ms/step - loss: 0.6192 - accuracy: 0.572 - 5s 4ms/step - loss: 0.6191 - accuracy: 0.572 - 5s 4ms/step - loss: 0.6190 - accuracy: 0.573 - 5s 4ms/step - loss: 0.6188 - accuracy: 0.573 - 5s 4ms/step - loss: 0.6188 - accuracy: 0.573 - 5s 4ms/step - loss: 0.6186 - accuracy: 0.573 - 5s 4ms/step - loss: 0.6185 - accuracy: 0.574 - 5s 4ms/step - loss: 0.6185 - accuracy: 0.574 - 5s 4ms/step - loss: 0.6184 - accuracy: 0.574 - 5s 4ms/step - loss: 0.6183 - accuracy: 0.574 - 5s 4ms/step - loss: 0.6184 - accuracy: 0.574 - 5s 4ms/step - loss: 0.6185 - accuracy: 0.574 - 5s 4ms/step - loss: 0.6183 - accuracy: 0.574 - 5s 4ms/step - loss: 0.6182 - accuracy: 0.574 - 5s 4ms/step - loss: 0.6180 - accuracy: 0.574 - 5s 4ms/step - loss: 0.6180 - accuracy: 0.574 - 5s 4ms/step - loss: 0.6177 - accuracy: 0.575 - 5s 4ms/step - loss: 0.6176 - accuracy: 0.575 - 5s 4ms/step - loss: 0.6175 - accuracy: 0.575 - 5s 4ms/step - loss: 0.6172 - accuracy: 0.575 - 5s 4ms/step - loss: 0.6170 - accuracy: 0.575 - 5s 4ms/step - loss: 0.6169 - accuracy: 0.576 - 5s 4ms/step - loss: 0.6166 - accuracy: 0.576 - 5s 4ms/step - loss: 0.6167 - accuracy: 0.576 - 5s 4ms/step - loss: 0.6166 - accuracy: 0.576 - 5s 4ms/step - loss: 0.6166 - accuracy: 0.576 - 5s 4ms/step - loss: 0.6164 - accuracy: 0.576 - 5s 4ms/step - loss: 0.6162 - accuracy: 0.576 - 5s 4ms/step - loss: 0.6161 - accuracy: 0.576 - 5s 4ms/step - loss: 0.6160 - accuracy: 0.576 - 5s 4ms/step - loss: 0.6161 - accuracy: 0.576 - 5s 4ms/step - loss: 0.6159 - accuracy: 0.577 - 5s 4ms/step - loss: 0.6158 - accuracy: 0.577 - 5s 4ms/step - loss: 0.6155 - accuracy: 0.577 - 5s 4ms/step - loss: 0.6153 - accuracy: 0.577 - 5s 4ms/step - loss: 0.6153 - accuracy: 0.577 - 5s 4ms/step - loss: 0.6152 - accuracy: 0.577 - 5s 4ms/step - loss: 0.6150 - accuracy: 0.577 - 5s 4ms/step - loss: 0.6149 - accuracy: 0.577 - 5s 4ms/step - loss: 0.6149 - accuracy: 0.578 - 5s 4ms/step - loss: 0.6147 - accuracy: 0.578 - 5s 4ms/step - loss: 0.6146 - accuracy: 0.578 - 5s 4ms/step - loss: 0.6145 - accuracy: 0.5786"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1359/Unknown - 5s 4ms/step - loss: 0.6144 - accuracy: 0.578 - 5s 4ms/step - loss: 0.6142 - accuracy: 0.579 - 5s 4ms/step - loss: 0.6141 - accuracy: 0.579 - 5s 4ms/step - loss: 0.6140 - accuracy: 0.579 - 5s 4ms/step - loss: 0.6141 - accuracy: 0.579 - 5s 4ms/step - loss: 0.6139 - accuracy: 0.579 - 5s 4ms/step - loss: 0.6138 - accuracy: 0.580 - 5s 4ms/step - loss: 0.6136 - accuracy: 0.580 - 5s 4ms/step - loss: 0.6135 - accuracy: 0.580 - 5s 4ms/step - loss: 0.6134 - accuracy: 0.580 - 5s 4ms/step - loss: 0.6131 - accuracy: 0.580 - 5s 4ms/step - loss: 0.6129 - accuracy: 0.581 - 5s 4ms/step - loss: 0.6129 - accuracy: 0.581 - 5s 4ms/step - loss: 0.6127 - accuracy: 0.581 - 5s 4ms/step - loss: 0.6126 - accuracy: 0.581 - 5s 4ms/step - loss: 0.6124 - accuracy: 0.581 - 5s 4ms/step - loss: 0.6123 - accuracy: 0.582 - 5s 4ms/step - loss: 0.6122 - accuracy: 0.582 - 5s 4ms/step - loss: 0.6119 - accuracy: 0.582 - 5s 4ms/step - loss: 0.6118 - accuracy: 0.582 - 5s 4ms/step - loss: 0.6116 - accuracy: 0.582 - 5s 4ms/step - loss: 0.6115 - accuracy: 0.583 - 5s 4ms/step - loss: 0.6114 - accuracy: 0.583 - 5s 4ms/step - loss: 0.6112 - accuracy: 0.583 - 5s 4ms/step - loss: 0.6111 - accuracy: 0.583 - 5s 4ms/step - loss: 0.6111 - accuracy: 0.583 - 5s 4ms/step - loss: 0.6110 - accuracy: 0.583 - 5s 4ms/step - loss: 0.6109 - accuracy: 0.584 - 5s 4ms/step - loss: 0.6108 - accuracy: 0.583 - 5s 4ms/step - loss: 0.6107 - accuracy: 0.584 - 5s 4ms/step - loss: 0.6106 - accuracy: 0.584 - 5s 4ms/step - loss: 0.6105 - accuracy: 0.584 - 5s 4ms/step - loss: 0.6104 - accuracy: 0.584 - 5s 4ms/step - loss: 0.6102 - accuracy: 0.584 - 5s 4ms/step - loss: 0.6101 - accuracy: 0.585 - 5s 4ms/step - loss: 0.6099 - accuracy: 0.585 - 5s 4ms/step - loss: 0.6097 - accuracy: 0.585 - 5s 4ms/step - loss: 0.6096 - accuracy: 0.585 - 5s 4ms/step - loss: 0.6093 - accuracy: 0.585 - 5s 4ms/step - loss: 0.6091 - accuracy: 0.586 - 5s 4ms/step - loss: 0.6090 - accuracy: 0.586 - 5s 4ms/step - loss: 0.6088 - accuracy: 0.586 - 5s 4ms/step - loss: 0.6087 - accuracy: 0.586 - 5s 4ms/step - loss: 0.6084 - accuracy: 0.587 - 5s 4ms/step - loss: 0.6083 - accuracy: 0.587 - 5s 4ms/step - loss: 0.6082 - accuracy: 0.587 - 5s 4ms/step - loss: 0.6082 - accuracy: 0.587 - 5s 4ms/step - loss: 0.6082 - accuracy: 0.587 - 5s 4ms/step - loss: 0.6081 - accuracy: 0.587 - 5s 4ms/step - loss: 0.6080 - accuracy: 0.587 - 5s 4ms/step - loss: 0.6079 - accuracy: 0.587 - 5s 4ms/step - loss: 0.6076 - accuracy: 0.588 - 5s 4ms/step - loss: 0.6074 - accuracy: 0.588 - 5s 4ms/step - loss: 0.6073 - accuracy: 0.588 - 5s 4ms/step - loss: 0.6072 - accuracy: 0.588 - 5s 4ms/step - loss: 0.6071 - accuracy: 0.588 - 5s 4ms/step - loss: 0.6070 - accuracy: 0.588 - 5s 4ms/step - loss: 0.6068 - accuracy: 0.588 - 5s 4ms/step - loss: 0.6067 - accuracy: 0.588 - 5s 4ms/step - loss: 0.6065 - accuracy: 0.589 - 5s 4ms/step - loss: 0.6064 - accuracy: 0.589 - 5s 4ms/step - loss: 0.6062 - accuracy: 0.589 - 5s 4ms/step - loss: 0.6062 - accuracy: 0.589 - 5s 4ms/step - loss: 0.6061 - accuracy: 0.589 - 5s 4ms/step - loss: 0.6059 - accuracy: 0.589 - 5s 4ms/step - loss: 0.6058 - accuracy: 0.590 - 5s 4ms/step - loss: 0.6057 - accuracy: 0.590 - 5s 4ms/step - loss: 0.6056 - accuracy: 0.590 - 5s 4ms/step - loss: 0.6054 - accuracy: 0.590 - 5s 4ms/step - loss: 0.6053 - accuracy: 0.590 - 5s 4ms/step - loss: 0.6052 - accuracy: 0.590 - 5s 4ms/step - loss: 0.6052 - accuracy: 0.590 - 5s 4ms/step - loss: 0.6051 - accuracy: 0.590 - 5s 4ms/step - loss: 0.6049 - accuracy: 0.590 - 5s 4ms/step - loss: 0.6048 - accuracy: 0.590 - 5s 4ms/step - loss: 0.6047 - accuracy: 0.590 - 5s 4ms/step - loss: 0.6045 - accuracy: 0.590 - 5s 4ms/step - loss: 0.6044 - accuracy: 0.591 - 5s 4ms/step - loss: 0.6042 - accuracy: 0.591 - 5s 4ms/step - loss: 0.6041 - accuracy: 0.591 - 5s 4ms/step - loss: 0.6040 - accuracy: 0.591 - 5s 4ms/step - loss: 0.6041 - accuracy: 0.591 - 5s 4ms/step - loss: 0.6041 - accuracy: 0.591 - 5s 4ms/step - loss: 0.6040 - accuracy: 0.592 - 5s 4ms/step - loss: 0.6038 - accuracy: 0.592 - 5s 4ms/step - loss: 0.6037 - accuracy: 0.592 - 5s 4ms/step - loss: 0.6035 - accuracy: 0.592 - 5s 4ms/step - loss: 0.6034 - accuracy: 0.592 - 5s 4ms/step - loss: 0.6034 - accuracy: 0.592 - 5s 4ms/step - loss: 0.6032 - accuracy: 0.593 - 5s 4ms/step - loss: 0.6029 - accuracy: 0.593 - 5s 4ms/step - loss: 0.6029 - accuracy: 0.593 - 5s 4ms/step - loss: 0.6027 - accuracy: 0.593 - 5s 4ms/step - loss: 0.6026 - accuracy: 0.593 - 5s 4ms/step - loss: 0.6026 - accuracy: 0.593 - 5s 4ms/step - loss: 0.6024 - accuracy: 0.593 - 5s 4ms/step - loss: 0.6022 - accuracy: 0.593 - 5s 4ms/step - loss: 0.6021 - accuracy: 0.593 - 5s 4ms/step - loss: 0.6021 - accuracy: 0.593 - 5s 4ms/step - loss: 0.6020 - accuracy: 0.593 - 5s 4ms/step - loss: 0.6019 - accuracy: 0.594 - 5s 4ms/step - loss: 0.6017 - accuracy: 0.594 - 5s 4ms/step - loss: 0.6014 - accuracy: 0.594 - 5s 4ms/step - loss: 0.6013 - accuracy: 0.594 - 5s 4ms/step - loss: 0.6013 - accuracy: 0.595 - 5s 4ms/step - loss: 0.6011 - accuracy: 0.595 - 5s 4ms/step - loss: 0.6009 - accuracy: 0.595 - 5s 4ms/step - loss: 0.6008 - accuracy: 0.595 - 5s 4ms/step - loss: 0.6007 - accuracy: 0.595 - 5s 4ms/step - loss: 0.6005 - accuracy: 0.596 - 5s 4ms/step - loss: 0.6004 - accuracy: 0.596 - 5s 4ms/step - loss: 0.6001 - accuracy: 0.596 - 5s 4ms/step - loss: 0.6001 - accuracy: 0.596 - 5s 4ms/step - loss: 0.5999 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5997 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5996 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5994 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5992 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5990 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5989 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5987 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5986 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5986 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5984 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5981 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5982 - accuracy: 0.597 - 5s 4ms/step - loss: 0.5981 - accuracy: 0.598 - 5s 4ms/step - loss: 0.5980 - accuracy: 0.598 - 5s 4ms/step - loss: 0.5979 - accuracy: 0.598 - 5s 4ms/step - loss: 0.5978 - accuracy: 0.598 - 5s 4ms/step - loss: 0.5976 - accuracy: 0.598 - 5s 4ms/step - loss: 0.5973 - accuracy: 0.598 - 5s 4ms/step - loss: 0.5971 - accuracy: 0.599 - 5s 4ms/step - loss: 0.5968 - accuracy: 0.599 - 5s 4ms/step - loss: 0.5969 - accuracy: 0.599 - 5s 4ms/step - loss: 0.5969 - accuracy: 0.599 - 5s 4ms/step - loss: 0.5969 - accuracy: 0.599 - 5s 4ms/step - loss: 0.5967 - accuracy: 0.599 - 5s 4ms/step - loss: 0.5966 - accuracy: 0.600 - 5s 4ms/step - loss: 0.5966 - accuracy: 0.600 - 5s 4ms/step - loss: 0.5965 - accuracy: 0.600 - 5s 4ms/step - loss: 0.5964 - accuracy: 0.600 - 5s 4ms/step - loss: 0.5964 - accuracy: 0.600 - 5s 4ms/step - loss: 0.5964 - accuracy: 0.601 - 5s 4ms/step - loss: 0.5963 - accuracy: 0.601 - 5s 4ms/step - loss: 0.5961 - accuracy: 0.601 - 5s 4ms/step - loss: 0.5960 - accuracy: 0.601 - 5s 4ms/step - loss: 0.5958 - accuracy: 0.601 - 5s 4ms/step - loss: 0.5956 - accuracy: 0.601 - 5s 4ms/step - loss: 0.5955 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5953 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5952 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5953 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5951 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5950 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5948 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5948 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5949 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5949 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5948 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5950 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5947 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5948 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5947 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5946 - accuracy: 0.602 - 5s 4ms/step - loss: 0.5944 - accuracy: 0.603 - 5s 4ms/step - loss: 0.5943 - accuracy: 0.603 - 5s 4ms/step - loss: 0.5941 - accuracy: 0.603 - 5s 4ms/step - loss: 0.5939 - accuracy: 0.603 - 5s 4ms/step - loss: 0.5938 - accuracy: 0.603 - 6s 4ms/step - loss: 0.5937 - accuracy: 0.603 - 6s 4ms/step - loss: 0.5936 - accuracy: 0.604 - 6s 4ms/step - loss: 0.5935 - accuracy: 0.604 - 6s 4ms/step - loss: 0.5936 - accuracy: 0.6043"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1533/Unknown - 6s 4ms/step - loss: 0.5935 - accuracy: 0.604 - 6s 4ms/step - loss: 0.5935 - accuracy: 0.604 - 6s 4ms/step - loss: 0.5932 - accuracy: 0.604 - 6s 4ms/step - loss: 0.5932 - accuracy: 0.604 - 6s 4ms/step - loss: 0.5931 - accuracy: 0.604 - 6s 4ms/step - loss: 0.5930 - accuracy: 0.605 - 6s 4ms/step - loss: 0.5929 - accuracy: 0.605 - 6s 4ms/step - loss: 0.5929 - accuracy: 0.605 - 6s 4ms/step - loss: 0.5927 - accuracy: 0.605 - 6s 4ms/step - loss: 0.5925 - accuracy: 0.605 - 6s 4ms/step - loss: 0.5925 - accuracy: 0.605 - 6s 4ms/step - loss: 0.5925 - accuracy: 0.605 - 6s 4ms/step - loss: 0.5923 - accuracy: 0.605 - 6s 4ms/step - loss: 0.5922 - accuracy: 0.606 - 6s 4ms/step - loss: 0.5920 - accuracy: 0.606 - 6s 4ms/step - loss: 0.5917 - accuracy: 0.606 - 6s 4ms/step - loss: 0.5915 - accuracy: 0.606 - 6s 4ms/step - loss: 0.5914 - accuracy: 0.606 - 6s 4ms/step - loss: 0.5912 - accuracy: 0.606 - 6s 4ms/step - loss: 0.5911 - accuracy: 0.606 - 6s 4ms/step - loss: 0.5909 - accuracy: 0.607 - 6s 4ms/step - loss: 0.5909 - accuracy: 0.607 - 6s 4ms/step - loss: 0.5908 - accuracy: 0.607 - 6s 4ms/step - loss: 0.5907 - accuracy: 0.607 - 6s 4ms/step - loss: 0.5906 - accuracy: 0.607 - 6s 4ms/step - loss: 0.5905 - accuracy: 0.607 - 6s 4ms/step - loss: 0.5905 - accuracy: 0.607 - 6s 4ms/step - loss: 0.5904 - accuracy: 0.607 - 6s 4ms/step - loss: 0.5902 - accuracy: 0.607 - 6s 4ms/step - loss: 0.5900 - accuracy: 0.608 - 6s 4ms/step - loss: 0.5899 - accuracy: 0.608 - 6s 4ms/step - loss: 0.5897 - accuracy: 0.608 - 6s 4ms/step - loss: 0.5895 - accuracy: 0.608 - 6s 4ms/step - loss: 0.5894 - accuracy: 0.608 - 6s 4ms/step - loss: 0.5893 - accuracy: 0.608 - 6s 4ms/step - loss: 0.5891 - accuracy: 0.609 - 6s 4ms/step - loss: 0.5889 - accuracy: 0.609 - 6s 4ms/step - loss: 0.5890 - accuracy: 0.609 - 6s 4ms/step - loss: 0.5887 - accuracy: 0.609 - 6s 4ms/step - loss: 0.5887 - accuracy: 0.609 - 6s 4ms/step - loss: 0.5885 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5884 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5882 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5881 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5880 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5879 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5879 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5879 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5876 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5876 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5876 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5877 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5875 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5874 - accuracy: 0.610 - 6s 4ms/step - loss: 0.5872 - accuracy: 0.611 - 6s 4ms/step - loss: 0.5871 - accuracy: 0.611 - 6s 4ms/step - loss: 0.5869 - accuracy: 0.611 - 6s 4ms/step - loss: 0.5868 - accuracy: 0.611 - 6s 4ms/step - loss: 0.5868 - accuracy: 0.611 - 6s 4ms/step - loss: 0.5866 - accuracy: 0.611 - 6s 4ms/step - loss: 0.5864 - accuracy: 0.612 - 6s 4ms/step - loss: 0.5865 - accuracy: 0.612 - 6s 4ms/step - loss: 0.5864 - accuracy: 0.612 - 6s 4ms/step - loss: 0.5865 - accuracy: 0.612 - 6s 4ms/step - loss: 0.5865 - accuracy: 0.612 - 6s 4ms/step - loss: 0.5864 - accuracy: 0.612 - 6s 4ms/step - loss: 0.5862 - accuracy: 0.612 - 6s 4ms/step - loss: 0.5861 - accuracy: 0.613 - 6s 4ms/step - loss: 0.5859 - accuracy: 0.613 - 6s 4ms/step - loss: 0.5857 - accuracy: 0.613 - 6s 4ms/step - loss: 0.5856 - accuracy: 0.613 - 6s 4ms/step - loss: 0.5854 - accuracy: 0.613 - 6s 4ms/step - loss: 0.5852 - accuracy: 0.613 - 6s 4ms/step - loss: 0.5851 - accuracy: 0.614 - 6s 4ms/step - loss: 0.5850 - accuracy: 0.614 - 6s 4ms/step - loss: 0.5849 - accuracy: 0.614 - 6s 4ms/step - loss: 0.5849 - accuracy: 0.614 - 6s 4ms/step - loss: 0.5846 - accuracy: 0.614 - 6s 4ms/step - loss: 0.5845 - accuracy: 0.614 - 6s 4ms/step - loss: 0.5842 - accuracy: 0.614 - 6s 4ms/step - loss: 0.5842 - accuracy: 0.614 - 6s 4ms/step - loss: 0.5840 - accuracy: 0.614 - 6s 4ms/step - loss: 0.5839 - accuracy: 0.614 - 6s 4ms/step - loss: 0.5838 - accuracy: 0.614 - 6s 4ms/step - loss: 0.5836 - accuracy: 0.615 - 6s 4ms/step - loss: 0.5834 - accuracy: 0.615 - 6s 4ms/step - loss: 0.5832 - accuracy: 0.615 - 6s 4ms/step - loss: 0.5830 - accuracy: 0.615 - 6s 4ms/step - loss: 0.5828 - accuracy: 0.615 - 6s 4ms/step - loss: 0.5827 - accuracy: 0.615 - 6s 4ms/step - loss: 0.5826 - accuracy: 0.616 - 6s 4ms/step - loss: 0.5825 - accuracy: 0.616 - 6s 4ms/step - loss: 0.5822 - accuracy: 0.616 - 6s 4ms/step - loss: 0.5821 - accuracy: 0.616 - 6s 4ms/step - loss: 0.5821 - accuracy: 0.616 - 6s 4ms/step - loss: 0.5818 - accuracy: 0.616 - 6s 4ms/step - loss: 0.5818 - accuracy: 0.617 - 6s 4ms/step - loss: 0.5815 - accuracy: 0.617 - 6s 4ms/step - loss: 0.5813 - accuracy: 0.617 - 6s 4ms/step - loss: 0.5811 - accuracy: 0.617 - 6s 4ms/step - loss: 0.5810 - accuracy: 0.617 - 6s 4ms/step - loss: 0.5809 - accuracy: 0.617 - 6s 4ms/step - loss: 0.5808 - accuracy: 0.618 - 6s 4ms/step - loss: 0.5807 - accuracy: 0.618 - 6s 4ms/step - loss: 0.5806 - accuracy: 0.618 - 6s 4ms/step - loss: 0.5806 - accuracy: 0.618 - 6s 4ms/step - loss: 0.5806 - accuracy: 0.618 - 6s 4ms/step - loss: 0.5805 - accuracy: 0.619 - 6s 4ms/step - loss: 0.5805 - accuracy: 0.618 - 6s 4ms/step - loss: 0.5803 - accuracy: 0.619 - 6s 4ms/step - loss: 0.5801 - accuracy: 0.619 - 6s 4ms/step - loss: 0.5799 - accuracy: 0.619 - 6s 4ms/step - loss: 0.5797 - accuracy: 0.619 - 6s 4ms/step - loss: 0.5795 - accuracy: 0.620 - 6s 4ms/step - loss: 0.5793 - accuracy: 0.620 - 6s 4ms/step - loss: 0.5793 - accuracy: 0.620 - 6s 4ms/step - loss: 0.5791 - accuracy: 0.620 - 6s 4ms/step - loss: 0.5791 - accuracy: 0.620 - 6s 4ms/step - loss: 0.5788 - accuracy: 0.620 - 6s 4ms/step - loss: 0.5786 - accuracy: 0.621 - 6s 4ms/step - loss: 0.5784 - accuracy: 0.621 - 6s 4ms/step - loss: 0.5783 - accuracy: 0.621 - 6s 4ms/step - loss: 0.5782 - accuracy: 0.621 - 6s 4ms/step - loss: 0.5781 - accuracy: 0.621 - 6s 4ms/step - loss: 0.5780 - accuracy: 0.621 - 6s 4ms/step - loss: 0.5778 - accuracy: 0.621 - 6s 4ms/step - loss: 0.5777 - accuracy: 0.621 - 6s 4ms/step - loss: 0.5776 - accuracy: 0.622 - 6s 4ms/step - loss: 0.5774 - accuracy: 0.622 - 6s 4ms/step - loss: 0.5774 - accuracy: 0.622 - 6s 4ms/step - loss: 0.5772 - accuracy: 0.622 - 6s 4ms/step - loss: 0.5772 - accuracy: 0.622 - 6s 4ms/step - loss: 0.5770 - accuracy: 0.622 - 6s 4ms/step - loss: 0.5768 - accuracy: 0.622 - 6s 4ms/step - loss: 0.5768 - accuracy: 0.622 - 6s 4ms/step - loss: 0.5765 - accuracy: 0.623 - 6s 4ms/step - loss: 0.5765 - accuracy: 0.623 - 6s 4ms/step - loss: 0.5765 - accuracy: 0.623 - 6s 4ms/step - loss: 0.5764 - accuracy: 0.623 - 6s 4ms/step - loss: 0.5762 - accuracy: 0.623 - 6s 4ms/step - loss: 0.5760 - accuracy: 0.623 - 6s 4ms/step - loss: 0.5759 - accuracy: 0.623 - 6s 4ms/step - loss: 0.5758 - accuracy: 0.623 - 6s 4ms/step - loss: 0.5758 - accuracy: 0.623 - 6s 4ms/step - loss: 0.5757 - accuracy: 0.623 - 6s 4ms/step - loss: 0.5757 - accuracy: 0.624 - 6s 4ms/step - loss: 0.5756 - accuracy: 0.624 - 6s 4ms/step - loss: 0.5755 - accuracy: 0.624 - 6s 4ms/step - loss: 0.5754 - accuracy: 0.624 - 6s 4ms/step - loss: 0.5754 - accuracy: 0.624 - 6s 4ms/step - loss: 0.5752 - accuracy: 0.624 - 6s 4ms/step - loss: 0.5753 - accuracy: 0.624 - 6s 4ms/step - loss: 0.5750 - accuracy: 0.624 - 6s 4ms/step - loss: 0.5749 - accuracy: 0.624 - 6s 4ms/step - loss: 0.5748 - accuracy: 0.624 - 6s 4ms/step - loss: 0.5746 - accuracy: 0.625 - 6s 4ms/step - loss: 0.5744 - accuracy: 0.625 - 6s 4ms/step - loss: 0.5742 - accuracy: 0.625 - 6s 4ms/step - loss: 0.5740 - accuracy: 0.625 - 6s 4ms/step - loss: 0.5740 - accuracy: 0.625 - 6s 4ms/step - loss: 0.5739 - accuracy: 0.625 - 6s 4ms/step - loss: 0.5739 - accuracy: 0.625 - 6s 4ms/step - loss: 0.5738 - accuracy: 0.626 - 6s 4ms/step - loss: 0.5735 - accuracy: 0.626 - 6s 4ms/step - loss: 0.5734 - accuracy: 0.626 - 6s 4ms/step - loss: 0.5732 - accuracy: 0.626 - 6s 4ms/step - loss: 0.5731 - accuracy: 0.626 - 6s 4ms/step - loss: 0.5729 - accuracy: 0.626 - 6s 4ms/step - loss: 0.5729 - accuracy: 0.627 - 6s 4ms/step - loss: 0.5728 - accuracy: 0.627 - 6s 4ms/step - loss: 0.5728 - accuracy: 0.627 - 6s 4ms/step - loss: 0.5727 - accuracy: 0.627 - 6s 4ms/step - loss: 0.5727 - accuracy: 0.627 - 6s 4ms/step - loss: 0.5725 - accuracy: 0.6274"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1707/Unknown - 6s 4ms/step - loss: 0.5723 - accuracy: 0.627 - 6s 4ms/step - loss: 0.5721 - accuracy: 0.627 - 6s 4ms/step - loss: 0.5721 - accuracy: 0.627 - 6s 4ms/step - loss: 0.5719 - accuracy: 0.627 - 6s 4ms/step - loss: 0.5718 - accuracy: 0.628 - 6s 4ms/step - loss: 0.5716 - accuracy: 0.628 - 6s 4ms/step - loss: 0.5716 - accuracy: 0.628 - 6s 4ms/step - loss: 0.5716 - accuracy: 0.628 - 6s 4ms/step - loss: 0.5715 - accuracy: 0.628 - 6s 4ms/step - loss: 0.5713 - accuracy: 0.628 - 6s 4ms/step - loss: 0.5710 - accuracy: 0.628 - 6s 4ms/step - loss: 0.5709 - accuracy: 0.628 - 6s 4ms/step - loss: 0.5708 - accuracy: 0.628 - 6s 4ms/step - loss: 0.5708 - accuracy: 0.628 - 6s 4ms/step - loss: 0.5707 - accuracy: 0.629 - 6s 4ms/step - loss: 0.5704 - accuracy: 0.629 - 6s 4ms/step - loss: 0.5704 - accuracy: 0.629 - 6s 4ms/step - loss: 0.5703 - accuracy: 0.629 - 6s 4ms/step - loss: 0.5703 - accuracy: 0.629 - 6s 4ms/step - loss: 0.5704 - accuracy: 0.629 - 6s 4ms/step - loss: 0.5702 - accuracy: 0.629 - 6s 4ms/step - loss: 0.5700 - accuracy: 0.629 - 6s 4ms/step - loss: 0.5700 - accuracy: 0.629 - 6s 4ms/step - loss: 0.5698 - accuracy: 0.630 - 6s 4ms/step - loss: 0.5697 - accuracy: 0.630 - 6s 4ms/step - loss: 0.5696 - accuracy: 0.630 - 6s 4ms/step - loss: 0.5694 - accuracy: 0.630 - 6s 4ms/step - loss: 0.5693 - accuracy: 0.630 - 6s 4ms/step - loss: 0.5692 - accuracy: 0.630 - 6s 4ms/step - loss: 0.5692 - accuracy: 0.630 - 6s 4ms/step - loss: 0.5691 - accuracy: 0.630 - 6s 4ms/step - loss: 0.5691 - accuracy: 0.631 - 6s 4ms/step - loss: 0.5690 - accuracy: 0.631 - 6s 4ms/step - loss: 0.5689 - accuracy: 0.631 - 6s 4ms/step - loss: 0.5688 - accuracy: 0.631 - 6s 4ms/step - loss: 0.5687 - accuracy: 0.631 - 6s 4ms/step - loss: 0.5687 - accuracy: 0.631 - 6s 4ms/step - loss: 0.5687 - accuracy: 0.631 - 6s 4ms/step - loss: 0.5685 - accuracy: 0.631 - 6s 4ms/step - loss: 0.5687 - accuracy: 0.631 - 6s 4ms/step - loss: 0.5686 - accuracy: 0.631 - 6s 4ms/step - loss: 0.5684 - accuracy: 0.631 - 6s 4ms/step - loss: 0.5682 - accuracy: 0.632 - 6s 4ms/step - loss: 0.5681 - accuracy: 0.632 - 6s 4ms/step - loss: 0.5680 - accuracy: 0.632 - 6s 4ms/step - loss: 0.5678 - accuracy: 0.632 - 6s 4ms/step - loss: 0.5677 - accuracy: 0.632 - 6s 4ms/step - loss: 0.5677 - accuracy: 0.632 - 6s 4ms/step - loss: 0.5676 - accuracy: 0.632 - 6s 4ms/step - loss: 0.5675 - accuracy: 0.632 - 6s 4ms/step - loss: 0.5673 - accuracy: 0.632 - 6s 4ms/step - loss: 0.5671 - accuracy: 0.632 - 6s 4ms/step - loss: 0.5670 - accuracy: 0.633 - 6s 4ms/step - loss: 0.5669 - accuracy: 0.633 - 6s 4ms/step - loss: 0.5668 - accuracy: 0.633 - 6s 4ms/step - loss: 0.5667 - accuracy: 0.633 - 6s 4ms/step - loss: 0.5666 - accuracy: 0.633 - 6s 4ms/step - loss: 0.5664 - accuracy: 0.633 - 6s 4ms/step - loss: 0.5663 - accuracy: 0.633 - 6s 4ms/step - loss: 0.5661 - accuracy: 0.634 - 6s 4ms/step - loss: 0.5659 - accuracy: 0.634 - 6s 4ms/step - loss: 0.5657 - accuracy: 0.634 - 6s 4ms/step - loss: 0.5657 - accuracy: 0.634 - 6s 4ms/step - loss: 0.5656 - accuracy: 0.634 - 6s 4ms/step - loss: 0.5655 - accuracy: 0.634 - 6s 4ms/step - loss: 0.5653 - accuracy: 0.635 - 6s 4ms/step - loss: 0.5651 - accuracy: 0.635 - 6s 4ms/step - loss: 0.5651 - accuracy: 0.635 - 6s 4ms/step - loss: 0.5648 - accuracy: 0.635 - 6s 4ms/step - loss: 0.5647 - accuracy: 0.635 - 6s 4ms/step - loss: 0.5645 - accuracy: 0.635 - 6s 4ms/step - loss: 0.5643 - accuracy: 0.635 - 6s 4ms/step - loss: 0.5642 - accuracy: 0.635 - 6s 4ms/step - loss: 0.5641 - accuracy: 0.635 - 6s 4ms/step - loss: 0.5640 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5638 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5638 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5637 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5635 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5634 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5633 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5632 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5633 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5632 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5633 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5632 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5632 - accuracy: 0.636 - 6s 4ms/step - loss: 0.5631 - accuracy: 0.637 - 6s 4ms/step - loss: 0.5630 - accuracy: 0.637 - 6s 4ms/step - loss: 0.5629 - accuracy: 0.637 - 6s 4ms/step - loss: 0.5628 - accuracy: 0.637 - 6s 4ms/step - loss: 0.5627 - accuracy: 0.637 - 6s 4ms/step - loss: 0.5627 - accuracy: 0.637 - 6s 4ms/step - loss: 0.5625 - accuracy: 0.637 - 6s 4ms/step - loss: 0.5623 - accuracy: 0.638 - 6s 4ms/step - loss: 0.5623 - accuracy: 0.638 - 6s 4ms/step - loss: 0.5622 - accuracy: 0.638 - 6s 4ms/step - loss: 0.5622 - accuracy: 0.638 - 6s 4ms/step - loss: 0.5620 - accuracy: 0.638 - 6s 4ms/step - loss: 0.5619 - accuracy: 0.638 - 6s 4ms/step - loss: 0.5618 - accuracy: 0.638 - 6s 4ms/step - loss: 0.5616 - accuracy: 0.638 - 6s 4ms/step - loss: 0.5616 - accuracy: 0.638 - 7s 4ms/step - loss: 0.5616 - accuracy: 0.639 - 7s 4ms/step - loss: 0.5614 - accuracy: 0.639 - 7s 4ms/step - loss: 0.5614 - accuracy: 0.639 - 7s 4ms/step - loss: 0.5614 - accuracy: 0.639 - 7s 4ms/step - loss: 0.5612 - accuracy: 0.639 - 7s 4ms/step - loss: 0.5610 - accuracy: 0.639 - 7s 4ms/step - loss: 0.5609 - accuracy: 0.639 - 7s 4ms/step - loss: 0.5608 - accuracy: 0.639 - 7s 4ms/step - loss: 0.5607 - accuracy: 0.639 - 7s 4ms/step - loss: 0.5606 - accuracy: 0.640 - 7s 4ms/step - loss: 0.5605 - accuracy: 0.640 - 7s 4ms/step - loss: 0.5605 - accuracy: 0.640 - 7s 4ms/step - loss: 0.5604 - accuracy: 0.640 - 7s 4ms/step - loss: 0.5603 - accuracy: 0.640 - 7s 4ms/step - loss: 0.5603 - accuracy: 0.640 - 7s 4ms/step - loss: 0.5604 - accuracy: 0.640 - 7s 4ms/step - loss: 0.5603 - accuracy: 0.640 - 7s 4ms/step - loss: 0.5602 - accuracy: 0.640 - 7s 4ms/step - loss: 0.5601 - accuracy: 0.640 - 7s 4ms/step - loss: 0.5601 - accuracy: 0.640 - 7s 4ms/step - loss: 0.5598 - accuracy: 0.641 - 7s 4ms/step - loss: 0.5598 - accuracy: 0.641 - 7s 4ms/step - loss: 0.5597 - accuracy: 0.641 - 7s 4ms/step - loss: 0.5595 - accuracy: 0.641 - 7s 4ms/step - loss: 0.5594 - accuracy: 0.641 - 7s 4ms/step - loss: 0.5592 - accuracy: 0.641 - 7s 4ms/step - loss: 0.5591 - accuracy: 0.641 - 7s 4ms/step - loss: 0.5590 - accuracy: 0.642 - 7s 4ms/step - loss: 0.5588 - accuracy: 0.642 - 7s 4ms/step - loss: 0.5587 - accuracy: 0.642 - 7s 4ms/step - loss: 0.5585 - accuracy: 0.642 - 7s 4ms/step - loss: 0.5584 - accuracy: 0.642 - 7s 4ms/step - loss: 0.5582 - accuracy: 0.643 - 7s 4ms/step - loss: 0.5581 - accuracy: 0.643 - 7s 4ms/step - loss: 0.5580 - accuracy: 0.643 - 7s 4ms/step - loss: 0.5579 - accuracy: 0.643 - 7s 4ms/step - loss: 0.5579 - accuracy: 0.643 - 7s 4ms/step - loss: 0.5579 - accuracy: 0.643 - 7s 4ms/step - loss: 0.5579 - accuracy: 0.643 - 7s 4ms/step - loss: 0.5577 - accuracy: 0.643 - 7s 4ms/step - loss: 0.5576 - accuracy: 0.643 - 7s 4ms/step - loss: 0.5574 - accuracy: 0.643 - 7s 4ms/step - loss: 0.5573 - accuracy: 0.644 - 7s 4ms/step - loss: 0.5572 - accuracy: 0.644 - 7s 4ms/step - loss: 0.5570 - accuracy: 0.644 - 7s 4ms/step - loss: 0.5569 - accuracy: 0.644 - 7s 4ms/step - loss: 0.5566 - accuracy: 0.644 - 7s 4ms/step - loss: 0.5564 - accuracy: 0.644 - 7s 4ms/step - loss: 0.5563 - accuracy: 0.645 - 7s 4ms/step - loss: 0.5560 - accuracy: 0.645 - 7s 4ms/step - loss: 0.5560 - accuracy: 0.645 - 7s 4ms/step - loss: 0.5559 - accuracy: 0.645 - 7s 4ms/step - loss: 0.5558 - accuracy: 0.645 - 7s 4ms/step - loss: 0.5558 - accuracy: 0.645 - 7s 4ms/step - loss: 0.5557 - accuracy: 0.645 - 7s 4ms/step - loss: 0.5556 - accuracy: 0.645 - 7s 4ms/step - loss: 0.5556 - accuracy: 0.645 - 7s 4ms/step - loss: 0.5555 - accuracy: 0.645 - 7s 4ms/step - loss: 0.5554 - accuracy: 0.645 - 7s 4ms/step - loss: 0.5553 - accuracy: 0.646 - 7s 4ms/step - loss: 0.5551 - accuracy: 0.646 - 7s 4ms/step - loss: 0.5549 - accuracy: 0.646 - 7s 4ms/step - loss: 0.5548 - accuracy: 0.646 - 7s 4ms/step - loss: 0.5547 - accuracy: 0.646 - 7s 4ms/step - loss: 0.5546 - accuracy: 0.646 - 7s 4ms/step - loss: 0.5545 - accuracy: 0.646 - 7s 4ms/step - loss: 0.5543 - accuracy: 0.647 - 7s 4ms/step - loss: 0.5542 - accuracy: 0.647 - 7s 4ms/step - loss: 0.5541 - accuracy: 0.647 - 7s 4ms/step - loss: 0.5541 - accuracy: 0.647 - 7s 4ms/step - loss: 0.5539 - accuracy: 0.6473"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1761/Unknown - 7s 4ms/step - loss: 0.5538 - accuracy: 0.647 - 7s 4ms/step - loss: 0.5537 - accuracy: 0.647 - 7s 4ms/step - loss: 0.5537 - accuracy: 0.647 - 7s 4ms/step - loss: 0.5538 - accuracy: 0.647 - 7s 4ms/step - loss: 0.5537 - accuracy: 0.647 - 7s 4ms/step - loss: 0.5536 - accuracy: 0.647 - 7s 4ms/step - loss: 0.5535 - accuracy: 0.648 - 7s 4ms/step - loss: 0.5534 - accuracy: 0.648 - 7s 4ms/step - loss: 0.5532 - accuracy: 0.648 - 7s 4ms/step - loss: 0.5530 - accuracy: 0.648 - 7s 4ms/step - loss: 0.5530 - accuracy: 0.648 - 7s 4ms/step - loss: 0.5528 - accuracy: 0.648 - 7s 4ms/step - loss: 0.5527 - accuracy: 0.648 - 7s 4ms/step - loss: 0.5525 - accuracy: 0.648 - 7s 4ms/step - loss: 0.5524 - accuracy: 0.648 - 7s 4ms/step - loss: 0.5522 - accuracy: 0.648 - 7s 4ms/step - loss: 0.5520 - accuracy: 0.649 - 7s 4ms/step - loss: 0.5519 - accuracy: 0.649 - 7s 4ms/step - loss: 0.5517 - accuracy: 0.649 - 7s 4ms/step - loss: 0.5517 - accuracy: 0.649 - 7s 4ms/step - loss: 0.5517 - accuracy: 0.649 - 7s 4ms/step - loss: 0.5515 - accuracy: 0.649 - 7s 4ms/step - loss: 0.5514 - accuracy: 0.649 - 7s 4ms/step - loss: 0.5513 - accuracy: 0.649 - 7s 4ms/step - loss: 0.5513 - accuracy: 0.649 - 7s 4ms/step - loss: 0.5512 - accuracy: 0.649 - 7s 4ms/step - loss: 0.5509 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5508 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5509 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5508 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5506 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5506 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5507 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5506 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5505 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5505 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5505 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5504 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5503 - accuracy: 0.651 - 7s 4ms/step - loss: 0.5503 - accuracy: 0.650 - 7s 4ms/step - loss: 0.5503 - accuracy: 0.651 - 7s 4ms/step - loss: 0.5502 - accuracy: 0.651 - 7s 4ms/step - loss: 0.5501 - accuracy: 0.651 - 7s 4ms/step - loss: 0.5500 - accuracy: 0.651 - 7s 4ms/step - loss: 0.5499 - accuracy: 0.651 - 7s 4ms/step - loss: 0.5499 - accuracy: 0.651 - 7s 4ms/step - loss: 0.5497 - accuracy: 0.651 - 7s 4ms/step - loss: 0.5496 - accuracy: 0.651 - 7s 4ms/step - loss: 0.5495 - accuracy: 0.651 - 7s 4ms/step - loss: 0.5493 - accuracy: 0.652 - 7s 4ms/step - loss: 0.5492 - accuracy: 0.652 - 7s 4ms/step - loss: 0.5491 - accuracy: 0.652 - 7s 4ms/step - loss: 0.5490 - accuracy: 0.652 - 7s 4ms/step - loss: 0.5489 - accuracy: 0.6525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2209/Unknown - 8s 4ms/step - loss: 0.5242 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5243 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5242 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5241 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5241 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5240 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5238 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5238 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5237 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5236 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5235 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5235 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5233 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5234 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5232 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5232 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5233 - accuracy: 0.677 - 8s 4ms/step - loss: 0.5231 - accuracy: 0.678 - 8s 4ms/step - loss: 0.5231 - accuracy: 0.678 - 8s 4ms/step - loss: 0.5230 - accuracy: 0.678 - 8s 4ms/step - loss: 0.5228 - accuracy: 0.678 - 8s 4ms/step - loss: 0.5227 - accuracy: 0.678 - 8s 4ms/step - loss: 0.5227 - accuracy: 0.678 - 8s 4ms/step - loss: 0.5226 - accuracy: 0.678 - 8s 4ms/step - loss: 0.5225 - accuracy: 0.678 - 8s 4ms/step - loss: 0.5224 - accuracy: 0.678 - 8s 4ms/step - loss: 0.5222 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5221 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5222 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5223 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5222 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5221 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5220 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5220 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5220 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5219 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5218 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5218 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5218 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5216 - accuracy: 0.679 - 8s 4ms/step - loss: 0.5215 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5215 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5214 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5214 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5213 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5211 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5210 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5208 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5208 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5207 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5207 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5206 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5206 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5206 - accuracy: 0.680 - 8s 4ms/step - loss: 0.5204 - accuracy: 0.681 - 8s 4ms/step - loss: 0.5204 - accuracy: 0.681 - 8s 4ms/step - loss: 0.5203 - accuracy: 0.681 - 8s 4ms/step - loss: 0.5203 - accuracy: 0.681 - 8s 4ms/step - loss: 0.5201 - accuracy: 0.681 - 8s 4ms/step - loss: 0.5200 - accuracy: 0.681 - 8s 4ms/step - loss: 0.5199 - accuracy: 0.681 - 8s 4ms/step - loss: 0.5198 - accuracy: 0.681 - 8s 4ms/step - loss: 0.5197 - accuracy: 0.681 - 8s 4ms/step - loss: 0.5196 - accuracy: 0.681 - 8s 4ms/step - loss: 0.5196 - accuracy: 0.681 - 8s 4ms/step - loss: 0.5195 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5194 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5193 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5192 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5191 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5190 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5188 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5190 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5189 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5190 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5190 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5190 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5190 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5189 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5188 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5187 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5186 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5186 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5185 - accuracy: 0.682 - 8s 4ms/step - loss: 0.5184 - accuracy: 0.683 - 8s 4ms/step - loss: 0.5183 - accuracy: 0.683 - 8s 4ms/step - loss: 0.5183 - accuracy: 0.683 - 8s 4ms/step - loss: 0.5183 - accuracy: 0.683 - 8s 4ms/step - loss: 0.5183 - accuracy: 0.683 - 8s 4ms/step - loss: 0.5182 - accuracy: 0.683 - 8s 4ms/step - loss: 0.5181 - accuracy: 0.683 - 8s 4ms/step - loss: 0.5180 - accuracy: 0.683 - 8s 4ms/step - loss: 0.5179 - accuracy: 0.683 - 8s 4ms/step - loss: 0.5178 - accuracy: 0.683 - 8s 4ms/step - loss: 0.5178 - accuracy: 0.683 - 8s 4ms/step - loss: 0.5177 - accuracy: 0.683 - 8s 4ms/step - loss: 0.5177 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5175 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5174 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5174 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5173 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5172 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5171 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5170 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5169 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5167 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5167 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5167 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5166 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5165 - accuracy: 0.684 - 8s 4ms/step - loss: 0.5163 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5162 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5163 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5162 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5162 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5161 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5160 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5159 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5158 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5157 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5157 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5156 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5156 - accuracy: 0.685 - 8s 4ms/step - loss: 0.5155 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5155 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5155 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5154 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5154 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5153 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5151 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5150 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5150 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5150 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5148 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5148 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5147 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5146 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5145 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5145 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5143 - accuracy: 0.686 - 8s 4ms/step - loss: 0.5142 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5141 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5140 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5140 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5139 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5139 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5138 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5137 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5135 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5134 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5134 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5134 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5133 - accuracy: 0.687 - 8s 4ms/step - loss: 0.5131 - accuracy: 0.688 - 8s 4ms/step - loss: 0.5132 - accuracy: 0.688 - 8s 4ms/step - loss: 0.5131 - accuracy: 0.688 - 8s 4ms/step - loss: 0.5129 - accuracy: 0.688 - 8s 4ms/step - loss: 0.5129 - accuracy: 0.688 - 8s 4ms/step - loss: 0.5128 - accuracy: 0.688 - 8s 4ms/step - loss: 0.5127 - accuracy: 0.688 - 8s 4ms/step - loss: 0.5126 - accuracy: 0.688 - 8s 4ms/step - loss: 0.5125 - accuracy: 0.688 - 8s 4ms/step - loss: 0.5124 - accuracy: 0.688 - 8s 4ms/step - loss: 0.5122 - accuracy: 0.688 - 8s 4ms/step - loss: 0.5123 - accuracy: 0.688 - 8s 4ms/step - loss: 0.5122 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5121 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5120 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5119 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5117 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5117 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5117 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5116 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5118 - accuracy: 0.6896"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2383/Unknown - 8s 4ms/step - loss: 0.5117 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5116 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5115 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5114 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5114 - accuracy: 0.689 - 8s 4ms/step - loss: 0.5113 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5113 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5114 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5113 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5113 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5113 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5112 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5112 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5111 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5109 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5109 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5109 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5108 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5107 - accuracy: 0.690 - 8s 4ms/step - loss: 0.5105 - accuracy: 0.690 - 9s 4ms/step - loss: 0.5105 - accuracy: 0.690 - 9s 4ms/step - loss: 0.5103 - accuracy: 0.690 - 9s 4ms/step - loss: 0.5102 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5101 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5099 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5099 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5098 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5098 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5097 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5096 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5094 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5094 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5095 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5094 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5093 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5092 - accuracy: 0.691 - 9s 4ms/step - loss: 0.5090 - accuracy: 0.692 - 9s 4ms/step - loss: 0.5089 - accuracy: 0.692 - 9s 4ms/step - loss: 0.5089 - accuracy: 0.692 - 9s 4ms/step - loss: 0.5087 - accuracy: 0.692 - 9s 4ms/step - loss: 0.5087 - accuracy: 0.692 - 9s 4ms/step - loss: 0.5087 - accuracy: 0.692 - 9s 4ms/step - loss: 0.5085 - accuracy: 0.692 - 9s 4ms/step - loss: 0.5084 - accuracy: 0.692 - 9s 4ms/step - loss: 0.5083 - accuracy: 0.692 - 9s 4ms/step - loss: 0.5082 - accuracy: 0.692 - 9s 4ms/step - loss: 0.5080 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5079 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5080 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5078 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5078 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5077 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5076 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5076 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5075 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5074 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5074 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5073 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5071 - accuracy: 0.693 - 9s 4ms/step - loss: 0.5070 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5069 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5068 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5067 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5068 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5069 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5068 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5068 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5068 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5067 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5066 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5067 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5066 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5065 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5064 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5063 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5062 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5062 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5061 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5062 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5061 - accuracy: 0.694 - 9s 4ms/step - loss: 0.5060 - accuracy: 0.695 - 9s 4ms/step - loss: 0.5059 - accuracy: 0.695 - 9s 4ms/step - loss: 0.5058 - accuracy: 0.695 - 9s 4ms/step - loss: 0.5057 - accuracy: 0.695 - 9s 4ms/step - loss: 0.5055 - accuracy: 0.695 - 9s 4ms/step - loss: 0.5054 - accuracy: 0.695 - 9s 4ms/step - loss: 0.5054 - accuracy: 0.695 - 9s 4ms/step - loss: 0.5052 - accuracy: 0.695 - 9s 4ms/step - loss: 0.5051 - accuracy: 0.695 - 9s 4ms/step - loss: 0.5050 - accuracy: 0.695 - 9s 4ms/step - loss: 0.5049 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5048 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5047 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5047 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5046 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5044 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5044 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5044 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5043 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5042 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5041 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5041 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5040 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5039 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5039 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5038 - accuracy: 0.696 - 9s 4ms/step - loss: 0.5038 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5036 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5035 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5034 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5034 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5034 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5034 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5034 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5033 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5034 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5033 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5033 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5032 - accuracy: 0.697 - 9s 4ms/step - loss: 0.5030 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5028 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5027 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5027 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5026 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5028 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5026 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5025 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5023 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5023 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5022 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5022 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5021 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5020 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5019 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5019 - accuracy: 0.698 - 9s 4ms/step - loss: 0.5018 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5017 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5016 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5016 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5015 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5014 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5013 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5013 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5012 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5011 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5010 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5009 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5007 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5006 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5006 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5005 - accuracy: 0.699 - 9s 4ms/step - loss: 0.5004 - accuracy: 0.700 - 9s 4ms/step - loss: 0.5003 - accuracy: 0.700 - 9s 4ms/step - loss: 0.5003 - accuracy: 0.700 - 9s 4ms/step - loss: 0.5002 - accuracy: 0.700 - 9s 4ms/step - loss: 0.5001 - accuracy: 0.700 - 9s 4ms/step - loss: 0.4999 - accuracy: 0.700 - 9s 4ms/step - loss: 0.4998 - accuracy: 0.700 - 9s 4ms/step - loss: 0.4997 - accuracy: 0.700 - 9s 4ms/step - loss: 0.4996 - accuracy: 0.700 - 9s 4ms/step - loss: 0.4995 - accuracy: 0.700 - 9s 4ms/step - loss: 0.4993 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4993 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4992 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4992 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4991 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4992 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4991 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4991 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4990 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4989 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4989 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4987 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4987 - accuracy: 0.7017"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================]87 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4986 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4984 - accuracy: 0.701 - 9s 4ms/step - loss: 0.4984 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4984 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4985 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4984 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4983 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4982 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4981 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4980 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4979 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4978 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4977 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4977 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4979 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4978 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4978 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4977 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4976 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4976 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4976 - accuracy: 0.702 - 9s 4ms/step - loss: 0.4975 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4976 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4975 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4975 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4974 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4974 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4974 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4974 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4972 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4972 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4971 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4969 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4969 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4969 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4967 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4967 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4966 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4966 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4966 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4966 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4964 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4964 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4964 - accuracy: 0.703 - 9s 4ms/step - loss: 0.4963 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4964 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4962 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4961 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4961 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4960 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4960 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4959 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4959 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4958 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4958 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4957 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4956 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4957 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4957 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4957 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4956 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4956 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4954 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4954 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4955 - accuracy: 0.704 - 9s 4ms/step - loss: 0.4954 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4954 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4954 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4952 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4951 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4951 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4950 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4949 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4947 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4946 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4945 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4945 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4944 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4943 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4943 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4942 - accuracy: 0.705 - 9s 4ms/step - loss: 0.4941 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4940 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4939 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4939 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4938 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4939 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4939 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4938 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4936 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4937 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4937 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4936 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4936 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4936 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4936 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4936 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4935 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4934 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4933 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4932 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4931 - accuracy: 0.706 - 9s 4ms/step - loss: 0.4931 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4930 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4929 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4928 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4928 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4928 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4926 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4926 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4925 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4925 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4924 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4922 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4923 - accuracy: 0.707 - 9s 4ms/step - loss: 0.4923 - accuracy: 0.707 - 10s 4ms/step - loss: 0.4923 - accuracy: 0.7078 - val_loss: 0.4148 - val_accuracy: 0.8800\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - ETA: 1:57 - loss: 0.4989 - accuracy: 0.80 - ETA: 8s - loss: 0.3434 - accuracy: 0.8704 - ETA: 7s - loss: 0.3037 - accuracy: 0.87 - ETA: 6s - loss: 0.3297 - accuracy: 0.86 - ETA: 5s - loss: 0.3273 - accuracy: 0.86 - ETA: 4s - loss: 0.3218 - accuracy: 0.85 - ETA: 4s - loss: 0.3225 - accuracy: 0.86 - ETA: 4s - loss: 0.3227 - accuracy: 0.86 - ETA: 4s - loss: 0.3222 - accuracy: 0.86 - ETA: 4s - loss: 0.3171 - accuracy: 0.86 - ETA: 3s - loss: 0.3207 - accuracy: 0.86 - ETA: 3s - loss: 0.3210 - accuracy: 0.86 - ETA: 3s - loss: 0.3222 - accuracy: 0.86 - ETA: 3s - loss: 0.3213 - accuracy: 0.86 - ETA: 3s - loss: 0.3219 - accuracy: 0.86 - ETA: 3s - loss: 0.3193 - accuracy: 0.86 - ETA: 3s - loss: 0.3208 - accuracy: 0.86 - ETA: 3s - loss: 0.3191 - accuracy: 0.86 - ETA: 3s - loss: 0.3175 - accuracy: 0.86 - ETA: 3s - loss: 0.3148 - accuracy: 0.86 - ETA: 3s - loss: 0.3165 - accuracy: 0.86 - ETA: 3s - loss: 0.3165 - accuracy: 0.86 - ETA: 3s - loss: 0.3158 - accuracy: 0.86 - ETA: 2s - loss: 0.3122 - accuracy: 0.87 - ETA: 2s - loss: 0.3105 - accuracy: 0.87 - ETA: 2s - loss: 0.3097 - accuracy: 0.87 - ETA: 2s - loss: 0.3070 - accuracy: 0.87 - ETA: 2s - loss: 0.3047 - accuracy: 0.87 - ETA: 2s - loss: 0.3024 - accuracy: 0.87 - ETA: 2s - loss: 0.3012 - accuracy: 0.87 - ETA: 2s - loss: 0.2994 - accuracy: 0.87 - ETA: 2s - loss: 0.2993 - accuracy: 0.87 - ETA: 2s - loss: 0.2979 - accuracy: 0.87 - ETA: 2s - loss: 0.2978 - accuracy: 0.87 - ETA: 2s - loss: 0.2988 - accuracy: 0.87 - ETA: 2s - loss: 0.2978 - accuracy: 0.87 - ETA: 2s - loss: 0.2975 - accuracy: 0.87 - ETA: 2s - loss: 0.2968 - accuracy: 0.87 - ETA: 2s - loss: 0.2958 - accuracy: 0.87 - ETA: 2s - loss: 0.2950 - accuracy: 0.87 - ETA: 1s - loss: 0.2943 - accuracy: 0.87 - ETA: 1s - loss: 0.2934 - accuracy: 0.88 - ETA: 1s - loss: 0.2924 - accuracy: 0.88 - ETA: 1s - loss: 0.2917 - accuracy: 0.88 - ETA: 1s - loss: 0.2911 - accuracy: 0.88 - ETA: 1s - loss: 0.2904 - accuracy: 0.88 - ETA: 1s - loss: 0.2896 - accuracy: 0.88 - ETA: 1s - loss: 0.2885 - accuracy: 0.88 - ETA: 1s - loss: 0.2880 - accuracy: 0.88 - ETA: 1s - loss: 0.2872 - accuracy: 0.88 - ETA: 1s - loss: 0.2875 - accuracy: 0.88 - ETA: 1s - loss: 0.2881 - accuracy: 0.88 - ETA: 1s - loss: 0.2873 - accuracy: 0.88 - ETA: 1s - loss: 0.2870 - accuracy: 0.88 - ETA: 1s - loss: 0.2864 - accuracy: 0.88 - ETA: 1s - loss: 0.2862 - accuracy: 0.88 - ETA: 1s - loss: 0.2851 - accuracy: 0.88 - ETA: 1s - loss: 0.2841 - accuracy: 0.88 - ETA: 1s - loss: 0.2858 - accuracy: 0.88 - ETA: 0s - loss: 0.2861 - accuracy: 0.88 - ETA: 0s - loss: 0.2855 - accuracy: 0.88 - ETA: 0s - loss: 0.2847 - accuracy: 0.88 - ETA: 0s - loss: 0.2841 - accuracy: 0.88 - ETA: 0s - loss: 0.2835 - accuracy: 0.88 - ETA: 0s - loss: 0.2833 - accuracy: 0.88 - ETA: 0s - loss: 0.2825 - accuracy: 0.88 - ETA: 0s - loss: 0.2819 - accuracy: 0.88 - ETA: 0s - loss: 0.2811 - accuracy: 0.88 - ETA: 0s - loss: 0.2808 - accuracy: 0.88 - ETA: 0s - loss: 0.2804 - accuracy: 0.88 - ETA: 0s - loss: 0.2800 - accuracy: 0.88 - ETA: 0s - loss: 0.2791 - accuracy: 0.88 - ETA: 0s - loss: 0.2787 - accuracy: 0.88 - ETA: 0s - loss: 0.2785 - accuracy: 0.88 - ETA: 0s - loss: 0.2780 - accuracy: 0.88 - ETA: 0s - loss: 0.2785 - accuracy: 0.88 - ETA: 0s - loss: 0.2782 - accuracy: 0.88 - ETA: 0s - loss: 0.2785 - accuracy: 0.88 - 4s 2ms/step - loss: 0.2786 - accuracy: 0.8865 - val_loss: 0.3216 - val_accuracy: 0.8600\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - ETA: 1:47 - loss: 0.0863 - accuracy: 1.00 - ETA: 7s - loss: 0.2410 - accuracy: 0.8906 - ETA: 5s - loss: 0.2581 - accuracy: 0.89 - ETA: 4s - loss: 0.2629 - accuracy: 0.89 - ETA: 4s - loss: 0.2520 - accuracy: 0.90 - ETA: 4s - loss: 0.2476 - accuracy: 0.90 - ETA: 4s - loss: 0.2516 - accuracy: 0.90 - ETA: 4s - loss: 0.2487 - accuracy: 0.90 - ETA: 3s - loss: 0.2385 - accuracy: 0.90 - ETA: 3s - loss: 0.2462 - accuracy: 0.90 - ETA: 3s - loss: 0.2520 - accuracy: 0.90 - ETA: 3s - loss: 0.2484 - accuracy: 0.90 - ETA: 3s - loss: 0.2478 - accuracy: 0.90 - ETA: 3s - loss: 0.2482 - accuracy: 0.90 - ETA: 3s - loss: 0.2481 - accuracy: 0.90 - ETA: 3s - loss: 0.2499 - accuracy: 0.90 - ETA: 3s - loss: 0.2503 - accuracy: 0.90 - ETA: 3s - loss: 0.2487 - accuracy: 0.90 - ETA: 3s - loss: 0.2483 - accuracy: 0.90 - ETA: 3s - loss: 0.2480 - accuracy: 0.90 - ETA: 3s - loss: 0.2486 - accuracy: 0.90 - ETA: 2s - loss: 0.2470 - accuracy: 0.90 - ETA: 2s - loss: 0.2449 - accuracy: 0.90 - ETA: 2s - loss: 0.2446 - accuracy: 0.90 - ETA: 2s - loss: 0.2440 - accuracy: 0.90 - ETA: 2s - loss: 0.2430 - accuracy: 0.90 - ETA: 2s - loss: 0.2434 - accuracy: 0.90 - ETA: 2s - loss: 0.2416 - accuracy: 0.90 - ETA: 2s - loss: 0.2401 - accuracy: 0.90 - ETA: 2s - loss: 0.2386 - accuracy: 0.90 - ETA: 2s - loss: 0.2387 - accuracy: 0.90 - ETA: 2s - loss: 0.2366 - accuracy: 0.90 - ETA: 2s - loss: 0.2364 - accuracy: 0.90 - ETA: 2s - loss: 0.2360 - accuracy: 0.90 - ETA: 2s - loss: 0.2355 - accuracy: 0.90 - ETA: 2s - loss: 0.2342 - accuracy: 0.90 - ETA: 2s - loss: 0.2339 - accuracy: 0.90 - ETA: 2s - loss: 0.2329 - accuracy: 0.90 - ETA: 2s - loss: 0.2343 - accuracy: 0.90 - ETA: 1s - loss: 0.2339 - accuracy: 0.90 - ETA: 1s - loss: 0.2324 - accuracy: 0.90 - ETA: 1s - loss: 0.2313 - accuracy: 0.90 - ETA: 1s - loss: 0.2309 - accuracy: 0.90 - ETA: 1s - loss: 0.2307 - accuracy: 0.90 - ETA: 1s - loss: 0.2306 - accuracy: 0.91 - ETA: 1s - loss: 0.2312 - accuracy: 0.91 - ETA: 1s - loss: 0.2307 - accuracy: 0.91 - ETA: 1s - loss: 0.2302 - accuracy: 0.91 - ETA: 1s - loss: 0.2301 - accuracy: 0.91 - ETA: 1s - loss: 0.2294 - accuracy: 0.91 - ETA: 1s - loss: 0.2297 - accuracy: 0.91 - ETA: 1s - loss: 0.2310 - accuracy: 0.91 - ETA: 1s - loss: 0.2306 - accuracy: 0.91 - ETA: 1s - loss: 0.2299 - accuracy: 0.91 - ETA: 1s - loss: 0.2294 - accuracy: 0.91 - ETA: 1s - loss: 0.2295 - accuracy: 0.91 - ETA: 1s - loss: 0.2294 - accuracy: 0.91 - ETA: 1s - loss: 0.2299 - accuracy: 0.91 - ETA: 0s - loss: 0.2294 - accuracy: 0.91 - ETA: 0s - loss: 0.2307 - accuracy: 0.91 - ETA: 0s - loss: 0.2306 - accuracy: 0.90 - ETA: 0s - loss: 0.2306 - accuracy: 0.90 - ETA: 0s - loss: 0.2310 - accuracy: 0.90 - ETA: 0s - loss: 0.2306 - accuracy: 0.90 - ETA: 0s - loss: 0.2304 - accuracy: 0.90 - ETA: 0s - loss: 0.2301 - accuracy: 0.91 - ETA: 0s - loss: 0.2299 - accuracy: 0.91 - ETA: 0s - loss: 0.2300 - accuracy: 0.91 - ETA: 0s - loss: 0.2298 - accuracy: 0.91 - ETA: 0s - loss: 0.2291 - accuracy: 0.91 - ETA: 0s - loss: 0.2288 - accuracy: 0.91 - ETA: 0s - loss: 0.2283 - accuracy: 0.91 - ETA: 0s - loss: 0.2280 - accuracy: 0.91 - ETA: 0s - loss: 0.2285 - accuracy: 0.91 - ETA: 0s - loss: 0.2281 - accuracy: 0.91 - ETA: 0s - loss: 0.2279 - accuracy: 0.91 - ETA: 0s - loss: 0.2274 - accuracy: 0.91 - 4s 2ms/step - loss: 0.2273 - accuracy: 0.9117 - val_loss: 0.3664 - val_accuracy: 0.8750\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - ETA: 1:47 - loss: 0.0378 - accuracy: 1.00 - ETA: 7s - loss: 0.1967 - accuracy: 0.9406 - ETA: 6s - loss: 0.2105 - accuracy: 0.93 - ETA: 5s - loss: 0.2423 - accuracy: 0.91 - ETA: 4s - loss: 0.2310 - accuracy: 0.92 - ETA: 4s - loss: 0.2261 - accuracy: 0.92 - ETA: 4s - loss: 0.2257 - accuracy: 0.92 - ETA: 4s - loss: 0.2181 - accuracy: 0.92 - ETA: 4s - loss: 0.2165 - accuracy: 0.92 - ETA: 3s - loss: 0.2205 - accuracy: 0.92 - ETA: 3s - loss: 0.2199 - accuracy: 0.92 - ETA: 3s - loss: 0.2204 - accuracy: 0.92 - ETA: 3s - loss: 0.2174 - accuracy: 0.92 - ETA: 3s - loss: 0.2132 - accuracy: 0.92 - ETA: 3s - loss: 0.2138 - accuracy: 0.92 - ETA: 3s - loss: 0.2115 - accuracy: 0.92 - ETA: 3s - loss: 0.2130 - accuracy: 0.92 - ETA: 3s - loss: 0.2146 - accuracy: 0.92 - ETA: 3s - loss: 0.2138 - accuracy: 0.92 - ETA: 3s - loss: 0.2143 - accuracy: 0.92 - ETA: 3s - loss: 0.2147 - accuracy: 0.92 - ETA: 3s - loss: 0.2132 - accuracy: 0.92 - ETA: 3s - loss: 0.2120 - accuracy: 0.92 - ETA: 2s - loss: 0.2105 - accuracy: 0.92 - ETA: 2s - loss: 0.2087 - accuracy: 0.92 - ETA: 2s - loss: 0.2072 - accuracy: 0.92 - ETA: 2s - loss: 0.2084 - accuracy: 0.92 - ETA: 2s - loss: 0.2071 - accuracy: 0.92 - ETA: 2s - loss: 0.2063 - accuracy: 0.92 - ETA: 2s - loss: 0.2057 - accuracy: 0.92 - ETA: 2s - loss: 0.2048 - accuracy: 0.92 - ETA: 2s - loss: 0.2048 - accuracy: 0.92 - ETA: 2s - loss: 0.2057 - accuracy: 0.92 - ETA: 2s - loss: 0.2031 - accuracy: 0.92 - ETA: 2s - loss: 0.2018 - accuracy: 0.92 - ETA: 2s - loss: 0.2024 - accuracy: 0.92 - ETA: 2s - loss: 0.2022 - accuracy: 0.92 - ETA: 2s - loss: 0.2020 - accuracy: 0.92 - ETA: 2s - loss: 0.2011 - accuracy: 0.92 - ETA: 2s - loss: 0.2012 - accuracy: 0.92 - ETA: 1s - loss: 0.2009 - accuracy: 0.92 - ETA: 1s - loss: 0.2004 - accuracy: 0.92 - ETA: 1s - loss: 0.2004 - accuracy: 0.92 - ETA: 1s - loss: 0.1997 - accuracy: 0.92 - ETA: 1s - loss: 0.1991 - accuracy: 0.92 - ETA: 1s - loss: 0.1993 - accuracy: 0.92 - ETA: 1s - loss: 0.1984 - accuracy: 0.92 - ETA: 1s - loss: 0.1985 - accuracy: 0.92 - ETA: 1s - loss: 0.1975 - accuracy: 0.92 - ETA: 1s - loss: 0.1982 - accuracy: 0.92 - ETA: 1s - loss: 0.1975 - accuracy: 0.92 - ETA: 1s - loss: 0.1979 - accuracy: 0.92 - ETA: 1s - loss: 0.1972 - accuracy: 0.92 - ETA: 1s - loss: 0.1979 - accuracy: 0.92 - ETA: 1s - loss: 0.1975 - accuracy: 0.92 - ETA: 1s - loss: 0.1977 - accuracy: 0.92 - ETA: 1s - loss: 0.1977 - accuracy: 0.92 - ETA: 1s - loss: 0.1978 - accuracy: 0.92 - ETA: 1s - loss: 0.1976 - accuracy: 0.92 - ETA: 0s - loss: 0.1975 - accuracy: 0.92 - ETA: 0s - loss: 0.1980 - accuracy: 0.92 - ETA: 0s - loss: 0.1977 - accuracy: 0.92 - ETA: 0s - loss: 0.1969 - accuracy: 0.92 - ETA: 0s - loss: 0.1979 - accuracy: 0.92 - ETA: 0s - loss: 0.1978 - accuracy: 0.92 - ETA: 0s - loss: 0.1972 - accuracy: 0.92 - ETA: 0s - loss: 0.1961 - accuracy: 0.92 - ETA: 0s - loss: 0.1955 - accuracy: 0.92 - ETA: 0s - loss: 0.1948 - accuracy: 0.92 - ETA: 0s - loss: 0.1946 - accuracy: 0.92 - ETA: 0s - loss: 0.1947 - accuracy: 0.92 - ETA: 0s - loss: 0.1949 - accuracy: 0.92 - ETA: 0s - loss: 0.1946 - accuracy: 0.92 - ETA: 0s - loss: 0.1941 - accuracy: 0.92 - ETA: 0s - loss: 0.1942 - accuracy: 0.92 - ETA: 0s - loss: 0.1952 - accuracy: 0.92 - ETA: 0s - loss: 0.1950 - accuracy: 0.92 - ETA: 0s - loss: 0.1952 - accuracy: 0.92 - 4s 2ms/step - loss: 0.1953 - accuracy: 0.9274 - val_loss: 0.3391 - val_accuracy: 0.8850\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - ETA: 1:49 - loss: 0.2750 - accuracy: 0.90 - ETA: 7s - loss: 0.2250 - accuracy: 0.9121 - ETA: 5s - loss: 0.2092 - accuracy: 0.92 - ETA: 4s - loss: 0.2118 - accuracy: 0.92 - ETA: 4s - loss: 0.2082 - accuracy: 0.92 - ETA: 4s - loss: 0.2052 - accuracy: 0.92 - ETA: 4s - loss: 0.2036 - accuracy: 0.92 - ETA: 4s - loss: 0.1965 - accuracy: 0.92 - ETA: 3s - loss: 0.1918 - accuracy: 0.92 - ETA: 3s - loss: 0.1921 - accuracy: 0.92 - ETA: 3s - loss: 0.1909 - accuracy: 0.92 - ETA: 3s - loss: 0.1925 - accuracy: 0.92 - ETA: 3s - loss: 0.1930 - accuracy: 0.92 - ETA: 3s - loss: 0.1888 - accuracy: 0.92 - ETA: 3s - loss: 0.1886 - accuracy: 0.93 - ETA: 3s - loss: 0.1875 - accuracy: 0.92 - ETA: 3s - loss: 0.1862 - accuracy: 0.93 - ETA: 3s - loss: 0.1897 - accuracy: 0.92 - ETA: 3s - loss: 0.1883 - accuracy: 0.92 - ETA: 3s - loss: 0.1858 - accuracy: 0.93 - ETA: 3s - loss: 0.1883 - accuracy: 0.92 - ETA: 3s - loss: 0.1864 - accuracy: 0.92 - ETA: 2s - loss: 0.1861 - accuracy: 0.92 - ETA: 2s - loss: 0.1842 - accuracy: 0.93 - ETA: 2s - loss: 0.1830 - accuracy: 0.93 - ETA: 2s - loss: 0.1824 - accuracy: 0.93 - ETA: 2s - loss: 0.1831 - accuracy: 0.93 - ETA: 2s - loss: 0.1816 - accuracy: 0.93 - ETA: 2s - loss: 0.1807 - accuracy: 0.93 - ETA: 2s - loss: 0.1801 - accuracy: 0.93 - ETA: 2s - loss: 0.1793 - accuracy: 0.93 - ETA: 2s - loss: 0.1794 - accuracy: 0.93 - ETA: 2s - loss: 0.1804 - accuracy: 0.93 - ETA: 2s - loss: 0.1800 - accuracy: 0.93 - ETA: 2s - loss: 0.1792 - accuracy: 0.93 - ETA: 2s - loss: 0.1785 - accuracy: 0.93 - ETA: 2s - loss: 0.1781 - accuracy: 0.93 - ETA: 2s - loss: 0.1793 - accuracy: 0.93 - ETA: 2s - loss: 0.1790 - accuracy: 0.93 - ETA: 2s - loss: 0.1784 - accuracy: 0.93 - ETA: 2s - loss: 0.1772 - accuracy: 0.93 - ETA: 1s - loss: 0.1774 - accuracy: 0.93 - ETA: 1s - loss: 0.1757 - accuracy: 0.93 - ETA: 1s - loss: 0.1757 - accuracy: 0.93 - ETA: 1s - loss: 0.1748 - accuracy: 0.93 - ETA: 1s - loss: 0.1739 - accuracy: 0.93 - ETA: 1s - loss: 0.1741 - accuracy: 0.93 - ETA: 1s - loss: 0.1734 - accuracy: 0.93 - ETA: 1s - loss: 0.1730 - accuracy: 0.93 - ETA: 1s - loss: 0.1732 - accuracy: 0.93 - ETA: 1s - loss: 0.1729 - accuracy: 0.93 - ETA: 1s - loss: 0.1741 - accuracy: 0.93 - ETA: 1s - loss: 0.1741 - accuracy: 0.93 - ETA: 1s - loss: 0.1737 - accuracy: 0.93 - ETA: 1s - loss: 0.1741 - accuracy: 0.93 - ETA: 1s - loss: 0.1741 - accuracy: 0.93 - ETA: 1s - loss: 0.1733 - accuracy: 0.93 - ETA: 1s - loss: 0.1736 - accuracy: 0.93 - ETA: 1s - loss: 0.1730 - accuracy: 0.93 - ETA: 1s - loss: 0.1721 - accuracy: 0.93 - ETA: 0s - loss: 0.1716 - accuracy: 0.93 - ETA: 0s - loss: 0.1723 - accuracy: 0.93 - ETA: 0s - loss: 0.1724 - accuracy: 0.93 - ETA: 0s - loss: 0.1720 - accuracy: 0.93 - ETA: 0s - loss: 0.1714 - accuracy: 0.93 - ETA: 0s - loss: 0.1710 - accuracy: 0.93 - ETA: 0s - loss: 0.1714 - accuracy: 0.93 - ETA: 0s - loss: 0.1714 - accuracy: 0.93 - ETA: 0s - loss: 0.1712 - accuracy: 0.93 - ETA: 0s - loss: 0.1710 - accuracy: 0.93 - ETA: 0s - loss: 0.1714 - accuracy: 0.93 - ETA: 0s - loss: 0.1709 - accuracy: 0.93 - ETA: 0s - loss: 0.1707 - accuracy: 0.93 - ETA: 0s - loss: 0.1709 - accuracy: 0.93 - ETA: 0s - loss: 0.1711 - accuracy: 0.93 - ETA: 0s - loss: 0.1708 - accuracy: 0.93 - ETA: 0s - loss: 0.1709 - accuracy: 0.93 - ETA: 0s - loss: 0.1707 - accuracy: 0.93 - ETA: 0s - loss: 0.1706 - accuracy: 0.93 - ETA: 0s - loss: 0.1714 - accuracy: 0.93 - 4s 2ms/step - loss: 0.1714 - accuracy: 0.9366 - val_loss: 0.3859 - val_accuracy: 0.8750\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - ETA: 1:47 - loss: 0.0679 - accuracy: 1.00 - ETA: 7s - loss: 0.2061 - accuracy: 0.9250 - ETA: 5s - loss: 0.1842 - accuracy: 0.92 - ETA: 5s - loss: 0.1848 - accuracy: 0.92 - ETA: 4s - loss: 0.1764 - accuracy: 0.92 - ETA: 4s - loss: 0.1803 - accuracy: 0.92 - ETA: 4s - loss: 0.1739 - accuracy: 0.93 - ETA: 4s - loss: 0.1729 - accuracy: 0.93 - ETA: 4s - loss: 0.1709 - accuracy: 0.93 - ETA: 3s - loss: 0.1690 - accuracy: 0.93 - ETA: 3s - loss: 0.1713 - accuracy: 0.93 - ETA: 3s - loss: 0.1710 - accuracy: 0.93 - ETA: 3s - loss: 0.1713 - accuracy: 0.93 - ETA: 3s - loss: 0.1676 - accuracy: 0.93 - ETA: 3s - loss: 0.1665 - accuracy: 0.93 - ETA: 3s - loss: 0.1650 - accuracy: 0.93 - ETA: 3s - loss: 0.1641 - accuracy: 0.93 - ETA: 3s - loss: 0.1649 - accuracy: 0.93 - ETA: 3s - loss: 0.1677 - accuracy: 0.93 - ETA: 3s - loss: 0.1653 - accuracy: 0.93 - ETA: 3s - loss: 0.1643 - accuracy: 0.93 - ETA: 3s - loss: 0.1638 - accuracy: 0.93 - ETA: 2s - loss: 0.1631 - accuracy: 0.93 - ETA: 2s - loss: 0.1620 - accuracy: 0.93 - ETA: 2s - loss: 0.1610 - accuracy: 0.94 - ETA: 2s - loss: 0.1624 - accuracy: 0.94 - ETA: 2s - loss: 0.1619 - accuracy: 0.94 - ETA: 2s - loss: 0.1615 - accuracy: 0.94 - ETA: 2s - loss: 0.1615 - accuracy: 0.94 - ETA: 2s - loss: 0.1612 - accuracy: 0.94 - ETA: 2s - loss: 0.1610 - accuracy: 0.94 - ETA: 2s - loss: 0.1610 - accuracy: 0.94 - ETA: 2s - loss: 0.1617 - accuracy: 0.94 - ETA: 2s - loss: 0.1617 - accuracy: 0.94 - ETA: 2s - loss: 0.1620 - accuracy: 0.94 - ETA: 2s - loss: 0.1620 - accuracy: 0.94 - ETA: 2s - loss: 0.1631 - accuracy: 0.93 - ETA: 2s - loss: 0.1617 - accuracy: 0.94 - ETA: 2s - loss: 0.1619 - accuracy: 0.94 - ETA: 2s - loss: 0.1606 - accuracy: 0.94 - ETA: 1s - loss: 0.1606 - accuracy: 0.94 - ETA: 1s - loss: 0.1606 - accuracy: 0.94 - ETA: 1s - loss: 0.1602 - accuracy: 0.94 - ETA: 1s - loss: 0.1598 - accuracy: 0.94 - ETA: 1s - loss: 0.1598 - accuracy: 0.94 - ETA: 1s - loss: 0.1590 - accuracy: 0.94 - ETA: 1s - loss: 0.1594 - accuracy: 0.94 - ETA: 1s - loss: 0.1583 - accuracy: 0.94 - ETA: 1s - loss: 0.1574 - accuracy: 0.94 - ETA: 1s - loss: 0.1571 - accuracy: 0.94 - ETA: 1s - loss: 0.1565 - accuracy: 0.94 - ETA: 1s - loss: 0.1567 - accuracy: 0.94 - ETA: 1s - loss: 0.1581 - accuracy: 0.94 - ETA: 1s - loss: 0.1578 - accuracy: 0.94 - ETA: 1s - loss: 0.1576 - accuracy: 0.94 - ETA: 1s - loss: 0.1578 - accuracy: 0.94 - ETA: 1s - loss: 0.1571 - accuracy: 0.94 - ETA: 1s - loss: 0.1577 - accuracy: 0.94 - ETA: 1s - loss: 0.1577 - accuracy: 0.94 - ETA: 1s - loss: 0.1577 - accuracy: 0.94 - ETA: 0s - loss: 0.1574 - accuracy: 0.94 - ETA: 0s - loss: 0.1578 - accuracy: 0.94 - ETA: 0s - loss: 0.1577 - accuracy: 0.94 - ETA: 0s - loss: 0.1574 - accuracy: 0.94 - ETA: 0s - loss: 0.1567 - accuracy: 0.94 - ETA: 0s - loss: 0.1568 - accuracy: 0.94 - ETA: 0s - loss: 0.1565 - accuracy: 0.94 - ETA: 0s - loss: 0.1566 - accuracy: 0.94 - ETA: 0s - loss: 0.1561 - accuracy: 0.94 - ETA: 0s - loss: 0.1572 - accuracy: 0.94 - ETA: 0s - loss: 0.1564 - accuracy: 0.94 - ETA: 0s - loss: 0.1563 - accuracy: 0.94 - ETA: 0s - loss: 0.1565 - accuracy: 0.94 - ETA: 0s - loss: 0.1565 - accuracy: 0.94 - ETA: 0s - loss: 0.1561 - accuracy: 0.94 - ETA: 0s - loss: 0.1562 - accuracy: 0.94 - ETA: 0s - loss: 0.1567 - accuracy: 0.94 - ETA: 0s - loss: 0.1566 - accuracy: 0.94 - ETA: 0s - loss: 0.1564 - accuracy: 0.94 - 4s 2ms/step - loss: 0.1563 - accuracy: 0.9418 - val_loss: 0.3820 - val_accuracy: 0.8650\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - ETA: 1:47 - loss: 0.5043 - accuracy: 0.90 - ETA: 6s - loss: 0.2024 - accuracy: 0.9324 - ETA: 5s - loss: 0.1679 - accuracy: 0.94 - ETA: 5s - loss: 0.1666 - accuracy: 0.94 - ETA: 4s - loss: 0.1602 - accuracy: 0.94 - ETA: 4s - loss: 0.1642 - accuracy: 0.93 - ETA: 4s - loss: 0.1655 - accuracy: 0.93 - ETA: 4s - loss: 0.1643 - accuracy: 0.93 - ETA: 4s - loss: 0.1646 - accuracy: 0.93 - ETA: 3s - loss: 0.1652 - accuracy: 0.93 - ETA: 3s - loss: 0.1638 - accuracy: 0.93 - ETA: 3s - loss: 0.1638 - accuracy: 0.93 - ETA: 3s - loss: 0.1644 - accuracy: 0.94 - ETA: 3s - loss: 0.1611 - accuracy: 0.94 - ETA: 3s - loss: 0.1603 - accuracy: 0.94 - ETA: 3s - loss: 0.1578 - accuracy: 0.94 - ETA: 3s - loss: 0.1540 - accuracy: 0.94 - ETA: 3s - loss: 0.1565 - accuracy: 0.94 - ETA: 3s - loss: 0.1541 - accuracy: 0.94 - ETA: 3s - loss: 0.1534 - accuracy: 0.94 - ETA: 3s - loss: 0.1543 - accuracy: 0.94 - ETA: 3s - loss: 0.1551 - accuracy: 0.94 - ETA: 2s - loss: 0.1533 - accuracy: 0.94 - ETA: 2s - loss: 0.1528 - accuracy: 0.94 - ETA: 2s - loss: 0.1522 - accuracy: 0.94 - ETA: 2s - loss: 0.1507 - accuracy: 0.94 - ETA: 2s - loss: 0.1496 - accuracy: 0.94 - ETA: 2s - loss: 0.1500 - accuracy: 0.94 - ETA: 2s - loss: 0.1494 - accuracy: 0.94 - ETA: 2s - loss: 0.1493 - accuracy: 0.94 - ETA: 2s - loss: 0.1480 - accuracy: 0.94 - ETA: 2s - loss: 0.1479 - accuracy: 0.94 - ETA: 2s - loss: 0.1490 - accuracy: 0.94 - ETA: 2s - loss: 0.1493 - accuracy: 0.94 - ETA: 2s - loss: 0.1492 - accuracy: 0.94 - ETA: 2s - loss: 0.1478 - accuracy: 0.94 - ETA: 2s - loss: 0.1475 - accuracy: 0.94 - ETA: 2s - loss: 0.1478 - accuracy: 0.94 - ETA: 2s - loss: 0.1472 - accuracy: 0.94 - ETA: 2s - loss: 0.1475 - accuracy: 0.94 - ETA: 1s - loss: 0.1477 - accuracy: 0.94 - ETA: 1s - loss: 0.1470 - accuracy: 0.94 - ETA: 1s - loss: 0.1463 - accuracy: 0.94 - ETA: 1s - loss: 0.1461 - accuracy: 0.94 - ETA: 1s - loss: 0.1458 - accuracy: 0.94 - ETA: 1s - loss: 0.1457 - accuracy: 0.94 - ETA: 1s - loss: 0.1455 - accuracy: 0.94 - ETA: 1s - loss: 0.1446 - accuracy: 0.94 - ETA: 1s - loss: 0.1448 - accuracy: 0.94 - ETA: 1s - loss: 0.1452 - accuracy: 0.94 - ETA: 1s - loss: 0.1444 - accuracy: 0.94 - ETA: 1s - loss: 0.1441 - accuracy: 0.94 - ETA: 1s - loss: 0.1442 - accuracy: 0.94 - ETA: 1s - loss: 0.1447 - accuracy: 0.94 - ETA: 1s - loss: 0.1452 - accuracy: 0.94 - ETA: 1s - loss: 0.1454 - accuracy: 0.94 - ETA: 1s - loss: 0.1455 - accuracy: 0.94 - ETA: 1s - loss: 0.1459 - accuracy: 0.94 - ETA: 1s - loss: 0.1450 - accuracy: 0.94 - ETA: 1s - loss: 0.1447 - accuracy: 0.94 - ETA: 0s - loss: 0.1442 - accuracy: 0.94 - ETA: 0s - loss: 0.1443 - accuracy: 0.94 - ETA: 0s - loss: 0.1440 - accuracy: 0.94 - ETA: 0s - loss: 0.1440 - accuracy: 0.94 - ETA: 0s - loss: 0.1444 - accuracy: 0.94 - ETA: 0s - loss: 0.1446 - accuracy: 0.94 - ETA: 0s - loss: 0.1453 - accuracy: 0.94 - ETA: 0s - loss: 0.1449 - accuracy: 0.94 - ETA: 0s - loss: 0.1453 - accuracy: 0.94 - ETA: 0s - loss: 0.1447 - accuracy: 0.94 - ETA: 0s - loss: 0.1443 - accuracy: 0.94 - ETA: 0s - loss: 0.1442 - accuracy: 0.94 - ETA: 0s - loss: 0.1443 - accuracy: 0.94 - ETA: 0s - loss: 0.1439 - accuracy: 0.94 - ETA: 0s - loss: 0.1433 - accuracy: 0.94 - ETA: 0s - loss: 0.1434 - accuracy: 0.94 - ETA: 0s - loss: 0.1429 - accuracy: 0.94 - ETA: 0s - loss: 0.1430 - accuracy: 0.94 - ETA: 0s - loss: 0.1438 - accuracy: 0.94 - 4s 2ms/step - loss: 0.1438 - accuracy: 0.9484 - val_loss: 0.5047 - val_accuracy: 0.8350\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - ETA: 1:49 - loss: 0.0900 - accuracy: 1.00 - ETA: 7s - loss: 0.1089 - accuracy: 0.9606 - ETA: 5s - loss: 0.1215 - accuracy: 0.95 - ETA: 4s - loss: 0.1280 - accuracy: 0.95 - ETA: 4s - loss: 0.1305 - accuracy: 0.95 - ETA: 4s - loss: 0.1334 - accuracy: 0.95 - ETA: 4s - loss: 0.1376 - accuracy: 0.95 - ETA: 4s - loss: 0.1357 - accuracy: 0.95 - ETA: 3s - loss: 0.1318 - accuracy: 0.95 - ETA: 3s - loss: 0.1331 - accuracy: 0.95 - ETA: 3s - loss: 0.1312 - accuracy: 0.95 - ETA: 3s - loss: 0.1306 - accuracy: 0.95 - ETA: 3s - loss: 0.1310 - accuracy: 0.95 - ETA: 3s - loss: 0.1297 - accuracy: 0.95 - ETA: 3s - loss: 0.1299 - accuracy: 0.95 - ETA: 3s - loss: 0.1285 - accuracy: 0.95 - ETA: 3s - loss: 0.1288 - accuracy: 0.95 - ETA: 3s - loss: 0.1307 - accuracy: 0.95 - ETA: 3s - loss: 0.1313 - accuracy: 0.95 - ETA: 3s - loss: 0.1314 - accuracy: 0.95 - ETA: 3s - loss: 0.1321 - accuracy: 0.95 - ETA: 3s - loss: 0.1328 - accuracy: 0.95 - ETA: 2s - loss: 0.1327 - accuracy: 0.95 - ETA: 2s - loss: 0.1321 - accuracy: 0.95 - ETA: 2s - loss: 0.1315 - accuracy: 0.95 - ETA: 2s - loss: 0.1327 - accuracy: 0.95 - ETA: 2s - loss: 0.1322 - accuracy: 0.95 - ETA: 2s - loss: 0.1306 - accuracy: 0.95 - ETA: 2s - loss: 0.1301 - accuracy: 0.95 - ETA: 2s - loss: 0.1302 - accuracy: 0.95 - ETA: 2s - loss: 0.1298 - accuracy: 0.95 - ETA: 2s - loss: 0.1289 - accuracy: 0.95 - ETA: 2s - loss: 0.1294 - accuracy: 0.95 - ETA: 2s - loss: 0.1299 - accuracy: 0.95 - ETA: 2s - loss: 0.1303 - accuracy: 0.95 - ETA: 2s - loss: 0.1305 - accuracy: 0.95 - ETA: 2s - loss: 0.1310 - accuracy: 0.95 - ETA: 2s - loss: 0.1307 - accuracy: 0.95 - ETA: 2s - loss: 0.1308 - accuracy: 0.95 - ETA: 2s - loss: 0.1293 - accuracy: 0.95 - ETA: 1s - loss: 0.1294 - accuracy: 0.95 - ETA: 1s - loss: 0.1292 - accuracy: 0.95 - ETA: 1s - loss: 0.1284 - accuracy: 0.95 - ETA: 1s - loss: 0.1271 - accuracy: 0.95 - ETA: 1s - loss: 0.1263 - accuracy: 0.95 - ETA: 1s - loss: 0.1261 - accuracy: 0.95 - ETA: 1s - loss: 0.1252 - accuracy: 0.95 - ETA: 1s - loss: 0.1269 - accuracy: 0.95 - ETA: 1s - loss: 0.1275 - accuracy: 0.95 - ETA: 1s - loss: 0.1276 - accuracy: 0.95 - ETA: 1s - loss: 0.1286 - accuracy: 0.95 - ETA: 1s - loss: 0.1288 - accuracy: 0.95 - ETA: 1s - loss: 0.1289 - accuracy: 0.95 - ETA: 1s - loss: 0.1286 - accuracy: 0.95 - ETA: 1s - loss: 0.1297 - accuracy: 0.95 - ETA: 1s - loss: 0.1299 - accuracy: 0.95 - ETA: 1s - loss: 0.1296 - accuracy: 0.95 - ETA: 1s - loss: 0.1299 - accuracy: 0.95 - ETA: 1s - loss: 0.1297 - accuracy: 0.95 - ETA: 0s - loss: 0.1288 - accuracy: 0.95 - ETA: 0s - loss: 0.1287 - accuracy: 0.95 - ETA: 0s - loss: 0.1289 - accuracy: 0.95 - ETA: 0s - loss: 0.1287 - accuracy: 0.95 - ETA: 0s - loss: 0.1284 - accuracy: 0.95 - ETA: 0s - loss: 0.1277 - accuracy: 0.95 - ETA: 0s - loss: 0.1278 - accuracy: 0.95 - ETA: 0s - loss: 0.1272 - accuracy: 0.95 - ETA: 0s - loss: 0.1272 - accuracy: 0.95 - ETA: 0s - loss: 0.1272 - accuracy: 0.95 - ETA: 0s - loss: 0.1276 - accuracy: 0.95 - ETA: 0s - loss: 0.1272 - accuracy: 0.95 - ETA: 0s - loss: 0.1275 - accuracy: 0.95 - ETA: 0s - loss: 0.1276 - accuracy: 0.95 - ETA: 0s - loss: 0.1277 - accuracy: 0.95 - ETA: 0s - loss: 0.1276 - accuracy: 0.95 - ETA: 0s - loss: 0.1273 - accuracy: 0.95 - ETA: 0s - loss: 0.1275 - accuracy: 0.95 - ETA: 0s - loss: 0.1278 - accuracy: 0.95 - 4s 2ms/step - loss: 0.1283 - accuracy: 0.9532 - val_loss: 0.4913 - val_accuracy: 0.8600\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - ETA: 1:44 - loss: 0.0329 - accuracy: 1.00 - ETA: 7s - loss: 0.1495 - accuracy: 0.9563 - ETA: 5s - loss: 0.1396 - accuracy: 0.95 - ETA: 4s - loss: 0.1335 - accuracy: 0.95 - ETA: 4s - loss: 0.1324 - accuracy: 0.95 - ETA: 4s - loss: 0.1346 - accuracy: 0.95 - ETA: 4s - loss: 0.1344 - accuracy: 0.95 - ETA: 4s - loss: 0.1326 - accuracy: 0.95 - ETA: 3s - loss: 0.1327 - accuracy: 0.95 - ETA: 3s - loss: 0.1317 - accuracy: 0.95 - ETA: 3s - loss: 0.1319 - accuracy: 0.95 - ETA: 3s - loss: 0.1354 - accuracy: 0.94 - ETA: 3s - loss: 0.1339 - accuracy: 0.95 - ETA: 3s - loss: 0.1305 - accuracy: 0.95 - ETA: 3s - loss: 0.1304 - accuracy: 0.95 - ETA: 3s - loss: 0.1297 - accuracy: 0.95 - ETA: 3s - loss: 0.1291 - accuracy: 0.95 - ETA: 3s - loss: 0.1289 - accuracy: 0.95 - ETA: 3s - loss: 0.1296 - accuracy: 0.95 - ETA: 3s - loss: 0.1297 - accuracy: 0.95 - ETA: 3s - loss: 0.1277 - accuracy: 0.95 - ETA: 2s - loss: 0.1267 - accuracy: 0.95 - ETA: 2s - loss: 0.1265 - accuracy: 0.95 - ETA: 2s - loss: 0.1259 - accuracy: 0.95 - ETA: 2s - loss: 0.1267 - accuracy: 0.95 - ETA: 2s - loss: 0.1259 - accuracy: 0.95 - ETA: 2s - loss: 0.1249 - accuracy: 0.95 - ETA: 2s - loss: 0.1237 - accuracy: 0.95 - ETA: 2s - loss: 0.1222 - accuracy: 0.95 - ETA: 2s - loss: 0.1226 - accuracy: 0.95 - ETA: 2s - loss: 0.1219 - accuracy: 0.95 - ETA: 2s - loss: 0.1220 - accuracy: 0.95 - ETA: 2s - loss: 0.1208 - accuracy: 0.95 - ETA: 2s - loss: 0.1221 - accuracy: 0.95 - ETA: 2s - loss: 0.1214 - accuracy: 0.95 - ETA: 2s - loss: 0.1210 - accuracy: 0.95 - ETA: 2s - loss: 0.1221 - accuracy: 0.95 - ETA: 2s - loss: 0.1224 - accuracy: 0.95 - ETA: 2s - loss: 0.1219 - accuracy: 0.95 - ETA: 1s - loss: 0.1224 - accuracy: 0.95 - ETA: 1s - loss: 0.1226 - accuracy: 0.95 - ETA: 1s - loss: 0.1217 - accuracy: 0.95 - ETA: 1s - loss: 0.1217 - accuracy: 0.95 - ETA: 1s - loss: 0.1214 - accuracy: 0.95 - ETA: 1s - loss: 0.1215 - accuracy: 0.95 - ETA: 1s - loss: 0.1218 - accuracy: 0.95 - ETA: 1s - loss: 0.1214 - accuracy: 0.95 - ETA: 1s - loss: 0.1210 - accuracy: 0.95 - ETA: 1s - loss: 0.1212 - accuracy: 0.95 - ETA: 1s - loss: 0.1211 - accuracy: 0.95 - ETA: 1s - loss: 0.1209 - accuracy: 0.95 - ETA: 1s - loss: 0.1202 - accuracy: 0.95 - ETA: 1s - loss: 0.1207 - accuracy: 0.95 - ETA: 1s - loss: 0.1202 - accuracy: 0.95 - ETA: 1s - loss: 0.1203 - accuracy: 0.95 - ETA: 1s - loss: 0.1205 - accuracy: 0.95 - ETA: 1s - loss: 0.1208 - accuracy: 0.95 - ETA: 1s - loss: 0.1210 - accuracy: 0.95 - ETA: 1s - loss: 0.1203 - accuracy: 0.95 - ETA: 0s - loss: 0.1202 - accuracy: 0.95 - ETA: 0s - loss: 0.1216 - accuracy: 0.95 - ETA: 0s - loss: 0.1209 - accuracy: 0.95 - ETA: 0s - loss: 0.1208 - accuracy: 0.95 - ETA: 0s - loss: 0.1203 - accuracy: 0.95 - ETA: 0s - loss: 0.1201 - accuracy: 0.95 - ETA: 0s - loss: 0.1199 - accuracy: 0.95 - ETA: 0s - loss: 0.1202 - accuracy: 0.95 - ETA: 0s - loss: 0.1202 - accuracy: 0.95 - ETA: 0s - loss: 0.1205 - accuracy: 0.95 - ETA: 0s - loss: 0.1199 - accuracy: 0.95 - ETA: 0s - loss: 0.1195 - accuracy: 0.95 - ETA: 0s - loss: 0.1193 - accuracy: 0.95 - ETA: 0s - loss: 0.1200 - accuracy: 0.95 - ETA: 0s - loss: 0.1199 - accuracy: 0.95 - ETA: 0s - loss: 0.1198 - accuracy: 0.95 - ETA: 0s - loss: 0.1198 - accuracy: 0.95 - ETA: 0s - loss: 0.1202 - accuracy: 0.95 - ETA: 0s - loss: 0.1203 - accuracy: 0.95 - 4s 2ms/step - loss: 0.1200 - accuracy: 0.9579 - val_loss: 0.5074 - val_accuracy: 0.8500\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - ETA: 1:47 - loss: 0.0977 - accuracy: 1.00 - ETA: 6s - loss: 0.1268 - accuracy: 0.9618 - ETA: 5s - loss: 0.1301 - accuracy: 0.95 - ETA: 4s - loss: 0.1159 - accuracy: 0.96 - ETA: 4s - loss: 0.1037 - accuracy: 0.96 - ETA: 4s - loss: 0.1172 - accuracy: 0.95 - ETA: 4s - loss: 0.1225 - accuracy: 0.95 - ETA: 4s - loss: 0.1235 - accuracy: 0.95 - ETA: 4s - loss: 0.1211 - accuracy: 0.95 - ETA: 3s - loss: 0.1218 - accuracy: 0.95 - ETA: 3s - loss: 0.1288 - accuracy: 0.95 - ETA: 3s - loss: 0.1289 - accuracy: 0.95 - ETA: 3s - loss: 0.1263 - accuracy: 0.95 - ETA: 3s - loss: 0.1290 - accuracy: 0.95 - ETA: 3s - loss: 0.1251 - accuracy: 0.95 - ETA: 3s - loss: 0.1249 - accuracy: 0.95 - ETA: 3s - loss: 0.1242 - accuracy: 0.95 - ETA: 3s - loss: 0.1217 - accuracy: 0.95 - ETA: 3s - loss: 0.1229 - accuracy: 0.95 - ETA: 3s - loss: 0.1225 - accuracy: 0.95 - ETA: 3s - loss: 0.1211 - accuracy: 0.95 - ETA: 3s - loss: 0.1219 - accuracy: 0.95 - ETA: 2s - loss: 0.1207 - accuracy: 0.95 - ETA: 2s - loss: 0.1196 - accuracy: 0.95 - ETA: 2s - loss: 0.1183 - accuracy: 0.95 - ETA: 2s - loss: 0.1183 - accuracy: 0.95 - ETA: 2s - loss: 0.1179 - accuracy: 0.95 - ETA: 2s - loss: 0.1178 - accuracy: 0.95 - ETA: 2s - loss: 0.1193 - accuracy: 0.95 - ETA: 2s - loss: 0.1200 - accuracy: 0.95 - ETA: 2s - loss: 0.1200 - accuracy: 0.95 - ETA: 2s - loss: 0.1190 - accuracy: 0.95 - ETA: 2s - loss: 0.1190 - accuracy: 0.95 - ETA: 2s - loss: 0.1178 - accuracy: 0.95 - ETA: 2s - loss: 0.1175 - accuracy: 0.95 - ETA: 2s - loss: 0.1179 - accuracy: 0.95 - ETA: 2s - loss: 0.1178 - accuracy: 0.95 - ETA: 2s - loss: 0.1171 - accuracy: 0.96 - ETA: 2s - loss: 0.1171 - accuracy: 0.95 - ETA: 2s - loss: 0.1164 - accuracy: 0.96 - ETA: 1s - loss: 0.1175 - accuracy: 0.96 - ETA: 1s - loss: 0.1167 - accuracy: 0.96 - ETA: 1s - loss: 0.1159 - accuracy: 0.96 - ETA: 1s - loss: 0.1155 - accuracy: 0.96 - ETA: 1s - loss: 0.1147 - accuracy: 0.96 - ETA: 1s - loss: 0.1154 - accuracy: 0.96 - ETA: 1s - loss: 0.1153 - accuracy: 0.96 - ETA: 1s - loss: 0.1151 - accuracy: 0.96 - ETA: 1s - loss: 0.1147 - accuracy: 0.96 - ETA: 1s - loss: 0.1142 - accuracy: 0.96 - ETA: 1s - loss: 0.1149 - accuracy: 0.96 - ETA: 1s - loss: 0.1144 - accuracy: 0.96 - ETA: 1s - loss: 0.1152 - accuracy: 0.96 - ETA: 1s - loss: 0.1155 - accuracy: 0.96 - ETA: 1s - loss: 0.1155 - accuracy: 0.96 - ETA: 1s - loss: 0.1143 - accuracy: 0.96 - ETA: 1s - loss: 0.1139 - accuracy: 0.96 - ETA: 1s - loss: 0.1138 - accuracy: 0.96 - ETA: 1s - loss: 0.1137 - accuracy: 0.96 - ETA: 0s - loss: 0.1135 - accuracy: 0.96 - ETA: 0s - loss: 0.1130 - accuracy: 0.96 - ETA: 0s - loss: 0.1127 - accuracy: 0.96 - ETA: 0s - loss: 0.1123 - accuracy: 0.96 - ETA: 0s - loss: 0.1122 - accuracy: 0.96 - ETA: 0s - loss: 0.1117 - accuracy: 0.96 - ETA: 0s - loss: 0.1117 - accuracy: 0.96 - ETA: 0s - loss: 0.1117 - accuracy: 0.96 - ETA: 0s - loss: 0.1123 - accuracy: 0.96 - ETA: 0s - loss: 0.1124 - accuracy: 0.96 - ETA: 0s - loss: 0.1120 - accuracy: 0.96 - ETA: 0s - loss: 0.1113 - accuracy: 0.96 - ETA: 0s - loss: 0.1109 - accuracy: 0.96 - ETA: 0s - loss: 0.1111 - accuracy: 0.96 - ETA: 0s - loss: 0.1109 - accuracy: 0.96 - ETA: 0s - loss: 0.1106 - accuracy: 0.96 - ETA: 0s - loss: 0.1107 - accuracy: 0.96 - ETA: 0s - loss: 0.1115 - accuracy: 0.96 - ETA: 0s - loss: 0.1114 - accuracy: 0.96 - 4s 2ms/step - loss: 0.1113 - accuracy: 0.9614 - val_loss: 0.6623 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "## compile and train the model\n",
    "model2.compile( optimizer='adam', \n",
    "              loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historty = model2.fit( train_batch, epochs=10, validation_data=test_batch, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot it\n",
    "h_dict = historty.history\n",
    "acc = h_dict['accuracy']\n",
    "v_acc = h_dict['val_accuracy']\n",
    "los = h_dict['loss']\n",
    "v_los = h_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1 )\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epochs, los, 'bo', label='Training loss')\n",
    "plt.plot(epochs, v_los, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, v_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim((0.5,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (vocab_size, embedding_dim) (8185, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.02762489, -0.01389265, -0.01915953, ..., -0.02048966,\n",
       "        -0.00591026,  0.07408127],\n",
       "       [-0.04557168,  0.01023355, -0.05564443, ..., -0.032729  ,\n",
       "         0.08119696,  0.06299481],\n",
       "       [-0.0298725 , -0.02709462, -0.10048167, ..., -0.07991067,\n",
       "         0.04869033,  0.0176893 ],\n",
       "       ...,\n",
       "       [-0.03100631,  0.04388758, -0.02521298, ...,  0.030868  ,\n",
       "        -0.03271617, -0.04126625],\n",
       "       [ 0.01514781, -0.0452388 , -0.02968427, ..., -0.01589551,\n",
       "        -0.00329635,  0.01389796],\n",
       "       [-0.03155911, -0.00072681,  0.0270893 , ..., -0.02695824,\n",
       "        -0.04032071,  0.04387034]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Retrieving the word embeddings learnt during training\n",
    "e_layer = model2.layers[0]\n",
    "e_weights = e_layer.get_weights()[0]\n",
    "\n",
    "print('shape: (vocab_size, embedding_dim)', e_weights.shape )\n",
    "\n",
    "e_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the weights for reuse \n",
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for n, w in enumerate( encoder.subwords):\n",
    "    vec = e_weights[n+1] ## skipping 0 b/c it's padding \n",
    "    out_m.write( w+\"\\n\")\n",
    "    out_v.write( '\\t'.join([ str(x) for x in vec]) + \"\\n\" ) \n",
    "\n",
    "out_v.close()\n",
    "out_m.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize the embeddings using Embedding Projector, which can also run in a  TensorBoard instance \n",
    "# http://projector.tensorflow.org/ << load the above two files here "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
