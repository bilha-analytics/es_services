{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coronavirus timeline:\n",
    "- January 19: 100 cases\n",
    "- January 24: 1,000 cases\n",
    "- February 12: 50,000 cases\n",
    "- March 6: 100,000 cases\n",
    "- March 18: 200,000 cases\n",
    "- March 21: 300,000 cases\n",
    "- March 24: 400,000 cases\n",
    "- March 26: 500,000 cases\n",
    "- March 28: 600,000 cases\n",
    "- March 29: 700,000 cases\n",
    "- March 31: 800,000 cases \n",
    "- April 1: 900,000 cases\n",
    "    \n",
    "    \n",
    "CoronaVirus in the EAC (Saturday 28th March)\n",
    "\n",
    "Rwanda - 60\n",
    "\n",
    "Kenya - 38\n",
    "\n",
    "Uganda - 30 \n",
    "\n",
    "Tanzania - 13\n",
    "\n",
    "Burundi - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab [31]:  , ,, ., 7, ?, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z\n",
      "\n",
      "Char2Idx: {' ': 0, ',': 1, '.': 2, '7': 3, '?': 4, 'a': 5, 'b': 6, 'c': 7, 'd': 8, 'e': 9, 'f': 10, 'g': 11, 'h': 12, 'i': 13, 'j': 14, 'k': 15, 'l': 16, 'm': 17, 'n': 18, 'o': 19, 'p': 20, 'q': 21, 'r': 22, 's': 23, 't': 24, 'u': 25, 'v': 26, 'w': 27, 'x': 28, 'y': 29, 'z': 30}\n",
      "\n",
      "Idx2Char: [' ' ',' '.' '7' '?' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm'\n",
      " 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
     ]
    }
   ],
   "source": [
    "st = \"The quick brown fox jumped over the lazy dogs. The dog had 7 bones, right?\"\n",
    "\n",
    "vocab = sorted(set(st.lower())) \n",
    "\n",
    "print(\"Vocab [{}]: {}\".format( len(vocab), \", \".join(vocab ) ) )\n",
    "\n",
    "char2idx = { c:i for i, c in enumerate( vocab ) }\n",
    "idx2char = np.array( vocab) # indexing follows vocab set order which is sorted asc\n",
    "\n",
    "print( \"\\nChar2Idx: {}\".format( char2idx ) ) \n",
    "print( \"\\nIdx2Char: {}\".format( idx2char ) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_db: <TensorSliceDataset shapes: (), types: tf.int32>\n",
      "24 ==> t\n",
      "12 ==> h\n",
      "9 ==> e\n",
      "0 ==>  \n",
      "21 ==> q\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10\n",
    "n_per_epoch = len( st ) \n",
    "\n",
    "sample_text_as_idx = np.array([ char2idx[c] for c in st.lower() ] ) \n",
    "\n",
    "## create training x_txt = y_target pairs as substr(st, i, seq_len) = substr(st, i+1, seq_len+1) \n",
    "## such that if seq_len = 3 \"Quick\" is partitioned as qui = uic, uic = ick, \n",
    "char_db = tf.data.Dataset.from_tensor_slices( sample_text_as_idx) \n",
    "\n",
    "print( \"char_db: {}\".format( char_db ) ) \n",
    "\n",
    "for i in char_db.take(5):\n",
    "    print( \"{} ==> {}\".format( i, idx2char[i.numpy() ] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([24 12  9  0 21 25 13  7 15  0  6], shape=(11,), dtype=int32)  ==>  't_h_e_ _q_u_i_c_k_ _b'\n",
      "tf.Tensor([22 19 27 18  0 10 19 28  0 14 25], shape=(11,), dtype=int32)  ==>  'r_o_w_n_ _f_o_x_ _j_u'\n",
      "tf.Tensor([17 20  9  8  0 19 26  9 22  0 24], shape=(11,), dtype=int32)  ==>  'm_p_e_d_ _o_v_e_r_ _t'\n",
      "tf.Tensor([12  9  0 16  5 30 29  0  8 19 11], shape=(11,), dtype=int32)  ==>  'h_e_ _l_a_z_y_ _d_o_g'\n",
      "tf.Tensor([23  2  0 24 12  9  0  8 19 11  0], shape=(11,), dtype=int32)  ==>  's_._ _t_h_e_ _d_o_g_ '\n"
     ]
    }
   ],
   "source": [
    "## batch method \n",
    "seqz = char_db.batch( seq_len+1, drop_remainder=True)\n",
    "for s in seqz.take(5):\n",
    "    print( s, \" ==> \", repr( '_'.join( idx2char[s.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-5371b65eee94>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-38-5371b65eee94>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    idx2char[ np.array([11:14])+[1, 7]]\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "idx2char[ np.array([11:14])+[1, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
