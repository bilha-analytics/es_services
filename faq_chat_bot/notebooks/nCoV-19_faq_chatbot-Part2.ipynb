{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Intro\n",
    "\n",
    "**FAQ style retrieval based chat bot**\n",
    "- Train three model types (in different configurations) to figure out user input and map to a response class. Let's see which one does well. The models are\n",
    "    - a TF-IDF similarity measure doc classifier \n",
    "    - a TFIDF based n-gram MLP multi-class classifier (supervised)\n",
    "    - an RNN classifier (unsupervised)\n",
    "\n",
    "**The Data**\n",
    "- Pulling data from known disease/pandemic authorities such as CDC and WHO\n",
    "\n",
    "- Also getting KE national government content. These are static data; knowledge already in place. TODO: a channel for news updates \n",
    "\n",
    "- Data is maintained in a Gsheet and can make updates/additions/etc from there\n",
    "\n",
    "- Clean and classify the above data to have two datasets\n",
    "    - FAQ_db: This is the knowledge base. One to one mapping of class categories and response paragraphs. Has two main fields: class_category, response_p. Additional fields: src, src_link \n",
    "    - Phrases_db: This is the training set on questions/input that users may present to the bot. Has two main fields: input_phrase, class_category \n",
    "    \n",
    "**Approach**\n",
    "- Retrieval based chat bot. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<a href=\"javascript:code_toggle()\">Show/Hide Code</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Corana Dashboard by John Hopkins Uni\n",
    "\n",
    "[Link to map FAQ](https://coronavirus.jhu.edu/map-faq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"650\"\n",
       "            height=\"400\"\n",
       "            src=\"//arcgis.com/apps/Embed/index.html?webmap=14aa9e5660cf42b5b4b546dec6ceec7c&extent=77.3846,11.535,163.5174,52.8632&center=28.8189834,-2.5117154&zoom=true&previewImage=false&scale=true&disable_scroll=true&theme=light?frameborder=0&scrolling=no&marginheight=0&marginwidth=0&title=2019-nCoV\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12148982d88>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### John Hopkins Dashboard - https://coronavirus.jhu.edu/map.html\n",
    "from IPython.display import IFrame\n",
    "## default 77.3846,11.535 \n",
    "start_coordz = \"77.3846,11.535\"  # rabat, morocco\"33.9693414,-6.9273026\"\n",
    "center_coordz = \"28.8189834,-2.5117154\" #center Bukavu, DRC \"-2.5117154,28.8189834\"\n",
    "\n",
    "IFrame(src=\"//arcgis.com/apps/Embed/index.html?webmap=14aa9e5660cf42b5b4b546dec6ceec7c&extent=\"+start_coordz+\",163.5174,52.8632\"+\n",
    "       \"&center=\"+center_coordz+\n",
    "       \"&zoom=true&previewImage=false&scale=true&disable_scroll=true&theme=light\", \n",
    "    width=\"650\", height=\"400\", frameborder=\"0\", scrolling=\"no\", marginheight=\"0\", marginwidth=\"0\", title=\"2019-nCoV\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. FAQ Chat bot - Part 2\n",
    "\n",
    "- Try different models\n",
    "- Fine tune hyper params\n",
    "- Save best fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall::**\n",
    "- INFOR   : 2020-04-06 17:38:00.251162 [dataSource.writeTo] dpath = cleaned_phrases.xftz\n",
    "- INFOR   : 2020-04-06 17:38:00.252160 [dataSource.writeTo] dpath = cleaned_phrases.ylbz\n",
    "- INFOR   : 2020-04-06 17:38:00.253182 [dataSource.writeTo] dpath = cleaned_phrases.faqdb\n",
    "- INFOR   : 2020-04-06 17:38:00.253182 [dataSource.writeTo] dpath = cleaned_phrases.phrdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "## Don't know why the stop words are failing and yet the last stop has the correct list :( \n",
    "## set a seed at shuffle dataset for train ,test split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Vectorize\n",
    "- Do TFIDF Vectorization. Can be used with similarity doc classification, n-gram MLP, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../shared\") \n",
    "import zdataset, zdata_source\n",
    "from zdataset import ZGsheetFaqDataSet\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot settings\n",
    "params = {\n",
    "    'font.size' : 14.0,\n",
    "    'figure.figsize': (20.0, 12.0),\n",
    "    'figure.dpi' : 40\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "plt.style.use('fivethirtyeight') #tableau-colorblind10 ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFOR   : 2020-04-06 21:03:16.115361 [\u001b[34mzdataset.dumpLoad\u001b[0m] Loaded cleaned_phrases.xftz of size 141\n",
      "INFOR   : 2020-04-06 21:03:16.118353 [\u001b[34mzdataset.dumpLoad\u001b[0m] Loaded cleaned_phrases.xidx of size 141\n",
      "INFOR   : 2020-04-06 21:03:16.119349 [\u001b[34mzdataset.dumpLoad\u001b[0m] Loaded cleaned_phrases.ylbz of size 141\n",
      "INFOR   : 2020-04-06 21:03:16.120346 [\u001b[34mzdataset.dumpLoad\u001b[0m] Not Found: cleaned_phrases.argz\n",
      "INFOR   : 2020-04-06 21:03:16.121344 [\u001b[34mzdataset.dumpLoad\u001b[0m] Loaded cleaned_phrases.faqdb of size 92\n",
      "INFOR   : 2020-04-06 21:03:16.122341 [\u001b[34mzdataset.dumpLoad\u001b[0m] Loaded cleaned_phrases.phrdb of size 141\n",
      "INFOR   : 2020-04-06 21:03:16.122341 [\u001b[34mzdataset.dumLoad\u001b[0m] FINISHED: clean data size 141\n"
     ]
    }
   ],
   "source": [
    "### Load the preprocessed data \n",
    "dpath = \"cleaned_phrases\"\n",
    "dset = ZGsheetFaqDataSet()\n",
    "dset.dumpLoad( dpath, zdata_source.zSERIALIZED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Featurez: ['pandemic' 'cause pandemic' 'mean declared pandemic']\n",
      "Example Label: ['pandemic_define' 'pandemic_causes' 'pandemic_WHO']\n",
      "Example Featurez: ['make cat dog pet sick']\n",
      "Example Label: ['pets_infection_cdc']\n"
     ]
    }
   ],
   "source": [
    "print(\"Example Featurez: {}\".format( dset.clean_data[:3] ) )\n",
    "print(\"Example Label: {}\".format( dset.y_labelz[:3] ) )\n",
    "\n",
    "print(\"Example Featurez: {}\".format( dset.clean_data[-1:] ) )\n",
    "print(\"Example Label: {}\".format( dset.y_labelz[-1:] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO: Split training and validation <<< b/c @ shuffling and resetting index at new dset obje\n",
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Encoding:   (1, 24)\t1.0\n",
      "  (2, 68)\t0.7071067811865476\n",
      "  (2, 173)\t0.7071067811865476\n",
      "Example Encoding:   (0, 205)\t0.533923657905307\n",
      "  (0, 167)\t0.533923657905307\n",
      "  (0, 75)\t0.46360061208869924\n",
      "  (0, 23)\t0.46360061208869924\n"
     ]
    }
   ],
   "source": [
    "## TFIDF encode \n",
    "# ZENC_TFIDF is default \n",
    "encoder_tfidf, encoded_featurez = dset.encodeTrain(enc_type=zdataset.ZENC_TFIDF, ngramz=(2,2)) \n",
    "print(\"Example Encoding: {}\".format( encoded_featurez[: 3] ) ) \n",
    "print(\"Example Encoding: {}\".format( encoded_featurez[-1:] ) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Cosine Similarity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zmodel_cosine_similarity import ZCosineSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup \n",
    "model = ZCosineSimilarity('TFIDF_Cosine')\n",
    "model.build( dset.context )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEANED: Is corana deadly ===> corana deadly\n",
      "CLEANED: What is corana ===> corana\n",
      "CLEANED: Should my pet get tested ===> pet get tested\n",
      "CLEANED: Will mosquito bite infect me ===> mosquito bite infect\n",
      "CLEANED: Can I vist my elderly parents ===> vist elderly parent\n",
      "CLEANED: Is there a vaccineS ===> vaccine\n"
     ]
    }
   ],
   "source": [
    "## TODO: train_test_split. For now use below\n",
    "val_txt = ['Is corana deadly', \n",
    "           'What is corana', \n",
    "           \"Should my pet get tested\", \n",
    "           \"Will mosquito bite infect me\", \n",
    "          \"Can I vist my elderly parents\", \n",
    "          \"Is there a vaccineS\"]\n",
    "\n",
    "val_ylabz = ['covid19_define',\n",
    "             'covid19_define',\n",
    "            'pets_testing', \n",
    "            'covid19_spread_insects',\n",
    "            'covid19_at_risk',\n",
    "            'covid19_cure']\n",
    "\n",
    "\n",
    "cleaned_txt = dset.preprocessPredict( val_txt)\n",
    "\n",
    "for itx, otx in zip(val_txt, cleaned_txt):\n",
    "    print(\"CLEANED: {} ===> {}\".format(itx, otx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFOR   : 2020-04-06 21:03:17.410896 [\u001b[34mcosine.predict\u001b[0m] IN: corana deadly\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d7e82b0c8fd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_yz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mcleaned_txt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ylabz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted Accuracy: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpredicted_yz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_txt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ylabz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mdset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPredictedAtIndex\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\zRepoz\\shared\\zmodel_cosine_similarity.py\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self, text_list, ylabelz_list)\u001b[0m\n\u001b[0;32m     27\u001b[0m     '''\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabelz_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mpredicted_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_list\u001b[0m \u001b[1;33m]\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpredicted_list\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mylabelz_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mpredicted_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\zRepoz\\shared\\zmodel_cosine_similarity.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     27\u001b[0m     '''\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabelz_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mpredicted_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_list\u001b[0m \u001b[1;33m]\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpredicted_list\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mylabelz_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mpredicted_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\zRepoz\\shared\\zmodel_cosine_similarity.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, clean_input_text)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_input_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mzlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cosine.predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"IN: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_input_text\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0minput_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mclean_input_text\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mvalz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents, copy)\u001b[0m\n\u001b[0;32m   1678\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'The tfidf vector is not fitted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1680\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1681\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1103\u001b[1;33m                 \u001b[1;34m\"Iterable over raw text documents expected, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m                 \"string object received.\")\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "acc, predicted_yz = model.validate( cleaned_txt, val_ylabz)\n",
    "print(\"Predicted Accuracy: {}\".format( acc) ) \n",
    "\n",
    "for idx, txt, y in  zip( predicted_yz, val_txt, val_ylabz):\n",
    "    cat,res =  dset.getPredictedAtIndex( idx )\n",
    "    print(\"PREDICTED: {}:{} ===> {} for '{}' \".format(idx, y, cat, txt))\n",
    "    print(\"\\t{}\\n\".format(resp) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Multi-class MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(np.array( [1, 2, 3] ) == np.array( [1, 2.0, 3.000] )).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
